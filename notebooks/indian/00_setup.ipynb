{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ac3786",
   "metadata": {},
   "source": [
    "# 00 — Setup and Data Preparation (Indian Music Genre)\n",
    "\n",
    "Downloads the Kaggle dataset `winchester19/indian-music-genre-dataset` via KaggleHub and prepares a leak-free split of mel-spectrogram arrays under `data/processed_indian/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee0eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger and config\n",
    "import os, shutil, json, time, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "VERBOSE = os.environ.get('IND_VERBOSE','1') == '1'\n",
    "def log(msg: str, level: str='INFO'):\n",
    "    if not VERBOSE and level=='INFO': return\n",
    "    print(f'[{datetime.now().strftime('%H:%M:%S')}] {level}: {msg}')\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve().parents[1]\n",
    "DATA_ROOT = PROJECT_ROOT/'data'\n",
    "RAW = DATA_ROOT/'indian_music'\n",
    "PROCESSED = DATA_ROOT/'processed_indian'\n",
    "PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Audio/Mel config\n",
    "SR = int(os.environ.get('SR','22050'))\n",
    "N_MELS = int(os.environ.get('N_MELS','128'))\n",
    "HOP = int(os.environ.get('HOP','256'))\n",
    "SEG_DUR = float(os.environ.get('SEG_DUR','3.0'))\n",
    "N_SEGMENTS = int(os.environ.get('N_SEGMENTS','10'))\n",
    "T_TARGET = int(os.environ.get('T_TARGET','128'))\n",
    "\n",
    "# Parallel/extraction toggles\n",
    "PARALLEL = os.environ.get('IND_PARALLEL','1')=='1'\n",
    "N_JOBS = int(os.environ.get('IND_JOBS','8'))\n",
    "MAX_TRACKS_PER_CLASS = int(os.environ.get('IND_MAX_PER_CLASS','0'))  # 0 = no cap\n",
    "\n",
    "CONFIG = dict(SR=SR, N_MELS=N_MELS, HOP=HOP, SEG_DUR=SEG_DUR, N_SEGMENTS=N_SEGMENTS, T_TARGET=T_TARGET, PARALLEL=PARALLEL, N_JOBS=N_JOBS, MAX_TRACKS_PER_CLASS=MAX_TRACKS_PER_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a178f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:30:43] INFO: Downloading dataset: winchester19/indian-music-genre-dataset\n",
      "[18:30:43] INFO: KaggleHub cache path: /home/alepot55/.cache/kagglehub/datasets/winchester19/indian-music-genre-dataset/versions/1\n",
      "[18:30:43] INFO: Prepared /home/alepot55/Desktop/projects/naml_project/data/indian_music — copied=0, skipped=1\n",
      "Subfolders: ['genrenew']\n"
     ]
    }
   ],
   "source": [
    "# Download via KaggleHub (idempotent copy into data/indian_music)\n",
    "import kagglehub\n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "DATASET_ID = os.environ.get('INDIAN_DATASET_ID', 'winchester19/indian-music-genre-dataset')\n",
    "log(f'Downloading dataset: {DATASET_ID}')\n",
    "cache_path = kagglehub.dataset_download(DATASET_ID)\n",
    "log(f'KaggleHub cache path: {cache_path}')\n",
    "import pathlib\n",
    "copied, skipped = 0, 0\n",
    "for item in pathlib.Path(cache_path).iterdir():\n",
    "    if not item.is_dir(): continue\n",
    "    dest = RAW/item.name\n",
    "    if dest.exists(): skipped += 1; continue\n",
    "    shutil.copytree(item, dest); copied += 1\n",
    "log(f'Prepared {RAW} — copied={copied}, skipped={skipped}')\n",
    "print('Subfolders:', sorted([p.name for p in RAW.iterdir() if p.is_dir()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb22d125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:44:47] INFO: Discovered classes: ['bollypop', 'carnatic', 'ghazal', 'semiclassical', 'sufi']\n",
      "[18:44:47] INFO: Train/Val/Test files: 300/100/100 | classes=5\n"
     ]
    }
   ],
   "source": [
    "# Build file list and labels from subfolders with nested-structure handling\n",
    "from pathlib import Path\n",
    "import numpy as np, librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Detect immediate subfolders at RAW level\n",
    "classes_top = sorted([p.name for p in RAW.iterdir() if p.is_dir()])\n",
    "\n",
    "# Collect files recursively and derive labels robustly\n",
    "files, labels = [], []\n",
    "allowed_ext = {'.mp3', '.wav', '.m4a', '.flac'}\n",
    "for fp in RAW.rglob('*'):\n",
    "    if not fp.is_file() or fp.suffix.lower() not in allowed_ext:\n",
    "        continue\n",
    "    rel_parts = fp.relative_to(RAW).parts\n",
    "    if len(classes_top) > 1:\n",
    "        # Use the first segment under RAW as class\n",
    "        lbl = rel_parts[0] if len(rel_parts) >= 1 else fp.parent.name\n",
    "    else:\n",
    "        # Single top-level folder -> take the next segment as class if available\n",
    "        lbl = rel_parts[1] if len(rel_parts) >= 2 else fp.parent.name\n",
    "    files.append(str(fp))\n",
    "    labels.append(lbl)\n",
    "\n",
    "# Compute discovered classes from labels\n",
    "classes = sorted(set(labels))\n",
    "log(f\"Discovered classes: {classes}\")\n",
    "\n",
    "# Optional per-class cap for quick runs\n",
    "if MAX_TRACKS_PER_CLASS > 0:\n",
    "    from collections import defaultdict; import random\n",
    "    byc = defaultdict(list)\n",
    "    for f,y in zip(files,labels): byc[y].append(f)\n",
    "    files,labels = [],[]\n",
    "    rng = random.Random(42)\n",
    "    for y,lst in byc.items(): lst = sorted(lst); rng.shuffle(lst); take = lst[:MAX_TRACKS_PER_CLASS]; files+=take; labels+=[y]*len(take)\n",
    "\n",
    "# Encode labels\n",
    "y_text = labels\n",
    "le = LabelEncoder().fit(sorted(set(y_text)))\n",
    "y = le.transform(y_text)\n",
    "\n",
    "# Stratify guards\n",
    "from collections import Counter\n",
    "cnts = Counter(y)\n",
    "min_count = min(cnts.values()) if cnts else 0\n",
    "strat = y if len(set(y))>1 and min_count>=2 else None\n",
    "Xtr_f, Xte_f, ytr, yte = train_test_split(files, y, test_size=0.2, random_state=42, stratify=strat)\n",
    "strat_tv = ytr if strat is not None else None\n",
    "Xtr_f, Xva_f, ytr, yva = train_test_split(Xtr_f, ytr, test_size=0.25, random_state=42, stratify=strat_tv)\n",
    "log(f'Train/Val/Test files: {len(Xtr_f)}/{len(Xva_f)}/{len(Xte_f)} | classes={len(classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37d98b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:59<00:00,  1.25it/s]\n",
      "100%|██████████| 300/300 [03:59<00:00,  1.25it/s]\n",
      "100%|██████████| 100/100 [01:18<00:00,  1.27it/s]\n",
      "100%|██████████| 100/100 [01:18<00:00,  1.27it/s]\n",
      "100%|██████████| 100/100 [01:16<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:51:23] INFO: Extracted segments -> train=3000, val=1000, test=1000\n",
      "[18:51:23] INFO: Saved processed arrays to /home/alepot55/Desktop/projects/naml_project/data/processed_indian\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction (mel-spectrograms) with padding/cropping to T_TARGET and robust decode fallback\n",
    "import numpy as np, librosa, subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_audio_librosa(fp: str, sr: int, duration: float):\n",
    "    \"\"\"Decode audio using librosa (soundfile/audioread).\"\"\"\n",
    "    y, _ = librosa.load(fp, sr=sr, mono=True, duration=duration, res_type='kaiser_fast')\n",
    "    return y\n",
    "\n",
    "\n",
    "def load_audio_ffmpeg(fp: str, sr: int, duration: float):\n",
    "    \"\"\"Decode audio via ffmpeg pipe to float32 PCM; returns np.ndarray or None.\n",
    "\n",
    "    Requires ffmpeg to be installed and available on PATH.\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-v\", \"error\", \"-i\", fp,\n",
    "        \"-ac\", \"1\", \"-ar\", str(sr)\n",
    "    ]\n",
    "    if duration and duration > 0:\n",
    "        cmd += [\"-t\", str(duration)]\n",
    "    cmd += [\"-f\", \"f32le\", \"pipe:1\"]\n",
    "    try:\n",
    "        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "        audio = np.frombuffer(proc.stdout, dtype=np.float32)\n",
    "        return audio\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_audio(fp: str, sr: int, duration: float):\n",
    "    \"\"\"Try librosa first, then ffmpeg fallback; raise if both fail.\"\"\"\n",
    "    try:\n",
    "        y = load_audio_librosa(fp, sr, duration)\n",
    "        if y is not None and y.size > 0:\n",
    "            return y\n",
    "    except Exception:\n",
    "        pass\n",
    "    y = load_audio_ffmpeg(fp, sr, duration)\n",
    "    if y is None or y.size == 0:\n",
    "        raise RuntimeError(f\"Failed to decode audio: {fp}\")\n",
    "    return y\n",
    "\n",
    "\n",
    "def extract_one(fp: str):\n",
    "    try:\n",
    "        y = load_audio(fp, SR, SEG_DUR * N_SEGMENTS)\n",
    "        seg_len = int(SR * SEG_DUR)\n",
    "        out = []\n",
    "        for s in range(N_SEGMENTS):\n",
    "            st, en = s * seg_len, s * seg_len + seg_len\n",
    "            if st >= len(y):\n",
    "                break\n",
    "            seg = y[st:en]\n",
    "            if len(seg) < seg_len:\n",
    "                seg = np.pad(seg, (0, seg_len - len(seg)))\n",
    "            mel = librosa.feature.melspectrogram(y=seg, sr=SR, n_mels=N_MELS, hop_length=HOP)\n",
    "            mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "            T = mel_db.shape[1]\n",
    "            if T > T_TARGET:\n",
    "                mel_db = mel_db[:, :T_TARGET]\n",
    "            elif T < T_TARGET:\n",
    "                mel_db = np.pad(mel_db, ((0, 0), (0, T_TARGET - T)))\n",
    "            out.append(mel_db)\n",
    "        return out\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "def extract_batch(file_list, y_list):\n",
    "    X_list, y_seg = [], []\n",
    "    for fp, y_lbl in tqdm(list(zip(file_list, y_list)), total=len(file_list)):\n",
    "        segs = extract_one(fp)\n",
    "        if len(segs) == 0:\n",
    "            continue\n",
    "        X_list.extend(segs)\n",
    "        y_seg.extend([y_lbl] * len(segs))\n",
    "    return X_list, np.asarray(y_seg, dtype=np.int64)\n",
    "\n",
    "\n",
    "Xtr_list, ytr_seg = extract_batch(Xtr_f, ytr)\n",
    "Xva_list, yva_seg = extract_batch(Xva_f, yva)\n",
    "Xte_list, yte_seg = extract_batch(Xte_f, yte)\n",
    "log(f\"Extracted segments -> train={len(Xtr_list)}, val={len(Xva_list)}, test={len(Xte_list)}\")\n",
    "\n",
    "\n",
    "def to_array(lst):\n",
    "    if len(lst) == 0:\n",
    "        return np.empty((0, N_MELS, T_TARGET, 1), dtype=np.float32)\n",
    "    return np.asarray(lst, dtype=np.float32)[..., None]\n",
    "\n",
    "\n",
    "Xtr, Xva, Xte = to_array(Xtr_list), to_array(Xva_list), to_array(Xte_list)\n",
    "\n",
    "# Fit scaler on train only\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "def scale_3d(X, fit=False):\n",
    "    if X.size == 0:\n",
    "        return X\n",
    "    sh = X.shape\n",
    "    Z = X.reshape(sh[0], -1)\n",
    "    Z = scaler.fit_transform(Z) if fit else scaler.transform(Z)\n",
    "    return Z.reshape(sh).astype(np.float32)\n",
    "\n",
    "\n",
    "if Xtr.shape[0] == 0:\n",
    "    n_files = len(Xtr_f)\n",
    "    log(f\"No training segments extracted from {n_files} training files.\", level=\"ERROR\")\n",
    "    log(\"Hints: ensure ffmpeg is installed and accessible, and RAW contains supported audio files (.wav, .mp3, .flac, .m4a).\", level=\"ERROR\")\n",
    "    raise ValueError(\"Training set is empty after feature extraction.\")\n",
    "\n",
    "Xtr = scale_3d(Xtr, fit=True)\n",
    "Xva = scale_3d(Xva)\n",
    "Xte = scale_3d(Xte)\n",
    "\n",
    "# Persist arrays and transformers\n",
    "np.save(PROCESSED / 'X_train.npy', Xtr)\n",
    "np.save(PROCESSED / 'y_train.npy', ytr_seg)\n",
    "np.save(PROCESSED / 'X_val.npy', Xva)\n",
    "np.save(PROCESSED / 'y_val.npy', yva_seg)\n",
    "np.save(PROCESSED / 'X_test.npy', Xte)\n",
    "np.save(PROCESSED / 'y_test.npy', yte_seg)\n",
    "import pickle\n",
    "with open(PROCESSED / 'label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "with open(PROCESSED / 'scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "log(f'Saved processed arrays to {PROCESSED}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
