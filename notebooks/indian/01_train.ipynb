{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a0f284",
   "metadata": {},
   "source": [
    "# 01 — Model Training on Indian Dataset (UNet_Audio_Classifier)\n",
    "\n",
    "Trains only `UNet_Audio_Classifier` on the Indian dataset with a clean, reproducible, and leak-free setup. Saves dataset-tagged artifacts in `models/` and `reports/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fd9d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:14:33] INFO: CFG: XLA=False | JIT=False | MP=True | CACHE_EVAL=True | GPU=True | DS_T=2 | BATCH=48 | AUG=True (F6,T12,N1) | TTA_SHIFT=0 | INIT_FROM_GTZAN=True\n"
     ]
    }
   ],
   "source": [
    "# Minimal setup & config (fast, reproducible)\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Tiny logger\n",
    "VERBOSE = os.environ.get('INDIAN_VERBOSE', '1') == '1'\n",
    "\n",
    "def log(msg: str, level: str = 'INFO'):\n",
    "    if not VERBOSE and level == 'INFO':\n",
    "        return\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {level}: {msg}\")\n",
    "\n",
    "# Core toggles only\n",
    "INDIAN_ENABLE_XLA      = os.environ.get('INDIAN_ENABLE_XLA', '0') == '1'\n",
    "INDIAN_JIT_COMPILE     = os.environ.get('INDIAN_JIT_COMPILE', '0') == '1'\n",
    "INDIAN_MIXED_PRECISION = os.environ.get('INDIAN_MIXED_PRECISION', '1') == '1'\n",
    "INDIAN_CACHE_EVAL      = os.environ.get('INDIAN_CACHE_EVAL', '1') == '1'\n",
    "\n",
    "# Device control (prefer GPU by default)\n",
    "INDIAN_TRAIN_ON_GPU    = os.environ.get('TRAIN_ON_GPU', '1') == '1'\n",
    "\n",
    "# Data/time controls\n",
    "INDIAN_TIME_DOWNSAMPLE = int(os.environ.get('INDIAN_TIME_DOWNSAMPLE', '2'))  # downsample for speed by default\n",
    "INDIAN_BATCH_SIZE      = int(os.environ.get('INFER_BATCH_SIZE', os.environ.get('INDIAN_BATCH_SIZE', '48')))\n",
    "\n",
    "# Augmentation (slightly softened defaults)\n",
    "INDIAN_SPEC_AUGMENT    = os.environ.get('INDIAN_SPEC_AUGMENT', '1') == '1'\n",
    "INDIAN_FREQ_MASK_PARAM = int(os.environ.get('INDIAN_FREQ_MASK_PARAM', '6'))\n",
    "INDIAN_TIME_MASK_PARAM = int(os.environ.get('INDIAN_TIME_MASK_PARAM', '12'))\n",
    "INDIAN_NUM_MASKS       = int(os.environ.get('INDIAN_NUM_MASKS', '1'))\n",
    "\n",
    "# Inference TTA (time shifts in frames; 0 disables TTA)\n",
    "INDIAN_TTA_SHIFTS      = int(os.environ.get('INDIAN_TTA_SHIFTS', '0'))\n",
    "\n",
    "# Transfer learning toggle\n",
    "INDIAN_INIT_FROM_GTZAN = os.environ.get('INDIAN_INIT_FROM_GTZAN', '1') == '1'\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "log(f\"CFG: XLA={INDIAN_ENABLE_XLA} | JIT={INDIAN_JIT_COMPILE} | MP={INDIAN_MIXED_PRECISION} | CACHE_EVAL={INDIAN_CACHE_EVAL} | \"\n",
    "    f\"GPU={INDIAN_TRAIN_ON_GPU} | DS_T={INDIAN_TIME_DOWNSAMPLE} | BATCH={INDIAN_BATCH_SIZE} | AUG={INDIAN_SPEC_AUGMENT} (F{INDIAN_FREQ_MASK_PARAM},T{INDIAN_TIME_MASK_PARAM},N{INDIAN_NUM_MASKS}) | \"\n",
    "    f\"TTA_SHIFT={INDIAN_TTA_SHIFTS} | INIT_FROM_GTZAN={INDIAN_INIT_FROM_GTZAN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe10bb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:14:33] WARN: Time downsample x2 -> train=(3000, 128, 64, 1), val=(1000, 128, 64, 1), test=(1000, 128, 64, 1)\n",
      "[17:14:33] INFO: Shapes: train=(3000, 128, 64, 1), val=(1000, 128, 64, 1), test=(1000, 128, 64, 1) | classes=5\n"
     ]
    }
   ],
   "source": [
    "# Load data and prepare environment (concise)\n",
    "import os, pickle\n",
    "import numpy as np, pandas as pd, tensorflow as tf, keras\n",
    "from keras import layers, models, callbacks\n",
    "from keras.utils import to_categorical\n",
    "from pathlib import Path\n",
    "\n",
    "# Device policy\n",
    "if not INDIAN_TRAIN_ON_GPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Optional global XLA\n",
    "try:\n",
    "    if INDIAN_ENABLE_XLA:\n",
    "        tf.config.optimizer.set_jit(True)\n",
    "        log('XLA JIT enabled')\n",
    "except Exception as e:\n",
    "    log(f'XLA enable failed: {e}', level='WARN')\n",
    "\n",
    "# Mixed precision on GPU\n",
    "try:\n",
    "    if INDIAN_MIXED_PRECISION and os.environ.get('CUDA_VISIBLE_DEVICES', '') != '-1':\n",
    "        from keras.mixed_precision import set_global_policy\n",
    "        set_global_policy('mixed_float16')\n",
    "        log('Mixed precision: float16 compute / float32 vars')\n",
    "except Exception as e:\n",
    "    log(f'MP not enabled: {e}', level='WARN')\n",
    "\n",
    "# Reproducibility & GPU safety\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "try:\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except Exception as e:\n",
    "    log(f'TF GPU setup: {e}', level='WARN')\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve().parents[1]\n",
    "PROCESSED = PROJECT_ROOT/'data'/'processed_indian'\n",
    "MODELS = PROJECT_ROOT/'models'; MODELS.mkdir(exist_ok=True)\n",
    "REPORTS = PROJECT_ROOT/'reports'; REPORTS.mkdir(exist_ok=True)\n",
    "\n",
    "# Data (memmap to limit RAM)\n",
    "X_train = np.load(PROCESSED/'X_train.npy', mmap_mode='r'); y_train = np.load(PROCESSED/'y_train.npy', mmap_mode='r')\n",
    "X_val   = np.load(PROCESSED/'X_val.npy',   mmap_mode='r'); y_val   = np.load(PROCESSED/'y_val.npy',   mmap_mode='r')\n",
    "X_test  = np.load(PROCESSED/'X_test.npy',  mmap_mode='r'); y_test  = np.load(PROCESSED/'y_test.npy',  mmap_mode='r')\n",
    "\n",
    "# Ensure channel dim\n",
    "if X_train.ndim == 3: X_train = X_train[..., None]\n",
    "if X_val.ndim   == 3: X_val   = X_val[..., None]\n",
    "if X_test.ndim  == 3: X_test  = X_test[..., None]\n",
    "\n",
    "# Optional time downsample\n",
    "if INDIAN_TIME_DOWNSAMPLE and INDIAN_TIME_DOWNSAMPLE > 1:\n",
    "    s = int(INDIAN_TIME_DOWNSAMPLE)\n",
    "    X_train, X_val, X_test = X_train[:, :, ::s, :], X_val[:, :, ::s, :], X_test[:, :, ::s, :]\n",
    "    log(f'Time downsample x{s} -> train={X_train.shape}, val={X_val.shape}, test={X_test.shape}', level='WARN')\n",
    "\n",
    "# Align time (crop/pad to min T)\n",
    "T_min = int(min(X_train.shape[2], X_val.shape[2], X_test.shape[2]))\n",
    "if not (X_train.shape[2] == X_val.shape[2] == X_test.shape[2]):\n",
    "    def _pad_or_crop_time(X, T):\n",
    "        cur = X.shape[2]\n",
    "        if cur == T: return X\n",
    "        if cur > T:  return X[:, :, :T, :]\n",
    "        pad = ((0,0),(0,0),(0,T-cur),(0,0))\n",
    "        return np.pad(np.asarray(X), pad, mode='constant')\n",
    "    X_train, X_val, X_test = (\n",
    "        _pad_or_crop_time(X_train, T_min),\n",
    "        _pad_or_crop_time(X_val,   T_min),\n",
    "        _pad_or_crop_time(X_test,  T_min),\n",
    "    )\n",
    "\n",
    "with open(PROCESSED/'label_encoder.pkl','rb') as f: le = pickle.load(f)\n",
    "num_classes = len(le.classes_)\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_val_cat   = to_categorical(y_val,   num_classes)\n",
    "y_test_cat  = to_categorical(y_test,  num_classes)\n",
    "\n",
    "log(f'Shapes: train={X_train.shape}, val={X_val.shape}, test={X_test.shape} | classes={num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3acbd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized SpecAugment and tf.data pipeline (lean)\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def batch_spec_augment(mels, freq_mask_param=INDIAN_FREQ_MASK_PARAM, time_mask_param=INDIAN_TIME_MASK_PARAM, num_masks=INDIAN_NUM_MASKS):\n",
    "    \"\"\"Batch SpecAugment, operates on [B, M, T, 1].\"\"\"\n",
    "    B = tf.shape(mels)[0]\n",
    "    M = tf.shape(mels)[1]\n",
    "    T = tf.shape(mels)[2]\n",
    "    x = mels\n",
    "    for _ in range(num_masks):\n",
    "        if freq_mask_param > 0:\n",
    "            f = tf.random.uniform([B, 1, 1, 1], 0, freq_mask_param + 1, dtype=tf.int32)\n",
    "            f = tf.minimum(f, M)\n",
    "            f0_max = tf.maximum(M - f, 1)\n",
    "            f0 = tf.cast(tf.floor(tf.random.uniform([B, 1, 1, 1]) * tf.cast(f0_max, tf.float32)), tf.int32)\n",
    "            freq_idx = tf.reshape(tf.range(M, dtype=tf.int32), [1, M, 1, 1])\n",
    "            freq_mask = (freq_idx >= f0) & (freq_idx < (f0 + f))\n",
    "            freq_mask = tf.broadcast_to(freq_mask, [B, M, T, 1])\n",
    "            x = tf.where(freq_mask, tf.zeros([], dtype=x.dtype), x)\n",
    "        if time_mask_param > 0:\n",
    "            t = tf.random.uniform([B, 1, 1, 1], 0, time_mask_param + 1, dtype=tf.int32)\n",
    "            t = tf.minimum(t, T)\n",
    "            t0_max = tf.maximum(T - t, 1)\n",
    "            t0 = tf.cast(tf.floor(tf.random.uniform([B, 1, 1, 1]) * tf.cast(t0_max, tf.float32)), tf.int32)\n",
    "            time_idx = tf.reshape(tf.range(T, dtype=tf.int32), [1, 1, T, 1])\n",
    "            time_mask = (time_idx >= t0) & (time_idx < (t0 + t))\n",
    "            time_mask = tf.broadcast_to(time_mask, [B, M, T, 1])\n",
    "            x = tf.where(time_mask, tf.zeros([], dtype=x.dtype), x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ds_with_optional_aug(X, y_cat, batch_size, training: bool):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y_cat))\n",
    "    if training:\n",
    "        ds = ds.shuffle(min(10000, len(X)), seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
    "    # Drop remainder only on training\n",
    "    ds = ds.batch(batch_size, drop_remainder=training)\n",
    "    if training and INDIAN_SPEC_AUGMENT:\n",
    "        def _aug(mel, y):\n",
    "            mel = batch_spec_augment(mel)\n",
    "            return mel, y\n",
    "        ds = ds.map(_aug, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    if not training and INDIAN_CACHE_EVAL:\n",
    "        ds = ds.cache()\n",
    "    return ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "def apply_tta_time_shifts(X, shifts: int):\n",
    "    \"\"\"Return a list of arrays with circular time shifts for simple TTA.\n",
    "    shifts=0 disables TTA.\n",
    "    \"\"\"\n",
    "    if not shifts or shifts <= 0:\n",
    "        return [X]\n",
    "    T = X.shape[2]\n",
    "    step = max(1, T // (shifts + 1))\n",
    "    variants = [X]\n",
    "    for s in range(1, shifts + 1):\n",
    "        shift = (s * step) % T\n",
    "        variants.append(tf.roll(X, shift=shift, axis=2).numpy())\n",
    "    return variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29b46a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 compatible layer(s) from UNet_Audio_Classifier_best_WITH_AUG.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UNet_Audio_Classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"UNet_Audio_Classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_prelu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_prelu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_prelu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_prelu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_prelu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_prelu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">294,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_prelu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_prelu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gap (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_prelu1 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m9,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_prelu2 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_prelu1 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_prelu2 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_prelu1 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_prelu2 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │       \u001b[38;5;34m294,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_prelu1 (\u001b[38;5;33mPReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │       \u001b[38;5;34m589,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_prelu2 (\u001b[38;5;33mPReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gap (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m1,285\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,176,805</span> (4.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,176,805\u001b[0m (4.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,174,885</span> (4.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,174,885\u001b[0m (4.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 600ms/step - accuracy: 0.3801 - loss: 1.5371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alepot55/Desktop/projects/naml_project/venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 655ms/step - accuracy: 0.4610 - loss: 1.3614 - val_accuracy: 0.5550 - val_loss: 1.1919\n",
      "Epoch 2/80\n",
      "Epoch 2/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 635ms/step - accuracy: 0.6599 - loss: 0.8870 - val_accuracy: 0.4070 - val_loss: 1.9885\n",
      "Epoch 3/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 658ms/step - accuracy: 0.7644 - loss: 0.6645 - val_accuracy: 0.5480 - val_loss: 1.2322\n",
      "Epoch 4/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 659ms/step - accuracy: 0.8249 - loss: 0.5050 - val_accuracy: 0.5240 - val_loss: 1.9763\n",
      "Epoch 5/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 696ms/step - accuracy: 0.8740 - loss: 0.3967 - val_accuracy: 0.5520 - val_loss: 1.6520\n",
      "Epoch 6/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 665ms/step - accuracy: 0.9113 - loss: 0.3109 - val_accuracy: 0.5700 - val_loss: 1.8164\n",
      "Epoch 7/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 679ms/step - accuracy: 0.9446 - loss: 0.2445 - val_accuracy: 0.5930 - val_loss: 1.3587\n",
      "Epoch 8/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 668ms/step - accuracy: 0.9567 - loss: 0.2039 - val_accuracy: 0.5910 - val_loss: 1.6757\n",
      "Epoch 9/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 700ms/step - accuracy: 0.9718 - loss: 0.1700 - val_accuracy: 0.6350 - val_loss: 1.3570\n",
      "Epoch 10/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 693ms/step - accuracy: 0.9775 - loss: 0.1520 - val_accuracy: 0.6920 - val_loss: 1.4438\n",
      "Epoch 11/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 679ms/step - accuracy: 0.9778 - loss: 0.1443 - val_accuracy: 0.6230 - val_loss: 2.0033\n",
      "Epoch 12/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 670ms/step - accuracy: 0.9802 - loss: 0.1380 - val_accuracy: 0.6230 - val_loss: 1.6654\n",
      "Epoch 13/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 672ms/step - accuracy: 0.9876 - loss: 0.1242 - val_accuracy: 0.6550 - val_loss: 1.9183\n",
      "Epoch 14/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 682ms/step - accuracy: 0.9872 - loss: 0.1232 - val_accuracy: 0.6340 - val_loss: 1.4549\n",
      "Epoch 15/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 678ms/step - accuracy: 0.9923 - loss: 0.1115 - val_accuracy: 0.5790 - val_loss: 2.1865\n",
      "Epoch 16/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 679ms/step - accuracy: 0.9929 - loss: 0.1056 - val_accuracy: 0.7050 - val_loss: 1.1152\n",
      "Epoch 17/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 672ms/step - accuracy: 0.9889 - loss: 0.1095 - val_accuracy: 0.6930 - val_loss: 1.5677\n",
      "Epoch 18/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 704ms/step - accuracy: 0.9926 - loss: 0.1069 - val_accuracy: 0.5040 - val_loss: 3.0422\n",
      "Epoch 19/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 681ms/step - accuracy: 0.9950 - loss: 0.0989 - val_accuracy: 0.6800 - val_loss: 1.2704\n",
      "Epoch 20/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 738ms/step - accuracy: 0.9973 - loss: 0.0944 - val_accuracy: 0.7110 - val_loss: 1.2221\n",
      "Epoch 21/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 713ms/step - accuracy: 0.9983 - loss: 0.0934 - val_accuracy: 0.6520 - val_loss: 1.7608\n",
      "Epoch 22/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 709ms/step - accuracy: 0.9943 - loss: 0.1019 - val_accuracy: 0.6550 - val_loss: 1.7086\n",
      "Epoch 23/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 714ms/step - accuracy: 0.9963 - loss: 0.0969 - val_accuracy: 0.5580 - val_loss: 2.7032\n",
      "Epoch 24/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 930ms/step - accuracy: 0.9946 - loss: 0.0973 - val_accuracy: 0.6180 - val_loss: 1.7801\n",
      "Epoch 25/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 695ms/step - accuracy: 0.9956 - loss: 0.0940 - val_accuracy: 0.6720 - val_loss: 1.5320\n",
      "Epoch 26/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 740ms/step - accuracy: 0.9966 - loss: 0.0928 - val_accuracy: 0.6790 - val_loss: 1.1750\n",
      "Epoch 27/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 696ms/step - accuracy: 0.9970 - loss: 0.0922 - val_accuracy: 0.6300 - val_loss: 1.6120\n",
      "Epoch 28/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 688ms/step - accuracy: 0.9983 - loss: 0.0871 - val_accuracy: 0.4840 - val_loss: 3.4775\n",
      "Epoch 29/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 695ms/step - accuracy: 0.9960 - loss: 0.0907 - val_accuracy: 0.6230 - val_loss: 1.6553\n",
      "Epoch 30/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 682ms/step - accuracy: 0.9976 - loss: 0.0901 - val_accuracy: 0.6460 - val_loss: 1.8180\n",
      "Epoch 31/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 677ms/step - accuracy: 0.9966 - loss: 0.0894 - val_accuracy: 0.6960 - val_loss: 1.4682\n",
      "Epoch 32/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 684ms/step - accuracy: 0.9970 - loss: 0.0880 - val_accuracy: 0.7210 - val_loss: 1.2234\n",
      "Epoch 33/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 685ms/step - accuracy: 0.9990 - loss: 0.0858 - val_accuracy: 0.6770 - val_loss: 1.4534\n",
      "Epoch 34/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 682ms/step - accuracy: 0.9970 - loss: 0.0895 - val_accuracy: 0.7100 - val_loss: 1.1826\n",
      "Epoch 35/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 684ms/step - accuracy: 0.9990 - loss: 0.0837 - val_accuracy: 0.6920 - val_loss: 1.0789\n",
      "Epoch 36/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 682ms/step - accuracy: 0.9997 - loss: 0.0810 - val_accuracy: 0.6540 - val_loss: 1.4806\n",
      "Epoch 37/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 671ms/step - accuracy: 0.9993 - loss: 0.0827 - val_accuracy: 0.7200 - val_loss: 1.0766\n",
      "Epoch 38/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 682ms/step - accuracy: 0.9997 - loss: 0.0801 - val_accuracy: 0.7100 - val_loss: 1.2350\n",
      "Epoch 39/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 670ms/step - accuracy: 0.9990 - loss: 0.0813 - val_accuracy: 0.7070 - val_loss: 1.2065\n",
      "Epoch 40/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 671ms/step - accuracy: 0.9980 - loss: 0.0820 - val_accuracy: 0.7580 - val_loss: 0.9144\n",
      "Epoch 41/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 679ms/step - accuracy: 0.9993 - loss: 0.0810 - val_accuracy: 0.7010 - val_loss: 1.2510\n",
      "Epoch 42/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 676ms/step - accuracy: 0.9990 - loss: 0.0808 - val_accuracy: 0.7170 - val_loss: 1.0692\n",
      "Epoch 43/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 673ms/step - accuracy: 0.9987 - loss: 0.0803 - val_accuracy: 0.7390 - val_loss: 0.9548\n",
      "Epoch 44/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 676ms/step - accuracy: 0.9993 - loss: 0.0812 - val_accuracy: 0.7150 - val_loss: 1.2575\n",
      "Epoch 45/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 682ms/step - accuracy: 0.9990 - loss: 0.0806 - val_accuracy: 0.7420 - val_loss: 1.0425\n",
      "Epoch 46/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 683ms/step - accuracy: 1.0000 - loss: 0.0762 - val_accuracy: 0.7510 - val_loss: 0.9276\n",
      "Epoch 47/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 683ms/step - accuracy: 0.9987 - loss: 0.0778 - val_accuracy: 0.7230 - val_loss: 1.0634\n",
      "Epoch 48/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 684ms/step - accuracy: 0.9983 - loss: 0.0790 - val_accuracy: 0.7040 - val_loss: 1.2585\n",
      "Epoch 49/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 685ms/step - accuracy: 0.9993 - loss: 0.0781 - val_accuracy: 0.7620 - val_loss: 0.8576\n",
      "Epoch 50/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 683ms/step - accuracy: 0.9990 - loss: 0.0775 - val_accuracy: 0.7400 - val_loss: 0.9281\n",
      "Epoch 51/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 688ms/step - accuracy: 0.9993 - loss: 0.0764 - val_accuracy: 0.7100 - val_loss: 1.1360\n",
      "Epoch 52/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 688ms/step - accuracy: 0.9997 - loss: 0.0759 - val_accuracy: 0.7350 - val_loss: 0.9299\n",
      "Epoch 53/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 679ms/step - accuracy: 0.9993 - loss: 0.0767 - val_accuracy: 0.7320 - val_loss: 0.9281\n",
      "Epoch 54/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 676ms/step - accuracy: 0.9993 - loss: 0.0767 - val_accuracy: 0.7370 - val_loss: 0.9339\n",
      "Epoch 55/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 673ms/step - accuracy: 0.9980 - loss: 0.0775 - val_accuracy: 0.7180 - val_loss: 0.9457\n",
      "Epoch 56/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 683ms/step - accuracy: 0.9997 - loss: 0.0765 - val_accuracy: 0.7440 - val_loss: 0.8729\n",
      "Epoch 57/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 665ms/step - accuracy: 1.0000 - loss: 0.0751 - val_accuracy: 0.7540 - val_loss: 0.8862\n",
      "Epoch 58/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 664ms/step - accuracy: 0.9993 - loss: 0.0762 - val_accuracy: 0.7560 - val_loss: 0.8680\n",
      "Epoch 59/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 677ms/step - accuracy: 0.9993 - loss: 0.0756 - val_accuracy: 0.7520 - val_loss: 0.8459\n",
      "Epoch 60/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 682ms/step - accuracy: 0.9997 - loss: 0.0742 - val_accuracy: 0.7250 - val_loss: 0.9193\n",
      "Epoch 61/80\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 669ms/step - accuracy: 0.9990 - loss: 0.0763 - val_accuracy: 0.7590 - val_loss: 0.8247\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step\n",
      "INDIAN Test Accuracy: 0.7220\n",
      "Saved: /home/alepot55/Desktop/projects/naml_project/reports/training_summary_INDIAN.csv\n"
     ]
    }
   ],
   "source": [
    "# UNet architecture aligned with GTZAN tournament (model only)\n",
    "from keras import layers, models, callbacks\n",
    "import keras, numpy as np, pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.optimizers.schedules import CosineDecay\n",
    "from typing import cast\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _unet_encoder_block(input_tensor, filters, pool=True, name_prefix=\"\"):\n",
    "    x = layers.Conv2D(filters, 3, padding='same', use_bias=False, name=f'{name_prefix}_conv1')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=f'{name_prefix}_bn1')(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2], name=f'{name_prefix}_prelu1')(x)\n",
    "    x = layers.Conv2D(filters, 3, padding='same', use_bias=False, name=f'{name_prefix}_conv2')(x)\n",
    "    x = layers.BatchNormalization(name=f'{name_prefix}_bn2')(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2], name=f'{name_prefix}_prelu2')(x)\n",
    "    skip_connection = x\n",
    "    if pool:\n",
    "        pool_output = layers.MaxPooling2D(2, name=f'{name_prefix}_pool')(x)\n",
    "        return pool_output, skip_connection\n",
    "    else:\n",
    "        return x, skip_connection\n",
    "\n",
    "\n",
    "def build_unet_audio_classifier(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Encoder path (mirrors GTZAN tournament UNet)\n",
    "    p1, s1 = _unet_encoder_block(inputs, 32, name_prefix=\"enc1\")\n",
    "    p2, s2 = _unet_encoder_block(p1, 64, name_prefix=\"enc2\")\n",
    "    p3, s3 = _unet_encoder_block(p2, 128, name_prefix=\"enc3\")\n",
    "    # Bottleneck (pool=False)\n",
    "    bottleneck, _ = _unet_encoder_block(p3, 256, pool=False, name_prefix=\"bneck\")\n",
    "    # Classification head (slightly stronger regularization)\n",
    "    x = layers.GlobalAveragePooling2D(name=\"gap\")(bottleneck)\n",
    "    x = layers.Dropout(float(os.environ.get('INDIAN_DROPOUT', '0.6')))(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    return models.Model(inputs=inputs, outputs=outputs, name='UNet_Audio_Classifier')\n",
    "\n",
    "\n",
    "def try_load_backbone_from_gtzan(model, models_dir: Path) -> None:\n",
    "    if not INDIAN_INIT_FROM_GTZAN:\n",
    "        return\n",
    "    for name in ['UNet_Audio_Classifier_best_WITH_AUG.keras', 'UNet_Audio_Classifier_best_NO_AUG.keras']:\n",
    "        ckpt = (models_dir / name)\n",
    "        if ckpt.exists():\n",
    "            try:\n",
    "                src = keras.models.load_model(ckpt.as_posix(), compile=False)\n",
    "                loaded = 0\n",
    "                for layer in model.layers:\n",
    "                    if layer.name == 'dense' or layer.name == 'logits':\n",
    "                        continue\n",
    "                    try:\n",
    "                        src_layer = src.get_layer(layer.name)\n",
    "                        if src_layer is not None and len(layer.get_weights()) == len(src_layer.get_weights()):\n",
    "                            tgt_w = layer.get_weights(); src_w = src_layer.get_weights()\n",
    "                            if all(ti.shape == si.shape for ti, si in zip(tgt_w, src_w)):\n",
    "                                layer.set_weights(src_w); loaded += 1\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                print(f'Loaded {loaded} compatible layer(s) from {ckpt.name}')\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print('Backbone init failed for', ckpt.name, '→', e)\n",
    "    print('No compatible GTZAN checkpoint found for backbone init.')\n",
    "\n",
    "# Hyperparameters (tuned)\n",
    "EPOCHS = int(os.environ.get('INDIAN_EPOCHS', 80))  # allow a bit more headroom\n",
    "BATCH  = INDIAN_BATCH_SIZE\n",
    "LABEL_SMOOTH = float(os.environ.get('INDIAN_LABEL_SMOOTH', 0.01))  # slightly less smoothing\n",
    "LR = float(os.environ.get('INDIAN_LR', 4e-4))   # a touch lower\n",
    "WEIGHT_DECAY = float(os.environ.get('INDIAN_WEIGHT_DECAY', 1e-5))\n",
    "\n",
    "# Input shape\n",
    "input_shape = tuple(int(d) for d in X_train.shape[1:])\n",
    "\n",
    "# Data pipelines\n",
    "train_ds = ds_with_optional_aug(X_train, y_train_cat, BATCH, training=True)\n",
    "val_ds   = ds_with_optional_aug(X_val,   y_val_cat,   BATCH, training=False)\n",
    "test_ds  = ds_with_optional_aug(X_test,  y_test_cat,  BATCH, training=False)\n",
    "\n",
    "# Steps (explicit for stable progress)\n",
    "train_steps = int(np.ceil(X_train.shape[0] / BATCH))\n",
    "val_steps   = int(np.ceil(X_val.shape[0]   / BATCH))\n",
    "\n",
    "# Learning rate schedule (incompatible with ReduceLROnPlateau)\n",
    "after_total_steps = max(1, train_steps * max(1, EPOCHS))\n",
    "lr_schedule = CosineDecay(initial_learning_rate=LR, decay_steps=after_total_steps)\n",
    "\n",
    "# Build & compile model (UNet + optional GTZAN init)\n",
    "model = build_unet_audio_classifier(input_shape, num_classes)\n",
    "try_load_backbone_from_gtzan(model, MODELS)\n",
    "\n",
    "opt = (\n",
    "    keras.optimizers.AdamW(\n",
    "        learning_rate=cast(float, lr_schedule),\n",
    "        weight_decay=WEIGHT_DECAY, clipnorm=1.0\n",
    "    )\n",
    "    if WEIGHT_DECAY and WEIGHT_DECAY > 0 else\n",
    "    keras.optimizers.Adam(learning_rate=cast(float, lr_schedule), clipnorm=1.0)\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTH),\n",
    "    metrics=['accuracy'],\n",
    "    jit_compile=INDIAN_JIT_COMPILE,\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Class weights\n",
    "classes_idx = np.arange(num_classes)\n",
    "class_weights_vec = compute_class_weight('balanced', classes=classes_idx, y=np.asarray(y_train))\n",
    "CLASS_WEIGHT = {int(i): float(w) for i, w in zip(classes_idx, class_weights_vec)}\n",
    "\n",
    "# Callbacks (Remove ReduceLROnPlateau since a schedule is used)\n",
    "ckpt_path = MODELS/'UNet_Audio_Classifier_best_INDIAN.keras'\n",
    "cb = [\n",
    "    callbacks.ModelCheckpoint(ckpt_path, monitor='val_accuracy', save_best_only=True),\n",
    "    callbacks.EarlyStopping(monitor='val_accuracy', patience=12, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=cb,\n",
    "    class_weight=CLASS_WEIGHT,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "# Evaluate/predict on full arrays to avoid dropping last batch\n",
    "from sklearn.metrics import accuracy_score\n",
    "if INDIAN_TTA_SHIFTS > 0:\n",
    "    preds = []\n",
    "    for Xv in apply_tta_time_shifts(X_test, INDIAN_TTA_SHIFTS):\n",
    "        preds.append(model.predict(Xv, batch_size=BATCH))\n",
    "    test_pred = np.mean(preds, axis=0)\n",
    "else:\n",
    "    test_pred = model.predict(X_test, batch_size=BATCH)\n",
    "print(f'INDIAN Test Accuracy: {accuracy_score(np.argmax(y_test_cat,1), np.argmax(test_pred,1)):.4f}')\n",
    "\n",
    "# Save summary\n",
    "pd.DataFrame([{ \n",
    "    'Model':'UNet_Audio_Classifier', 'Dataset':'INDIAN',\n",
    "    'Best_Val_Accuracy': float(np.max(history.history.get('val_accuracy', [0]))),\n",
    "    'Test_Accuracy': float(accuracy_score(np.argmax(y_test_cat,1), np.argmax(test_pred,1))),\n",
    "    'Epochs_Run': int(len(history.history.get('val_accuracy', [])))\n",
    "}]).to_csv(REPORTS/'training_summary_INDIAN.csv', index=False)\n",
    "print(f'Saved: {REPORTS/\"training_summary_INDIAN.csv\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3442bc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step\n",
      "Saved VAL/TEST reports and confusion matrices to /home/alepot55/Desktop/projects/naml_project/reports\n"
     ]
    }
   ],
   "source": [
    "# Metrics: classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns, matplotlib.pyplot as plt, numpy as np, pandas as pd\n",
    "\n",
    "# Predict (full arrays)\n",
    "y_val_pred = model.predict(X_val, batch_size=BATCH)\n",
    "y_test_pred = model.predict(X_test, batch_size=BATCH)\n",
    "\n",
    "# VAL report/CM\n",
    "val_true_idx = np.argmax(y_val_cat, axis=1)\n",
    "val_pred_idx = np.argmax(y_val_pred, axis=1)\n",
    "val_report = classification_report(val_true_idx, val_pred_idx, target_names=list(le.classes_), zero_division=0)\n",
    "with open(REPORTS/'classification_report_UNet_Audio_Classifier_INDIAN_VAL.txt', 'w') as f:\n",
    "    f.write(str(val_report))\n",
    "cm_val = confusion_matrix(val_true_idx, val_pred_idx)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', xticklabels=list(le.classes_), yticklabels=list(le.classes_))\n",
    "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix — UNet (INDIAN) VAL')\n",
    "plt.tight_layout(); plt.savefig(REPORTS/'confusion_matrix_UNet_Audio_Classifier_INDIAN_VAL.png'); plt.close()\n",
    "\n",
    "# TEST report/CM\n",
    "test_true_idx = np.argmax(y_test_cat, axis=1)\n",
    "test_pred_idx = np.argmax(y_test_pred, axis=1)\n",
    "report = classification_report(test_true_idx, test_pred_idx, target_names=list(le.classes_), zero_division=0)\n",
    "with open(REPORTS/'classification_report_UNet_Audio_Classifier_INDIAN.txt', 'w') as f:\n",
    "    f.write(str(report))\n",
    "cm = confusion_matrix(test_true_idx, test_pred_idx)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=list(le.classes_), yticklabels=list(le.classes_))\n",
    "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix — UNet (INDIAN) TEST')\n",
    "plt.tight_layout(); plt.savefig(REPORTS/'confusion_matrix_UNet_Audio_Classifier_INDIAN.png'); plt.close()\n",
    "\n",
    "print('Saved VAL/TEST reports and confusion matrices to', REPORTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
