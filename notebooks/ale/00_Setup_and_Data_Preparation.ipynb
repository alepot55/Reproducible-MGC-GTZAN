{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a4fd43",
   "metadata": {},
   "source": [
    "# Notebook 00: GTZAN Data Pre-processing and Augmentation\n",
    "\n",
    "**Project:** Music Genre Classification on GTZAN  \n",
    "**Author:** Alessandro Potenza & Camilla Sed  \n",
    "**Course:** Numerical Analysis for Machine Learning, Politecnico di Milano\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook serves as the foundational step of our entire project. Its sole responsibility is to load the raw GTZAN audio files and transform them into a clean, augmented, and robust dataset suitable for training deep learning models.\n",
    "\n",
    "The pipeline implemented here is critically designed to **prevent data leakage**, a common flaw in MGC research that leads to inflated and unreliable results.\n",
    "\n",
    "### Key Steps Performed:\n",
    "\n",
    "1.  **Load File Paths**: Scan the GTZAN directory to get a list of all audio files and their corresponding genre labels.\n",
    "2.  **Strategic Data Splitting**: Split the _file paths_ into training (60%), validation (20%), and test (20%) sets. This is the **most critical step** to ensure data integrity.\n",
    "3.  **Segmentation (Chunking)**: Augment the dataset by slicing each 30-second audio clip into 10 smaller, 3-second segments. This increases our dataset size tenfold.\n",
    "4.  **Feature Extraction**: Convert each audio segment into a Mel-spectrogram, transforming the audio classification problem into an image classification task.\n",
    "5.  **Standardization**: Normalize the spectrograms by fitting a `StandardScaler` **only on the training data** and then applying it to all sets.\n",
    "6.  **Save Artifacts**: Save the final NumPy arrays (`X_train`, `y_train`, etc.) and the fitted `LabelEncoder` and `StandardScaler` objects for use in subsequent training notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb25ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 1: Setup, Imports, and Global Configuration\n",
    "\n",
    "This cell handles the initial setup of our environment. We import all necessary libraries and define global constants for file paths and the random state to ensure our experiments are fully reproducible. An output directory for the processed data is also created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487a3d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment setup complete. Data paths configured.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 1: SETUP, IMPORTS, AND GLOBAL CONFIGURATION\n",
    "# ===================================================================\n",
    "# This cell handles the initial setup of our environment. We import general\n",
    "# libraries and define global constants for file paths and reproducibility.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- Define Project Paths ---\n",
    "# Assumes this notebook is in a 'notebooks' directory, one level down from the project root.\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Path to the raw data destination\n",
    "GTZAN_ROOT_PATH = os.path.join(PROJECT_ROOT, 'data', 'gtzan')\n",
    "# Path to the specific folder containing genre subdirectories\n",
    "DATA_PATH = os.path.join(GTZAN_ROOT_PATH, 'genres')\n",
    "# Path for saving processed numpy arrays\n",
    "PROCESSED_DATA_PATH = os.path.join(PROJECT_ROOT, 'data', 'processed')\n",
    "\n",
    "# --- Global Constants for Reproducibility ---\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# --- Create Output Directory ---\n",
    "os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Environment setup complete. Data paths configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ccb541",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: Kaggle Setup and Automatic Dataset Download\n",
    "This cell handles the configuration of Kaggle credentials and automates the download of the GTZAN dataset.\n",
    "\n",
    "### Logic:\n",
    "1.  **Check Credentials**: It first verifies that the `kaggle/kaggle.json` file exists in the project root. If not, it halts execution with clear instructions for the user.\n",
    "2.  **Set Environment**: It points the Kaggle API to our project-specific credential file.\n",
    "3.  **Check for Data**: It then checks if the GTZAN `genres` directory already exists.\n",
    "4.  **Download if Missing**: If the data is not found, it uses the Kaggle API to download and unzip the dataset automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cccf831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Configuring Kaggle API environment...\n",
      "âœ… Kaggle credentials configured successfully.\n",
      "\n",
      "ðŸŽµ Checking for GTZAN dataset...\n",
      "âœ… Dataset already found at: /home/alepot55/Desktop/projects/naml_project/data/gtzan/genres\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 2: KAGGLE SETUP AND DOWNLOAD (WITH PROGRESS BAR)\n",
    "# ===================================================================\n",
    "# This cell ensures the GTZAN dataset is available locally. It uses a\n",
    "# two-step process to provide a real-time progress bar during extraction.\n",
    "\n",
    "# --- 1. CONFIGURE KAGGLE API ENVIRONMENT ---\n",
    "print(\"ðŸ”§ Configuring Kaggle API environment...\")\n",
    "KAGGLE_DIR = os.path.join(PROJECT_ROOT, 'kaggle')\n",
    "KAGGLE_JSON_PATH = os.path.join(KAGGLE_DIR, 'kaggle.json')\n",
    "\n",
    "# Check if credentials file exists\n",
    "if not os.path.exists(KAGGLE_JSON_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"âŒ Kaggle API credentials not found at: {KAGGLE_JSON_PATH}\\n\"\n",
    "        \"Please follow the instructions in the README to set it up.\"\n",
    "    )\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = KAGGLE_DIR\n",
    "if os.name != 'nt':\n",
    "    os.chmod(KAGGLE_JSON_PATH, 0o600)\n",
    "\n",
    "# --- 2. RELOAD KAGGLE LIBRARY AND DOWNLOAD DATASET ---\n",
    "try:\n",
    "    import kaggle\n",
    "    import zipfile\n",
    "    import importlib\n",
    "    importlib.reload(kaggle) # Force reload to read the new environment config\n",
    "    print(\"âœ… Kaggle credentials configured successfully.\")\n",
    "except Exception as e:\n",
    "    raise ImportError(f\"Could not import or reload 'kaggle' package. Error: {e}\")\n",
    "\n",
    "KAGGLE_DATASET_ID = 'carlthome/gtzan-genre-collection'\n",
    "print(\"\\nðŸŽµ Checking for GTZAN dataset...\")\n",
    "\n",
    "if os.path.isdir(DATA_PATH) and len(os.listdir(DATA_PATH)) > 0:\n",
    "    print(f\"âœ… Dataset already found at: {DATA_PATH}\")\n",
    "else:\n",
    "    print(\"Dataset not found. Proceeding with download and extraction.\")\n",
    "    try:\n",
    "        os.makedirs(GTZAN_ROOT_PATH, exist_ok=True)\n",
    "        \n",
    "        # --- STEP 1: DOWNLOAD THE ZIP FILE ONLY ---\n",
    "        print(\"Downloading dataset from Kaggle (this may take a moment)...\")\n",
    "        kaggle.api.dataset_download_files(\n",
    "            KAGGLE_DATASET_ID,\n",
    "            path=GTZAN_ROOT_PATH,\n",
    "            unzip=False, # Set to False to handle extraction manually\n",
    "            quiet=True # We'll provide our own progress for extraction\n",
    "        )\n",
    "        print(\"âœ… Download complete.\")\n",
    "\n",
    "        # --- STEP 2: EXTRACT WITH A TQDM PROGRESS BAR ---\n",
    "        # Construct the path to the downloaded zip file\n",
    "        zip_filename = KAGGLE_DATASET_ID.split('/')[1] + '.zip'\n",
    "        zip_path = os.path.join(GTZAN_ROOT_PATH, zip_filename)\n",
    "        \n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # Get the list of files to show progress against the number of files\n",
    "            file_list = zip_ref.infolist()\n",
    "            \n",
    "            # Wrap the extraction in a tqdm loop\n",
    "            for file in tqdm(file_list, desc=\"Extracting dataset\"):\n",
    "                zip_ref.extract(file, path=GTZAN_ROOT_PATH)\n",
    "        \n",
    "        # --- STEP 3: CLEANUP ---\n",
    "        # Remove the zip file after successful extraction\n",
    "        os.remove(zip_path)\n",
    "        print(\"âœ… Extraction complete and zip file removed.\")\n",
    "        \n",
    "        if not os.path.isdir(DATA_PATH):\n",
    "             raise FileNotFoundError(f\"Extraction failed: 'genres' directory not found.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ An error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24e630e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 3: The Data Loading and Processing Class\n",
    "\n",
    "This cell defines the `GTZANDataLoader`, a comprehensive class that encapsulates all the logic for loading, processing, and augmenting the GTZAN dataset. By structuring our logic this way, the code becomes modular, reusable, and easy to understand.\n",
    "\n",
    "### Key Methods:\n",
    "\n",
    "- `load_file_paths()`: Scans the directory structure to create a master list of audio files and labels.\n",
    "- `process_file()`: Loads a single audio file, slices it into 10 segments, and computes the log-Mel spectrogram for each segment. This is our primary data augmentation strategy. It includes error handling for potentially corrupt files in the dataset.\n",
    "- `create_dataset_from_files()`: Iterates through a list of file paths (e.g., the training set) and applies the `process_file` method to each, compiling the final list of spectrograms and labels.\n",
    "- `adjust_spectrograms_shape()`: A helper function to ensure all spectrograms have a uniform length by padding or truncating them. This is necessary because minor variations in file length can lead to spectrograms with slightly different time dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa44d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GTZANDataLoader class defined.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 3: THE DATA LOADER CLASS\n",
    "# ===================================================================\n",
    "\n",
    "class GTZANDataLoader:\n",
    "    \"\"\"\n",
    "    Handles the loading, pre-processing, and splitting of the GTZAN dataset\n",
    "    with a strong focus on preventing data leakage.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str, sample_rate: int = 22050, n_mels: int = 128, hop_length: int = 512):\n",
    "        \"\"\"\n",
    "        Initializes the loader with audio parameters and fits the LabelEncoder.\n",
    "        The StandardScaler is initialized but remains unfitted until the training\n",
    "        data is available.\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mels = n_mels\n",
    "        self.hop_length = hop_length\n",
    "        \n",
    "        # Discover genres from subdirectories\n",
    "        self.genres = sorted([d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))])\n",
    "        \n",
    "        # Fit the LabelEncoder once on all possible genre names\n",
    "        self.label_encoder = LabelEncoder().fit(self.genres)\n",
    "        \n",
    "        # Initialize an empty scaler; it will be fitted ONLY on the training data later\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def load_all_filepaths(self) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Scans the data directory and returns a list of all file paths and their text labels.\"\"\"\n",
    "        filepaths, labels = [], []\n",
    "        for genre in self.genres:\n",
    "            genre_path = os.path.join(self.data_path, genre)\n",
    "            for filename in os.listdir(genre_path):\n",
    "                if filename.endswith(('.wav', '.au')):\n",
    "                    filepaths.append(os.path.join(genre_path, filename))\n",
    "                    labels.append(genre)\n",
    "        return filepaths, labels\n",
    "    \n",
    "    def _process_audio_file(self, file_path: str, n_segments: int = 10, segment_duration: float = 2.97) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Loads and processes a single audio file, augmenting it into multiple segments.\n",
    "        Returns a list of log-Mel spectrograms for that file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            signal, _ = librosa.load(file_path, sr=self.sample_rate)\n",
    "            samples_per_segment = int(self.sample_rate * segment_duration)\n",
    "            \n",
    "            spectrograms = []\n",
    "            for s in range(n_segments):\n",
    "                start = s * samples_per_segment\n",
    "                end = start + samples_per_segment\n",
    "                if end <= len(signal):\n",
    "                    segment_signal = signal[start:end]\n",
    "                    mel_spec = librosa.feature.melspectrogram(\n",
    "                        y=segment_signal, sr=self.sample_rate, n_mels=self.n_mels, hop_length=self.hop_length\n",
    "                    )\n",
    "                    log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "                    spectrograms.append(log_mel_spec)\n",
    "            return spectrograms\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not process file {os.path.basename(file_path)}. Error: {e}\")\n",
    "            return []\n",
    "            \n",
    "    def create_dataset_from_filepaths(self, filepaths: List[str], text_labels: List[str], n_segments: int = 10) -> Tuple[List[np.ndarray], np.ndarray]:\n",
    "        \"\"\"Creates a dataset of spectrograms and encoded labels from a list of files.\"\"\"\n",
    "        X_list, y_list = [], []\n",
    "        encoded_labels = self.label_encoder.transform(text_labels)\n",
    "        \n",
    "        for i, file_path in enumerate(tqdm(filepaths, desc=f\"Processing {len(filepaths)} files\")):\n",
    "            spectrograms = self._process_audio_file(file_path, n_segments=n_segments)\n",
    "            for spec in spectrograms:\n",
    "                X_list.append(spec)\n",
    "                y_list.append(encoded_labels[i])\n",
    "                \n",
    "        return X_list, np.array(y_list)\n",
    "\n",
    "    @staticmethod\n",
    "    def _unify_spectrogram_shapes(spec_list: List[np.ndarray], target_len: int = 128) -> np.ndarray:\n",
    "        \"\"\"Pads or truncates spectrograms to a uniform target length.\"\"\"\n",
    "        adjusted_list = []\n",
    "        for spec in spec_list:\n",
    "            if spec.shape[1] > target_len:\n",
    "                adjusted_list.append(spec[:, :target_len])\n",
    "            else:\n",
    "                padding_needed = target_len - spec.shape[1]\n",
    "                adjusted_list.append(np.pad(spec, ((0, 0), (0, padding_needed)), mode='constant'))\n",
    "        return np.array(adjusted_list)\n",
    "\n",
    "print(\"âœ… GTZANDataLoader class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8afb09f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 4: Execution of the Full Pipeline\n",
    "\n",
    "This is the main execution cell where we orchestrate the entire data preparation process from start to finish.\n",
    "\n",
    "### The sequence of operations is critical for ensuring no data leakage:\n",
    "\n",
    "1.  **Load and Split Paths**: We instantiate our `GTZANDataLoader` and immediately split the raw file paths into training, validation, and test sets. This ensures that all segments from a single original song will reside in only one data split.\n",
    "2.  **Process Datasets**: We process each set of files (train, val, test) separately to create our augmented spectrogram datasets.\n",
    "3.  **Unify Shape**: We enforce a uniform shape across all generated spectrograms.\n",
    "4.  **Normalize Data**: We correctly fit the `StandardScaler` **only on the training data** and then apply this learned transformation to the validation and test sets.\n",
    "5.  **Add Channel Dimension**: We add a final \"channel\" dimension to the spectrograms, transforming their shape from `(N, H, W)` to `(N, H, W, 1)`, which is the standard input format for 2D Convolutional Neural Networks in Keras/TensorFlow.\n",
    "6.  **Save Artifacts**: Finally, we save all processed arrays and the fitted `scaler` and `label_encoder` objects to disk. These artifacts are now ready to be loaded directly by our training and analysis notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b3cca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preparation pipeline...\n",
      "Data split into: 600 train, 200 validation, 200 test files.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5c811fa2d14d449b3f2dceaf89d4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 600 files:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c830e67ffbd241f5aadb8b72e4c10ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 200 files:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff7777b280c4ce3abaa3775355089c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 200 files:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Spectrogram extraction complete.\n",
      "Unifying spectrogram shapes...\n",
      "Normalizing data (fitting scaler only on training data)...\n",
      "âœ… Normalization and channel formatting complete.\n",
      "\n",
      "ðŸ’¾ Saving processed data and artifacts...\n",
      "\n",
      "ðŸŽ‰ Pipeline complete. Data is ready for training in the subsequent notebooks.\n",
      "\n",
      "ðŸ“Š Summary of Saved Data:\n",
      "   - Training Set:   X=(6000, 128, 128, 1), y=(6000,)\n",
      "   - Validation Set: X=(2000, 128, 128, 1), y=(2000,)\n",
      "   - Test Set:       X=(2000, 128, 128, 1), y=(2000,)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 4: EXECUTION AND SAVING OF PROCESSED DATA\n",
    "# ===================================================================\n",
    "\n",
    "print(\"Starting data preparation pipeline...\")\n",
    "\n",
    "# 1. Load file paths and split at the file level to prevent data leakage.\n",
    "# Final split: 60% train, 20% validation, 20% test.\n",
    "data_loader = GTZANDataLoader(data_path=DATA_PATH)\n",
    "filepaths, text_labels = data_loader.load_all_filepaths()\n",
    "\n",
    "# First split: 80% for train/val, 20% for test\n",
    "train_val_files, test_files, train_val_labels, test_labels = train_test_split(\n",
    "    filepaths, text_labels, test_size=0.2, random_state=RANDOM_STATE, stratify=text_labels\n",
    ")\n",
    "# Second split: create train and validation from the 80% pool\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    train_val_files, train_val_labels, test_size=0.25, random_state=RANDOM_STATE, stratify=train_val_labels # 0.25 * 0.8 = 0.2\n",
    ")\n",
    "print(f\"Data split into: {len(train_files)} train, {len(val_files)} validation, {len(test_files)} test files.\")\n",
    "\n",
    "# 2. Process each data split into spectrograms\n",
    "X_train_list, y_train = data_loader.create_dataset_from_filepaths(train_files, train_labels)\n",
    "X_val_list, y_val = data_loader.create_dataset_from_filepaths(val_files, val_labels)\n",
    "X_test_list, y_test = data_loader.create_dataset_from_filepaths(test_files, test_labels)\n",
    "print(\"\\nâœ… Spectrogram extraction complete.\")\n",
    "\n",
    "# 3. Unify spectrogram shapes to a consistent length\n",
    "print(\"Unifying spectrogram shapes...\")\n",
    "X_train = GTZANDataLoader._unify_spectrogram_shapes(X_train_list)\n",
    "X_val = GTZANDataLoader._unify_spectrogram_shapes(X_val_list)\n",
    "X_test = GTZANDataLoader._unify_spectrogram_shapes(X_test_list)\n",
    "\n",
    "# 4. Normalize the data (Fit on train ONLY)\n",
    "# The scaler expects 2D data, so we reshape, fit/transform, then reshape back.\n",
    "print(\"Normalizing data (fitting scaler only on training data)...\")\n",
    "scaler = data_loader.scaler\n",
    "X_train_shape = X_train.shape\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train_shape[1] * X_train_shape[2])).reshape(X_train_shape)\n",
    "\n",
    "X_val_shape = X_val.shape\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_val_shape[1] * X_val_shape[2])).reshape(X_val_shape)\n",
    "\n",
    "X_test_shape = X_test.shape\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test_shape[1] * X_test_shape[2])).reshape(X_test_shape)\n",
    "\n",
    "# 5. Add channel dimension for CNN input: (N, H, W) -> (N, H, W, 1)\n",
    "X_train, X_val, X_test = X_train[..., np.newaxis], X_val[..., np.newaxis], X_test[..., np.newaxis]\n",
    "print(\"âœ… Normalization and channel formatting complete.\")\n",
    "\n",
    "# --- 6. SAVE ALL ARTIFACTS ---\n",
    "print(\"\\nðŸ’¾ Saving processed data and artifacts...\")\n",
    "np.save(os.path.join(PROCESSED_DATA_PATH, 'X_train.npy'), X_train)\n",
    "np.save(os.path.join(PROCESSED_DATA_PATH, 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(PROCESSED_DATA_PATH, 'X_val.npy'), X_val)\n",
    "np.save(os.path.join(PROCESSED_DATA_PATH, 'y_val.npy'), y_val)\n",
    "np.save(os.path.join(PROCESSED_DATA_PATH, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(PROCESSED_DATA_PATH, 'y_test.npy'), y_test)\n",
    "\n",
    "with open(os.path.join(PROCESSED_DATA_PATH, 'scaler.pkl'), 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open(os.path.join(PROCESSED_DATA_PATH, 'label_encoder.pkl'), 'wb') as f:\n",
    "    pickle.dump(data_loader.label_encoder, f)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Pipeline complete. Data is ready for training in the subsequent notebooks.\")\n",
    "print(\"\\nðŸ“Š Summary of Saved Data:\")\n",
    "print(f\"   - Training Set:   X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"   - Validation Set: X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"   - Test Set:       X={X_test.shape}, y={y_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
