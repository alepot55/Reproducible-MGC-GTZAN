{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27f33041",
   "metadata": {},
   "source": [
    "# Notebook 01: Final Model Training Tournament\n",
    "\n",
    "**Project:** Music Genre Classification on GTZAN  \n",
    "**Author:** Alessandro Potenza & Camilla Sed  \n",
    "**Course:** Numerical Analysis for Machine Learning, Politecnico di Milano\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook serves as the primary \"computation engine\" for our project. Its purpose is to conduct the definitive, comparative training experiment for the three architectures selected to represent our research narrative.\n",
    "\n",
    "This notebook will:\n",
    "1.  **Configure the Environment**: Set up GPU resources and mixed-precision training for efficiency.\n",
    "2.  **Load Pre-processed Data**: Load the clean, augmented, and leak-free datasets created by `00_Setup_and_Data_Preparation.ipynb`.\n",
    "3.  **Define a Curated `ModelFactory`**: Specify the three key architectures that tell our project's story, from a simple baseline to a sophisticated, paper-inspired model.\n",
    "4.  **Orchestrate the Training Tournament**: Systematically train and evaluate each of the three models under identical conditions, using a robust training loop.\n",
    "5.  **Save Results and Models**: Save the final performance summary (`training_summary_final.csv`) and the best weights for each model (`.keras` files) for later use in our analysis notebook (`02_Analysis_and_Publication_Results.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8939e9fa",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1: Environment Setup and Data Loading\n",
    "This cell handles all initial configuration. It sets up global paths, configures TensorFlow to use available GPUs with memory growth, and enables mixed-precision training to accelerate computation and reduce memory usage.\n",
    "\n",
    "Finally, it loads the NumPy arrays and the `label_encoder` object generated by the pre-processing notebook, preparing all necessary data for the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU(s) Trovata/e: ['NVIDIA GeForce RTX 4070']\n",
      "‚úÖ Politica di Mixed Precision impostata su: mixed_float16\n",
      "\n",
      "üîÑ Caricamento dei dati pre-processati...\n",
      "\n",
      "‚úÖ Dati caricati con successo.\n",
      "   - Shape X_train: (5990, 128, 128, 1) | Shape y_train_cat: (5990, 10)\n",
      "   - Numero di classi: 10\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 1: SETUP, IMPORTS E CARICAMENTO DATI\n",
    "# ===================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from keras import layers, models, optimizers, callbacks, regularizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# --- Configurazione Globale ---\n",
    "PROCESSED_DATA_PATH = '../../data/processed/'\n",
    "MODELS_PATH = '../../models/'\n",
    "REPORTS_PATH = '../../reports/'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(REPORTS_PATH, exist_ok=True)\n",
    "\n",
    "# 1. GPU e Mixed Precision\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU(s) Trovata/e: {[tf.config.experimental.get_device_details(g)['device_name'] for g in gpus]}\")\n",
    "        policy = keras.mixed_precision.Policy('mixed_float16')\n",
    "        keras.mixed_precision.set_global_policy(policy)\n",
    "        print(f\"‚úÖ Politica di Mixed Precision impostata su: {keras.mixed_precision.global_policy().name}\")\n",
    "    except RuntimeError as e: print(f\"‚ö†Ô∏è Errore durante l'inizializzazione della GPU: {e}\")\n",
    "else: print(\"‚ùå NESSUNA GPU TROVATA. L'allenamento sar√† su CPU.\")\n",
    "\n",
    "# 2. Caricamento Dati Pre-processati\n",
    "print(\"\\nüîÑ Caricamento dei dati pre-processati...\")\n",
    "try:\n",
    "    X_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_train.npy'))\n",
    "    y_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_train.npy'))\n",
    "    X_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_val.npy'))\n",
    "    y_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_val.npy'))\n",
    "    X_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_test.npy'))\n",
    "    y_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_test.npy'))\n",
    "    \n",
    "    with open(os.path.join(PROCESSED_DATA_PATH, 'label_encoder.pkl'), 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "\n",
    "    # Conversione in formato categorico\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val_cat = to_categorical(y_val, num_classes=num_classes)\n",
    "    y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "    print(\"\\n‚úÖ Dati caricati con successo.\")\n",
    "    print(f\"   - Shape X_train: {X_train.shape} | Shape y_train_cat: {y_train_cat.shape}\")\n",
    "    print(f\"   - Numero di classi: {num_classes}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ERRORE: File di dati non trovati. Eseguire prima il notebook '00_Setup_and_Data_Preparation.ipynb'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4696a1e9",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: Curated Model Factory for Final Narrative\n",
    "This cell defines the `ModelFactory`, a class that now contains only the three architectures essential to our project's story. This curated selection allows us to tell a clear and compelling narrative of architectural evolution and performance gains.\n",
    "\n",
    "### The Three Acts of Our Story:\n",
    "1.  **`Efficient_VGG`**: The simple, robust baseline. Represents the \"less-is-more\" philosophy.\n",
    "2.  **`ResSE_AudioCNN`**: The modern standard. A sophisticated classifier using residual connections and attention, representing a typical high-performance approach.\n",
    "3.  **`UNet_Audio_Classifier`**: The paper-inspired innovator. This model tests our central hypothesis that multi-scale feature learning is superior for this task, achieving the best generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56958c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Curated ModelFactory defined with 3 key architectures for the final analysis.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 2: CURATED MODEL FACTORY FOR FINAL NARRATIVE\n",
    "# ===================================================================\n",
    "# This cell defines the three key architectures that form the core of\n",
    "# our project's narrative. The selection tells a clear story, moving from\n",
    "# a simple baseline, to a modern standard, and finally to an innovative\n",
    "# model inspired by the reference paper's core concepts.\n",
    "\n",
    "from keras import layers, models, regularizers\n",
    "\n",
    "class ModelFactory:\n",
    "    \"\"\"\n",
    "    A curated factory for building and comparing the three key CNN\n",
    "    architectures selected for our final, focused analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # Public Methods to Get Model Builders\n",
    "    # -------------------------------------------------------------------\n",
    "    @staticmethod\n",
    "    def get_final_models():\n",
    "        \"\"\"\n",
    "        Returns a dictionary mapping the names of our three final, curated\n",
    "        models to their respective builder functions. This is the definitive\n",
    "        list for our final experiment.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"Efficient_VGG\": ModelFactory.build_efficient_vgg,\n",
    "            \"ResSE_AudioCNN\": ModelFactory.build_res_se_audio_cnn,\n",
    "            \"UNet_Audio_Classifier\": ModelFactory.build_unet_audio_classifier,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_final_model_names():\n",
    "        \"\"\"Returns a list of the curated model names.\"\"\"\n",
    "        return list(ModelFactory.get_final_models().keys())\n",
    "\n",
    "    @staticmethod\n",
    "    def get_builder_by_name(name):\n",
    "        \"\"\"\n",
    "        Retrieves the model-building function for a given model name from\n",
    "        our curated list.\n",
    "        \"\"\"\n",
    "        builder = ModelFactory.get_final_models().get(name)\n",
    "        if builder is None:\n",
    "            raise AttributeError(f\"Model '{name}' not found. Available models for the final run: {ModelFactory.get_final_model_names()}\")\n",
    "        return builder\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # Shared Helper Building Blocks\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "    @staticmethod\n",
    "    def _se_block(input_tensor, ratio=8, name_prefix=\"\"):\n",
    "        \"\"\"Squeeze-and-Excitation block to add channel-wise attention.\"\"\"\n",
    "        channels = input_tensor.shape[-1]\n",
    "        se = layers.GlobalAveragePooling2D(name=f'{name_prefix}_se_squeeze')(input_tensor)\n",
    "        se = layers.Reshape((1, 1, channels))(se)\n",
    "        se = layers.Dense(channels // ratio, activation='relu', name=f'{name_prefix}_se_excite_1')(se)\n",
    "        se = layers.Dense(channels, activation='sigmoid', name=f'{name_prefix}_se_excite_2')(se)\n",
    "        return layers.Multiply(name=f'{name_prefix}_se_scale')([input_tensor, se])\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # ACT 1: The Efficient Baseline (Our Unexpected Champion)\n",
    "    # -------------------------------------------------------------------\n",
    "    @staticmethod\n",
    "    def build_efficient_vgg(input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        ACT 1: The surprisingly effective baseline. A simple VGG-style\n",
    "        architecture, well-regularized with SE blocks. Represents the\n",
    "        \"less is more\" philosophy and sets a high bar for performance.\n",
    "        \"\"\"\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        # Block 1\n",
    "        x = layers.Conv2D(16, 3, padding='same', use_bias=False)(inputs)\n",
    "        x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = ModelFactory._se_block(x, name_prefix=\"vgg_b1\")\n",
    "        # Block 2\n",
    "        x = layers.Conv2D(32, 3, padding='same', use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = ModelFactory._se_block(x, name_prefix=\"vgg_b2\")\n",
    "        # Block 3\n",
    "        x = layers.Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = ModelFactory._se_block(x, name_prefix=\"vgg_b3\")\n",
    "        # Classification Head\n",
    "        x = layers.GlobalAveragePooling2D(name=\"gap\")(x)\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "        return models.Model(inputs=inputs, outputs=outputs, name='Efficient_VGG')\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # ACT 2: The Modern Standard (The Sophisticated Challenger)\n",
    "    # -------------------------------------------------------------------\n",
    "    @staticmethod\n",
    "    def _res_se_block(input_tensor, filters, stride=1, name_prefix=\"\"):\n",
    "        \"\"\"Residual block using standard convolutions, PReLU, and SE attention.\"\"\"\n",
    "        shortcut = input_tensor\n",
    "        # First convolution\n",
    "        x = layers.Conv2D(filters, 3, strides=stride, padding='same', use_bias=False, name=f'{name_prefix}_conv1')(input_tensor)\n",
    "        x = layers.BatchNormalization(name=f'{name_prefix}_bn1')(x)\n",
    "        x = layers.PReLU(shared_axes=[1, 2], name=f'{name_prefix}_prelu1')(x)\n",
    "        # Second convolution\n",
    "        x = layers.Conv2D(filters, 3, padding='same', use_bias=False, name=f'{name_prefix}_conv2')(x)\n",
    "        x = layers.BatchNormalization(name=f'{name_prefix}_bn2')(x)\n",
    "        x = ModelFactory._se_block(x, name_prefix=f'{name_prefix}_se')\n",
    "        # Shortcut connection\n",
    "        if stride > 1 or shortcut.shape[-1] != filters:\n",
    "            shortcut = layers.Conv2D(filters, 1, strides=stride, use_bias=False, name=f'{name_prefix}_shortcut_conv')(shortcut)\n",
    "            shortcut = layers.BatchNormalization(name=f'{name_prefix}_shortcut_bn')(shortcut)\n",
    "        x = layers.Add(name=f'{name_prefix}_add')([shortcut, x])\n",
    "        x = layers.PReLU(shared_axes=[1, 2], name=f'{name_prefix}_prelu2')(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def build_res_se_audio_cnn(input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        ACT 2: The modern standard. Combines deep residual connections\n",
    "        (ResNet) with Squeeze-and-Excitation attention to represent the\n",
    "        current state-of-the-art for classification.\n",
    "        \"\"\"\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        # Entry block\n",
    "        x = layers.Conv2D(32, 3, strides=1, padding='same', use_bias=False)(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "        # Residual blocks\n",
    "        x = ModelFactory._res_se_block(x, 64, stride=2, name_prefix=\"res_b1\")\n",
    "        x = ModelFactory._res_se_block(x, 128, stride=2, name_prefix=\"res_b2\")\n",
    "        x = ModelFactory._res_se_block(x, 256, stride=2, name_prefix=\"res_b3\")\n",
    "        # Classification Head\n",
    "        x = layers.GlobalAveragePooling2D(name=\"gap\")(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "        return models.Model(inputs=inputs, outputs=outputs, name='ResSE_AudioCNN')\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # ACT 3: The Paper-Inspired Innovator (The Best Generalizer)\n",
    "    # -------------------------------------------------------------------\n",
    "    @staticmethod\n",
    "    def _unet_encoder_block(input_tensor, filters, pool=True, name_prefix=\"\"):\n",
    "        \"\"\"Encoder block for a U-Net, returning both the pooled output and skip connection.\"\"\"\n",
    "        x = layers.Conv2D(filters, 3, padding='same', use_bias=False, name=f'{name_prefix}_conv1')(input_tensor)\n",
    "        x = layers.BatchNormalization(name=f'{name_prefix}_bn1')(x); x = layers.PReLU(shared_axes=[1, 2], name=f'{name_prefix}_prelu1')(x)\n",
    "        x = layers.Conv2D(filters, 3, padding='same', use_bias=False, name=f'{name_prefix}_conv2')(x)\n",
    "        x = layers.BatchNormalization(name=f'{name_prefix}_bn2')(x); x = layers.PReLU(shared_axes=[1, 2], name=f'{name_prefix}_prelu2')(x)\n",
    "        skip_connection = x\n",
    "        if pool:\n",
    "            pool_output = layers.MaxPooling2D(2, name=f'{name_prefix}_pool')(x)\n",
    "            return pool_output, skip_connection\n",
    "        else: # For the bottleneck\n",
    "            return x, skip_connection\n",
    "\n",
    "    @staticmethod\n",
    "    def build_unet_audio_classifier(input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        ACT 3: Paper-inspired innovation. Adapts the U-Net's multi-scale\n",
    "        feature learning for classification. Uses the deep, abstract features\n",
    "        from the bottleneck to achieve the best generalization on the test set.\n",
    "        \"\"\"\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        # Encoder Path\n",
    "        p1, s1 = ModelFactory._unet_encoder_block(inputs, 32, name_prefix=\"enc1\")\n",
    "        p2, s2 = ModelFactory._unet_encoder_block(p1, 64, name_prefix=\"enc2\")\n",
    "        p3, s3 = ModelFactory._unet_encoder_block(p2, 128, name_prefix=\"enc3\")\n",
    "        # Bottleneck (we only need its primary output for classification)\n",
    "        bottleneck, _ = ModelFactory._unet_encoder_block(p3, 256, pool=False, name_prefix=\"bneck\")\n",
    "        # Classification Head\n",
    "        x = layers.GlobalAveragePooling2D(name=\"gap\")(bottleneck)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "        return models.Model(inputs=inputs, outputs=outputs, name='UNet_Audio_Classifier')\n",
    "\n",
    "\n",
    "print(\"‚úÖ Curated ModelFactory defined with 3 key architectures for the final analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c326a",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3: The Definitive Training and Evaluation Framework\n",
    "This is the main execution cell of the notebook. It orchestrates the end-to-end training and evaluation process for our three selected models.\n",
    "\n",
    "### Key Components:\n",
    "-   **`spec_augment_tf`**: An on-the-fly data augmentation function that applies frequency and time masking to the training spectrograms to improve model robustness.\n",
    "-   **`RichLoggerCallback`**: A custom Keras callback for clean, professional logging of training progress, including epoch time and learning rate.\n",
    "-   **`ModelEvaluator`**: A robust class that iterates through each model factory, compiles the model, and runs the `fit`/`evaluate` cycle with a standardized set of callbacks (`EarlyStopping`, `ReduceLROnPlateau`, `ModelCheckpoint`).\n",
    "-   **Experiment Execution**: The cell configures the `tf.data` pipelines, instantiates the `ModelEvaluator`, and launches the training tournament. Upon completion, it saves the final results to a CSV file for analysis in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a6c0fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed data...\n",
      "‚úÖ Data successfully loaded and prepared.\n",
      "\n",
      "Configuring JIT data pipelines...\n",
      "\n",
      "‚úÖ Ready to run final tournament for the following models: ['Efficient_VGG', 'ResSE_AudioCNN', 'UNet_Audio_Classifier']\n",
      "\n",
      "================================================================================\n",
      "TRAINING ARCHITECTURE: 'Efficient_VGG'\n",
      "================================================================================\n",
      "üöÄ Starting training for model: Efficient_VGG...\n",
      "Epoch 01/100 | Time: 9.71s | Loss: 1.9332 | Acc: 0.2912 | Val Loss: 2.3392 | Val Acc: 0.1005 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 02/100 | Time: 1.07s | Loss: 1.5779 | Acc: 0.4244 | Val Loss: 3.0182 | Val Acc: 0.1330 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 03/100 | Time: 1.03s | Loss: 1.4420 | Acc: 0.4766 | Val Loss: 3.3359 | Val Acc: 0.1820 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 04/100 | Time: 1.08s | Loss: 1.3104 | Acc: 0.5304 | Val Loss: 1.5637 | Val Acc: 0.4395 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 05/100 | Time: 1.02s | Loss: 1.2198 | Acc: 0.5693 | Val Loss: 2.2346 | Val Acc: 0.3280 | LR: 1.0e-03\n",
      "Epoch 06/100 | Time: 1.12s | Loss: 1.1540 | Acc: 0.5943 | Val Loss: 1.7913 | Val Acc: 0.4265 | LR: 1.0e-03\n",
      "Epoch 07/100 | Time: 0.98s | Loss: 1.0961 | Acc: 0.6205 | Val Loss: 1.5748 | Val Acc: 0.4770 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 08/100 | Time: 1.11s | Loss: 1.0509 | Acc: 0.6394 | Val Loss: 1.6433 | Val Acc: 0.4660 | LR: 1.0e-03\n",
      "Epoch 09/100 | Time: 1.04s | Loss: 1.0124 | Acc: 0.6533 | Val Loss: 2.1559 | Val Acc: 0.4095 | LR: 1.0e-03\n",
      "Epoch 10/100 | Time: 1.06s | Loss: 0.9857 | Acc: 0.6591 | Val Loss: 1.1498 | Val Acc: 0.6100 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 11/100 | Time: 1.04s | Loss: 0.9528 | Acc: 0.6803 | Val Loss: 2.2359 | Val Acc: 0.4220 | LR: 1.0e-03\n",
      "Epoch 12/100 | Time: 1.04s | Loss: 0.9217 | Acc: 0.6866 | Val Loss: 1.5948 | Val Acc: 0.5205 | LR: 1.0e-03\n",
      "Epoch 13/100 | Time: 1.06s | Loss: 0.9119 | Acc: 0.6856 | Val Loss: 1.2990 | Val Acc: 0.5940 | LR: 1.0e-03\n",
      "Epoch 14/100 | Time: 1.06s | Loss: 0.9279 | Acc: 0.6776 | Val Loss: 1.2764 | Val Acc: 0.5970 | LR: 1.0e-03\n",
      "Epoch 15/100 | Time: 1.12s | Loss: 0.8584 | Acc: 0.7018 | Val Loss: 1.8399 | Val Acc: 0.4945 | LR: 1.0e-03\n",
      "Epoch 16/100 | Time: 1.04s | Loss: 0.8642 | Acc: 0.7080 | Val Loss: 1.7630 | Val Acc: 0.4910 | LR: 1.0e-03\n",
      "Epoch 17/100 | Time: 1.12s | Loss: 0.8508 | Acc: 0.7087 | Val Loss: 1.4702 | Val Acc: 0.5245 | LR: 1.0e-03\n",
      "Epoch 18/100 | Time: 1.01s | Loss: 0.8289 | Acc: 0.7129 | Val Loss: 1.2589 | Val Acc: 0.5955 | LR: 1.0e-03\n",
      "Epoch 19/100 | Time: 1.08s | Loss: 0.8112 | Acc: 0.7194 | Val Loss: 1.4806 | Val Acc: 0.5745 | LR: 1.0e-03\n",
      "Epoch 20/100 | Time: 0.99s | Loss: 0.8033 | Acc: 0.7312 | Val Loss: 1.2504 | Val Acc: 0.6190 | LR: 1.0e-03 ‚úÖ\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 21/100 | Time: 1.08s | Loss: 0.7274 | Acc: 0.7533 | Val Loss: 1.0563 | Val Acc: 0.6680 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 22/100 | Time: 1.02s | Loss: 0.7092 | Acc: 0.7573 | Val Loss: 0.9491 | Val Acc: 0.7000 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 23/100 | Time: 1.06s | Loss: 0.6908 | Acc: 0.7669 | Val Loss: 0.9233 | Val Acc: 0.7025 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 24/100 | Time: 1.04s | Loss: 0.7135 | Acc: 0.7634 | Val Loss: 0.8755 | Val Acc: 0.7090 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 25/100 | Time: 1.04s | Loss: 0.6861 | Acc: 0.7691 | Val Loss: 0.9533 | Val Acc: 0.7100 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 26/100 | Time: 1.07s | Loss: 0.6820 | Acc: 0.7741 | Val Loss: 1.0420 | Val Acc: 0.6565 | LR: 2.0e-04\n",
      "Epoch 27/100 | Time: 1.03s | Loss: 0.6888 | Acc: 0.7699 | Val Loss: 0.9504 | Val Acc: 0.7130 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 28/100 | Time: 1.08s | Loss: 0.6793 | Acc: 0.7741 | Val Loss: 1.0712 | Val Acc: 0.6600 | LR: 2.0e-04\n",
      "Epoch 29/100 | Time: 1.01s | Loss: 0.6914 | Acc: 0.7691 | Val Loss: 0.9308 | Val Acc: 0.7115 | LR: 2.0e-04\n",
      "Epoch 30/100 | Time: 1.10s | Loss: 0.6748 | Acc: 0.7728 | Val Loss: 0.9746 | Val Acc: 0.6890 | LR: 2.0e-04\n",
      "Epoch 31/100 | Time: 1.00s | Loss: 0.6747 | Acc: 0.7760 | Val Loss: 0.9345 | Val Acc: 0.6985 | LR: 2.0e-04\n",
      "Epoch 32/100 | Time: 1.09s | Loss: 0.6610 | Acc: 0.7790 | Val Loss: 0.9580 | Val Acc: 0.6905 | LR: 2.0e-04\n",
      "Epoch 33/100 | Time: 0.98s | Loss: 0.6665 | Acc: 0.7781 | Val Loss: 1.0709 | Val Acc: 0.6730 | LR: 2.0e-04\n",
      "Epoch 34/100 | Time: 1.09s | Loss: 0.6689 | Acc: 0.7761 | Val Loss: 0.9955 | Val Acc: 0.6845 | LR: 2.0e-04\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 35/100 | Time: 1.00s | Loss: 0.6403 | Acc: 0.7861 | Val Loss: 0.8561 | Val Acc: 0.7340 | LR: 4.0e-05 ‚úÖ\n",
      "Epoch 36/100 | Time: 1.08s | Loss: 0.6368 | Acc: 0.7927 | Val Loss: 0.8506 | Val Acc: 0.7325 | LR: 4.0e-05\n",
      "Epoch 37/100 | Time: 1.03s | Loss: 0.6262 | Acc: 0.7957 | Val Loss: 0.8672 | Val Acc: 0.7340 | LR: 4.0e-05\n",
      "Epoch 38/100 | Time: 1.06s | Loss: 0.6401 | Acc: 0.7843 | Val Loss: 0.8378 | Val Acc: 0.7375 | LR: 4.0e-05 ‚úÖ\n",
      "Epoch 39/100 | Time: 1.04s | Loss: 0.6245 | Acc: 0.7876 | Val Loss: 0.8929 | Val Acc: 0.7265 | LR: 4.0e-05\n",
      "Epoch 40/100 | Time: 1.05s | Loss: 0.6147 | Acc: 0.7958 | Val Loss: 0.8487 | Val Acc: 0.7325 | LR: 4.0e-05\n",
      "Epoch 41/100 | Time: 1.05s | Loss: 0.6288 | Acc: 0.7912 | Val Loss: 0.8503 | Val Acc: 0.7265 | LR: 4.0e-05\n",
      "Epoch 42/100 | Time: 1.04s | Loss: 0.6208 | Acc: 0.7943 | Val Loss: 0.8559 | Val Acc: 0.7260 | LR: 4.0e-05\n",
      "Epoch 43/100 | Time: 1.06s | Loss: 0.6352 | Acc: 0.7878 | Val Loss: 0.8628 | Val Acc: 0.7195 | LR: 4.0e-05\n",
      "Epoch 44/100 | Time: 1.03s | Loss: 0.6331 | Acc: 0.7891 | Val Loss: 0.9020 | Val Acc: 0.7110 | LR: 4.0e-05\n",
      "Epoch 45/100 | Time: 1.08s | Loss: 0.6178 | Acc: 0.7910 | Val Loss: 0.8615 | Val Acc: 0.7265 | LR: 4.0e-05\n",
      "Epoch 46/100 | Time: 1.02s | Loss: 0.6237 | Acc: 0.7891 | Val Loss: 0.8414 | Val Acc: 0.7350 | LR: 4.0e-05\n",
      "Epoch 47/100 | Time: 1.08s | Loss: 0.6238 | Acc: 0.7888 | Val Loss: 0.8655 | Val Acc: 0.7385 | LR: 4.0e-05 ‚úÖ\n",
      "Epoch 48/100 | Time: 1.00s | Loss: 0.6349 | Acc: 0.7845 | Val Loss: 0.8508 | Val Acc: 0.7250 | LR: 4.0e-05\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 49/100 | Time: 1.10s | Loss: 0.6238 | Acc: 0.7871 | Val Loss: 0.8441 | Val Acc: 0.7310 | LR: 8.0e-06\n",
      "Epoch 50/100 | Time: 1.01s | Loss: 0.6076 | Acc: 0.7988 | Val Loss: 0.8357 | Val Acc: 0.7360 | LR: 8.0e-06\n",
      "Epoch 51/100 | Time: 1.10s | Loss: 0.6192 | Acc: 0.7943 | Val Loss: 0.8414 | Val Acc: 0.7325 | LR: 8.0e-06\n",
      "Epoch 52/100 | Time: 1.05s | Loss: 0.6146 | Acc: 0.7923 | Val Loss: 0.8417 | Val Acc: 0.7330 | LR: 8.0e-06\n",
      "Epoch 53/100 | Time: 1.06s | Loss: 0.6166 | Acc: 0.7922 | Val Loss: 0.8422 | Val Acc: 0.7310 | LR: 8.0e-06\n",
      "Epoch 54/100 | Time: 1.04s | Loss: 0.6252 | Acc: 0.7918 | Val Loss: 0.8387 | Val Acc: 0.7340 | LR: 8.0e-06\n",
      "Epoch 55/100 | Time: 1.05s | Loss: 0.6204 | Acc: 0.7945 | Val Loss: 0.8378 | Val Acc: 0.7370 | LR: 8.0e-06\n",
      "Epoch 56/100 | Time: 1.04s | Loss: 0.6200 | Acc: 0.7912 | Val Loss: 0.8405 | Val Acc: 0.7310 | LR: 8.0e-06\n",
      "Epoch 57/100 | Time: 1.04s | Loss: 0.6233 | Acc: 0.7997 | Val Loss: 0.8351 | Val Acc: 0.7345 | LR: 8.0e-06\n",
      "Epoch 58/100 | Time: 1.05s | Loss: 0.6144 | Acc: 0.7940 | Val Loss: 0.8354 | Val Acc: 0.7320 | LR: 8.0e-06\n",
      "Epoch 59/100 | Time: 1.04s | Loss: 0.6067 | Acc: 0.7962 | Val Loss: 0.8342 | Val Acc: 0.7300 | LR: 8.0e-06\n",
      "Epoch 60/100 | Time: 1.06s | Loss: 0.6113 | Acc: 0.7990 | Val Loss: 0.8403 | Val Acc: 0.7320 | LR: 8.0e-06\n",
      "Epoch 61/100 | Time: 1.03s | Loss: 0.6083 | Acc: 0.7955 | Val Loss: 0.8376 | Val Acc: 0.7320 | LR: 8.0e-06\n",
      "Epoch 62/100 | Time: 1.07s | Loss: 0.6152 | Acc: 0.7952 | Val Loss: 0.8375 | Val Acc: 0.7335 | LR: 8.0e-06\n",
      "Epoch 63/100 | Time: 1.02s | Loss: 0.6213 | Acc: 0.7945 | Val Loss: 0.8378 | Val Acc: 0.7335 | LR: 8.0e-06\n",
      "Epoch 64/100 | Time: 1.07s | Loss: 0.6170 | Acc: 0.7928 | Val Loss: 0.8394 | Val Acc: 0.7345 | LR: 8.0e-06\n",
      "Epoch 65/100 | Time: 1.02s | Loss: 0.6215 | Acc: 0.7888 | Val Loss: 0.8391 | Val Acc: 0.7340 | LR: 8.0e-06\n",
      "Epoch 66/100 | Time: 1.09s | Loss: 0.6158 | Acc: 0.7905 | Val Loss: 0.8403 | Val Acc: 0.7330 | LR: 8.0e-06\n",
      "Epoch 67/100 | Time: 1.00s | Loss: 0.6268 | Acc: 0.7903 | Val Loss: 0.8343 | Val Acc: 0.7305 | LR: 8.0e-06\n",
      "üèÅ Finished training. Best Validation Accuracy: 0.7385\n",
      "\n",
      "================================================================================\n",
      "TRAINING ARCHITECTURE: 'ResSE_AudioCNN'\n",
      "================================================================================\n",
      "üöÄ Starting training for model: ResSE_AudioCNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 14:37:32.028633: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/100 | Time: 29.61s | Loss: 1.6398 | Acc: 0.3987 | Val Loss: 3.1155 | Val Acc: 0.1955 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 02/100 | Time: 3.71s | Loss: 1.2327 | Acc: 0.5631 | Val Loss: 3.1900 | Val Acc: 0.1770 | LR: 1.0e-03\n",
      "Epoch 03/100 | Time: 3.64s | Loss: 1.0317 | Acc: 0.6449 | Val Loss: 3.8619 | Val Acc: 0.1905 | LR: 1.0e-03\n",
      "Epoch 04/100 | Time: 3.73s | Loss: 0.8192 | Acc: 0.7200 | Val Loss: 2.2087 | Val Acc: 0.4380 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 05/100 | Time: 3.68s | Loss: 0.6919 | Acc: 0.7618 | Val Loss: 2.0798 | Val Acc: 0.5020 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 06/100 | Time: 3.65s | Loss: 0.6094 | Acc: 0.7945 | Val Loss: 1.8721 | Val Acc: 0.4930 | LR: 1.0e-03\n",
      "Epoch 07/100 | Time: 3.75s | Loss: 0.4699 | Acc: 0.8394 | Val Loss: 1.2563 | Val Acc: 0.6470 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 08/100 | Time: 3.65s | Loss: 0.3989 | Acc: 0.8648 | Val Loss: 1.9650 | Val Acc: 0.5715 | LR: 1.0e-03\n",
      "Epoch 09/100 | Time: 3.69s | Loss: 0.3225 | Acc: 0.8908 | Val Loss: 1.4458 | Val Acc: 0.6345 | LR: 1.0e-03\n",
      "Epoch 10/100 | Time: 3.76s | Loss: 0.2623 | Acc: 0.9144 | Val Loss: 2.4590 | Val Acc: 0.5215 | LR: 1.0e-03\n",
      "Epoch 11/100 | Time: 3.65s | Loss: 0.1976 | Acc: 0.9382 | Val Loss: 1.9483 | Val Acc: 0.5905 | LR: 1.0e-03\n",
      "Epoch 12/100 | Time: 3.65s | Loss: 0.1630 | Acc: 0.9484 | Val Loss: 2.8375 | Val Acc: 0.5550 | LR: 1.0e-03\n",
      "Epoch 13/100 | Time: 3.74s | Loss: 0.1457 | Acc: 0.9533 | Val Loss: 4.9699 | Val Acc: 0.3395 | LR: 1.0e-03\n",
      "Epoch 14/100 | Time: 3.65s | Loss: 0.1048 | Acc: 0.9693 | Val Loss: 1.9465 | Val Acc: 0.5870 | LR: 1.0e-03\n",
      "Epoch 15/100 | Time: 3.72s | Loss: 0.0953 | Acc: 0.9721 | Val Loss: 1.8241 | Val Acc: 0.6155 | LR: 1.0e-03\n",
      "Epoch 16/100 | Time: 3.65s | Loss: 0.0795 | Acc: 0.9768 | Val Loss: 3.8330 | Val Acc: 0.5400 | LR: 1.0e-03\n",
      "Epoch 17/100 | Time: 3.72s | Loss: 0.0808 | Acc: 0.9750 | Val Loss: 1.3682 | Val Acc: 0.6870 | LR: 1.0e-03 ‚úÖ\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 18/100 | Time: 3.70s | Loss: 0.0367 | Acc: 0.9915 | Val Loss: 0.9442 | Val Acc: 0.7675 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 19/100 | Time: 3.74s | Loss: 0.0271 | Acc: 0.9937 | Val Loss: 1.1483 | Val Acc: 0.7480 | LR: 2.0e-04\n",
      "Epoch 20/100 | Time: 3.68s | Loss: 0.0225 | Acc: 0.9960 | Val Loss: 1.0478 | Val Acc: 0.7595 | LR: 2.0e-04\n",
      "Epoch 21/100 | Time: 3.65s | Loss: 0.0181 | Acc: 0.9977 | Val Loss: 0.9858 | Val Acc: 0.7705 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 22/100 | Time: 3.81s | Loss: 0.0168 | Acc: 0.9983 | Val Loss: 1.0040 | Val Acc: 0.7645 | LR: 2.0e-04\n",
      "Epoch 23/100 | Time: 3.64s | Loss: 0.0155 | Acc: 0.9977 | Val Loss: 1.0379 | Val Acc: 0.7650 | LR: 2.0e-04\n",
      "Epoch 24/100 | Time: 3.69s | Loss: 0.0158 | Acc: 0.9972 | Val Loss: 0.9286 | Val Acc: 0.7790 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 25/100 | Time: 3.68s | Loss: 0.0157 | Acc: 0.9965 | Val Loss: 1.0305 | Val Acc: 0.7765 | LR: 2.0e-04\n",
      "Epoch 26/100 | Time: 3.72s | Loss: 0.0129 | Acc: 0.9990 | Val Loss: 1.0679 | Val Acc: 0.7755 | LR: 2.0e-04\n",
      "Epoch 27/100 | Time: 3.70s | Loss: 0.0129 | Acc: 0.9977 | Val Loss: 1.1893 | Val Acc: 0.7540 | LR: 2.0e-04\n",
      "Epoch 28/100 | Time: 3.66s | Loss: 0.0142 | Acc: 0.9968 | Val Loss: 1.1895 | Val Acc: 0.7525 | LR: 2.0e-04\n",
      "Epoch 29/100 | Time: 3.74s | Loss: 0.0098 | Acc: 0.9988 | Val Loss: 1.0991 | Val Acc: 0.7680 | LR: 2.0e-04\n",
      "Epoch 30/100 | Time: 3.69s | Loss: 0.0110 | Acc: 0.9983 | Val Loss: 1.0138 | Val Acc: 0.7710 | LR: 2.0e-04\n",
      "Epoch 31/100 | Time: 3.73s | Loss: 0.0118 | Acc: 0.9978 | Val Loss: 1.0605 | Val Acc: 0.7625 | LR: 2.0e-04\n",
      "Epoch 32/100 | Time: 3.69s | Loss: 0.0111 | Acc: 0.9987 | Val Loss: 0.9565 | Val Acc: 0.7750 | LR: 2.0e-04\n",
      "Epoch 33/100 | Time: 3.65s | Loss: 0.0093 | Acc: 0.9985 | Val Loss: 1.3573 | Val Acc: 0.7495 | LR: 2.0e-04\n",
      "Epoch 34/100 | Time: 3.78s | Loss: 0.0082 | Acc: 0.9988 | Val Loss: 1.0760 | Val Acc: 0.7735 | LR: 2.0e-04\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 35/100 | Time: 3.69s | Loss: 0.0087 | Acc: 0.9988 | Val Loss: 1.0094 | Val Acc: 0.7820 | LR: 4.0e-05 ‚úÖ\n",
      "Epoch 36/100 | Time: 3.66s | Loss: 0.0077 | Acc: 0.9990 | Val Loss: 1.0772 | Val Acc: 0.7800 | LR: 4.0e-05\n",
      "Epoch 37/100 | Time: 3.78s | Loss: 0.0071 | Acc: 0.9992 | Val Loss: 1.0585 | Val Acc: 0.7795 | LR: 4.0e-05\n",
      "Epoch 38/100 | Time: 3.69s | Loss: 0.0075 | Acc: 0.9988 | Val Loss: 1.0561 | Val Acc: 0.7830 | LR: 4.0e-05 ‚úÖ\n",
      "Epoch 39/100 | Time: 3.65s | Loss: 0.0064 | Acc: 0.9993 | Val Loss: 0.9779 | Val Acc: 0.7820 | LR: 4.0e-05\n",
      "Epoch 40/100 | Time: 3.65s | Loss: 0.0071 | Acc: 0.9992 | Val Loss: 1.0173 | Val Acc: 0.7880 | LR: 4.0e-05 ‚úÖ\n",
      "Epoch 41/100 | Time: 3.72s | Loss: 0.0065 | Acc: 0.9992 | Val Loss: 1.0316 | Val Acc: 0.7875 | LR: 4.0e-05\n",
      "Epoch 42/100 | Time: 3.67s | Loss: 0.0067 | Acc: 0.9990 | Val Loss: 0.9871 | Val Acc: 0.7815 | LR: 4.0e-05\n",
      "Epoch 43/100 | Time: 3.73s | Loss: 0.0061 | Acc: 0.9988 | Val Loss: 1.0234 | Val Acc: 0.7860 | LR: 4.0e-05\n",
      "Epoch 44/100 | Time: 3.74s | Loss: 0.0062 | Acc: 0.9990 | Val Loss: 1.0538 | Val Acc: 0.7790 | LR: 4.0e-05\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 45/100 | Time: 3.75s | Loss: 0.0055 | Acc: 0.9992 | Val Loss: 1.0361 | Val Acc: 0.7860 | LR: 8.0e-06\n",
      "Epoch 46/100 | Time: 3.68s | Loss: 0.0056 | Acc: 0.9997 | Val Loss: 1.0352 | Val Acc: 0.7855 | LR: 8.0e-06\n",
      "Epoch 47/100 | Time: 3.72s | Loss: 0.0061 | Acc: 0.9990 | Val Loss: 1.0276 | Val Acc: 0.7905 | LR: 8.0e-06 ‚úÖ\n",
      "Epoch 48/100 | Time: 3.71s | Loss: 0.0069 | Acc: 0.9988 | Val Loss: 1.0258 | Val Acc: 0.7875 | LR: 8.0e-06\n",
      "Epoch 49/100 | Time: 3.73s | Loss: 0.0054 | Acc: 0.9995 | Val Loss: 1.0244 | Val Acc: 0.7870 | LR: 8.0e-06\n",
      "Epoch 50/100 | Time: 3.68s | Loss: 0.0057 | Acc: 0.9993 | Val Loss: 1.0226 | Val Acc: 0.7865 | LR: 8.0e-06\n",
      "Epoch 51/100 | Time: 3.72s | Loss: 0.0059 | Acc: 0.9995 | Val Loss: 1.0206 | Val Acc: 0.7870 | LR: 8.0e-06\n",
      "Epoch 52/100 | Time: 3.77s | Loss: 0.0065 | Acc: 0.9988 | Val Loss: 1.0278 | Val Acc: 0.7890 | LR: 8.0e-06\n",
      "Epoch 53/100 | Time: 3.68s | Loss: 0.0049 | Acc: 0.9997 | Val Loss: 1.0373 | Val Acc: 0.7865 | LR: 8.0e-06\n",
      "Epoch 54/100 | Time: 3.75s | Loss: 0.0060 | Acc: 0.9990 | Val Loss: 1.0243 | Val Acc: 0.7900 | LR: 8.0e-06\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 55/100 | Time: 3.65s | Loss: 0.0052 | Acc: 0.9998 | Val Loss: 1.0290 | Val Acc: 0.7880 | LR: 1.6e-06\n",
      "Epoch 56/100 | Time: 3.72s | Loss: 0.0051 | Acc: 0.9995 | Val Loss: 1.0320 | Val Acc: 0.7890 | LR: 1.6e-06\n",
      "Epoch 57/100 | Time: 3.66s | Loss: 0.0065 | Acc: 0.9992 | Val Loss: 1.0332 | Val Acc: 0.7880 | LR: 1.6e-06\n",
      "Epoch 58/100 | Time: 3.73s | Loss: 0.0060 | Acc: 0.9997 | Val Loss: 1.0298 | Val Acc: 0.7895 | LR: 1.6e-06\n",
      "Epoch 59/100 | Time: 3.76s | Loss: 0.0069 | Acc: 0.9987 | Val Loss: 1.0300 | Val Acc: 0.7880 | LR: 1.6e-06\n",
      "Epoch 60/100 | Time: 3.66s | Loss: 0.0053 | Acc: 0.9998 | Val Loss: 1.0320 | Val Acc: 0.7880 | LR: 1.6e-06\n",
      "Epoch 61/100 | Time: 3.72s | Loss: 0.0058 | Acc: 0.9990 | Val Loss: 1.0324 | Val Acc: 0.7885 | LR: 1.6e-06\n",
      "Epoch 62/100 | Time: 3.71s | Loss: 0.0069 | Acc: 0.9985 | Val Loss: 1.0288 | Val Acc: 0.7880 | LR: 1.6e-06\n",
      "Epoch 63/100 | Time: 3.74s | Loss: 0.0065 | Acc: 0.9992 | Val Loss: 1.0339 | Val Acc: 0.7875 | LR: 1.6e-06\n",
      "Epoch 64/100 | Time: 3.75s | Loss: 0.0048 | Acc: 0.9998 | Val Loss: 1.0327 | Val Acc: 0.7870 | LR: 1.6e-06\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "Epoch 65/100 | Time: 3.65s | Loss: 0.0056 | Acc: 0.9992 | Val Loss: 1.0355 | Val Acc: 0.7875 | LR: 3.2e-07\n",
      "Epoch 66/100 | Time: 3.72s | Loss: 0.0056 | Acc: 0.9992 | Val Loss: 1.0351 | Val Acc: 0.7880 | LR: 3.2e-07\n",
      "Epoch 67/100 | Time: 3.67s | Loss: 0.0058 | Acc: 0.9993 | Val Loss: 1.0347 | Val Acc: 0.7875 | LR: 3.2e-07\n",
      "üèÅ Finished training. Best Validation Accuracy: 0.7905\n",
      "\n",
      "================================================================================\n",
      "TRAINING ARCHITECTURE: 'UNet_Audio_Classifier'\n",
      "================================================================================\n",
      "üöÄ Starting training for model: UNet_Audio_Classifier...\n",
      "Epoch 01/100 | Time: 18.07s | Loss: 1.5113 | Acc: 0.4611 | Val Loss: 5.6665 | Val Acc: 0.1000 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 02/100 | Time: 4.24s | Loss: 1.0790 | Acc: 0.6285 | Val Loss: 3.4543 | Val Acc: 0.1355 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 03/100 | Time: 4.32s | Loss: 0.8890 | Acc: 0.6925 | Val Loss: 4.1549 | Val Acc: 0.2520 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 04/100 | Time: 4.26s | Loss: 0.7406 | Acc: 0.7561 | Val Loss: 2.1743 | Val Acc: 0.4405 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 05/100 | Time: 4.32s | Loss: 0.6055 | Acc: 0.7958 | Val Loss: 1.9863 | Val Acc: 0.5770 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 06/100 | Time: 4.27s | Loss: 0.5085 | Acc: 0.8329 | Val Loss: 3.3411 | Val Acc: 0.4465 | LR: 1.0e-03\n",
      "Epoch 07/100 | Time: 4.28s | Loss: 0.4358 | Acc: 0.8564 | Val Loss: 3.2147 | Val Acc: 0.4465 | LR: 1.0e-03\n",
      "Epoch 08/100 | Time: 4.29s | Loss: 0.3562 | Acc: 0.8860 | Val Loss: 3.5477 | Val Acc: 0.4305 | LR: 1.0e-03\n",
      "Epoch 09/100 | Time: 4.30s | Loss: 0.3241 | Acc: 0.8962 | Val Loss: 4.8982 | Val Acc: 0.3365 | LR: 1.0e-03\n",
      "Epoch 10/100 | Time: 4.26s | Loss: 0.2686 | Acc: 0.9135 | Val Loss: 2.0604 | Val Acc: 0.5580 | LR: 1.0e-03\n",
      "Epoch 11/100 | Time: 4.33s | Loss: 0.2524 | Acc: 0.9177 | Val Loss: 2.5130 | Val Acc: 0.5335 | LR: 1.0e-03\n",
      "Epoch 12/100 | Time: 4.24s | Loss: 0.1949 | Acc: 0.9346 | Val Loss: 0.9858 | Val Acc: 0.6865 | LR: 1.0e-03 ‚úÖ\n",
      "Epoch 13/100 | Time: 4.34s | Loss: 0.1642 | Acc: 0.9487 | Val Loss: 2.0084 | Val Acc: 0.6080 | LR: 1.0e-03\n",
      "Epoch 14/100 | Time: 4.28s | Loss: 0.1312 | Acc: 0.9621 | Val Loss: 1.7823 | Val Acc: 0.5780 | LR: 1.0e-03\n",
      "Epoch 15/100 | Time: 4.25s | Loss: 0.1179 | Acc: 0.9633 | Val Loss: 10.4034 | Val Acc: 0.1520 | LR: 1.0e-03\n",
      "Epoch 16/100 | Time: 4.30s | Loss: 0.1061 | Acc: 0.9683 | Val Loss: 3.2977 | Val Acc: 0.4985 | LR: 1.0e-03\n",
      "Epoch 17/100 | Time: 4.31s | Loss: 0.0896 | Acc: 0.9748 | Val Loss: 1.4905 | Val Acc: 0.6370 | LR: 1.0e-03\n",
      "Epoch 18/100 | Time: 4.29s | Loss: 0.0940 | Acc: 0.9698 | Val Loss: 1.7339 | Val Acc: 0.6855 | LR: 1.0e-03\n",
      "Epoch 19/100 | Time: 4.30s | Loss: 0.0994 | Acc: 0.9671 | Val Loss: 4.0519 | Val Acc: 0.4285 | LR: 1.0e-03\n",
      "Epoch 20/100 | Time: 4.31s | Loss: 0.0719 | Acc: 0.9771 | Val Loss: 3.0823 | Val Acc: 0.5610 | LR: 1.0e-03\n",
      "Epoch 21/100 | Time: 4.30s | Loss: 0.0633 | Acc: 0.9813 | Val Loss: 2.8126 | Val Acc: 0.6145 | LR: 1.0e-03\n",
      "Epoch 22/100 | Time: 4.24s | Loss: 0.0741 | Acc: 0.9745 | Val Loss: 4.3803 | Val Acc: 0.5590 | LR: 1.0e-03\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 23/100 | Time: 4.32s | Loss: 0.0373 | Acc: 0.9908 | Val Loss: 1.0412 | Val Acc: 0.7635 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 24/100 | Time: 4.29s | Loss: 0.0267 | Acc: 0.9928 | Val Loss: 1.0724 | Val Acc: 0.7840 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 25/100 | Time: 4.24s | Loss: 0.0181 | Acc: 0.9965 | Val Loss: 0.7625 | Val Acc: 0.8130 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 26/100 | Time: 4.31s | Loss: 0.0163 | Acc: 0.9962 | Val Loss: 0.8322 | Val Acc: 0.7945 | LR: 2.0e-04\n",
      "Epoch 27/100 | Time: 4.24s | Loss: 0.0177 | Acc: 0.9963 | Val Loss: 1.0533 | Val Acc: 0.7760 | LR: 2.0e-04\n",
      "Epoch 28/100 | Time: 4.32s | Loss: 0.0142 | Acc: 0.9970 | Val Loss: 0.8732 | Val Acc: 0.7990 | LR: 2.0e-04\n",
      "Epoch 29/100 | Time: 4.29s | Loss: 0.0123 | Acc: 0.9977 | Val Loss: 0.7055 | Val Acc: 0.8265 | LR: 2.0e-04 ‚úÖ\n",
      "Epoch 30/100 | Time: 4.30s | Loss: 0.0121 | Acc: 0.9980 | Val Loss: 0.7584 | Val Acc: 0.8195 | LR: 2.0e-04\n",
      "Epoch 31/100 | Time: 4.28s | Loss: 0.0099 | Acc: 0.9990 | Val Loss: 0.9587 | Val Acc: 0.7890 | LR: 2.0e-04\n",
      "Epoch 32/100 | Time: 4.29s | Loss: 0.0126 | Acc: 0.9973 | Val Loss: 1.1451 | Val Acc: 0.7810 | LR: 2.0e-04\n",
      "Epoch 33/100 | Time: 4.28s | Loss: 0.0110 | Acc: 0.9980 | Val Loss: 0.8138 | Val Acc: 0.8150 | LR: 2.0e-04\n",
      "Epoch 34/100 | Time: 4.29s | Loss: 0.0087 | Acc: 0.9990 | Val Loss: 0.8126 | Val Acc: 0.8160 | LR: 2.0e-04\n",
      "Epoch 35/100 | Time: 4.24s | Loss: 0.0121 | Acc: 0.9972 | Val Loss: 1.7521 | Val Acc: 0.6970 | LR: 2.0e-04\n",
      "Epoch 36/100 | Time: 4.28s | Loss: 0.0089 | Acc: 0.9988 | Val Loss: 0.8262 | Val Acc: 0.8220 | LR: 2.0e-04\n",
      "Epoch 37/100 | Time: 4.32s | Loss: 0.0084 | Acc: 0.9987 | Val Loss: 0.9508 | Val Acc: 0.8055 | LR: 2.0e-04\n",
      "Epoch 38/100 | Time: 4.30s | Loss: 0.0107 | Acc: 0.9978 | Val Loss: 1.0376 | Val Acc: 0.8005 | LR: 2.0e-04\n",
      "Epoch 39/100 | Time: 4.30s | Loss: 0.0097 | Acc: 0.9983 | Val Loss: 0.9707 | Val Acc: 0.7870 | LR: 2.0e-04\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 40/100 | Time: 4.28s | Loss: 0.0085 | Acc: 0.9982 | Val Loss: 0.7887 | Val Acc: 0.8230 | LR: 4.0e-05\n",
      "Epoch 41/100 | Time: 4.29s | Loss: 0.0058 | Acc: 0.9995 | Val Loss: 0.7473 | Val Acc: 0.8300 | LR: 4.0e-05 ‚úÖ\n",
      "Epoch 42/100 | Time: 4.30s | Loss: 0.0066 | Acc: 0.9990 | Val Loss: 0.7644 | Val Acc: 0.8340 | LR: 4.0e-05 ‚úÖ\n",
      "Epoch 43/100 | Time: 4.28s | Loss: 0.0056 | Acc: 0.9990 | Val Loss: 0.7807 | Val Acc: 0.8320 | LR: 4.0e-05\n",
      "Epoch 44/100 | Time: 4.27s | Loss: 0.0077 | Acc: 0.9988 | Val Loss: 0.7339 | Val Acc: 0.8310 | LR: 4.0e-05\n",
      "Epoch 45/100 | Time: 4.27s | Loss: 0.0064 | Acc: 0.9985 | Val Loss: 0.7503 | Val Acc: 0.8330 | LR: 4.0e-05\n",
      "Epoch 46/100 | Time: 4.36s | Loss: 0.0062 | Acc: 0.9992 | Val Loss: 0.8463 | Val Acc: 0.8125 | LR: 4.0e-05\n",
      "Epoch 47/100 | Time: 4.37s | Loss: 0.0059 | Acc: 0.9987 | Val Loss: 0.8019 | Val Acc: 0.8285 | LR: 4.0e-05\n",
      "Epoch 48/100 | Time: 4.28s | Loss: 0.0063 | Acc: 0.9988 | Val Loss: 0.7224 | Val Acc: 0.8320 | LR: 4.0e-05\n",
      "Epoch 49/100 | Time: 4.29s | Loss: 0.0066 | Acc: 0.9992 | Val Loss: 0.7381 | Val Acc: 0.8330 | LR: 4.0e-05\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 50/100 | Time: 4.29s | Loss: 0.0078 | Acc: 0.9983 | Val Loss: 0.7442 | Val Acc: 0.8350 | LR: 8.0e-06 ‚úÖ\n",
      "Epoch 51/100 | Time: 4.30s | Loss: 0.0065 | Acc: 0.9987 | Val Loss: 0.7383 | Val Acc: 0.8350 | LR: 8.0e-06\n",
      "Epoch 52/100 | Time: 4.32s | Loss: 0.0055 | Acc: 0.9993 | Val Loss: 0.7506 | Val Acc: 0.8365 | LR: 8.0e-06 ‚úÖ\n",
      "Epoch 53/100 | Time: 4.28s | Loss: 0.0057 | Acc: 0.9992 | Val Loss: 0.7655 | Val Acc: 0.8350 | LR: 8.0e-06\n",
      "Epoch 54/100 | Time: 4.33s | Loss: 0.0063 | Acc: 0.9983 | Val Loss: 0.7855 | Val Acc: 0.8340 | LR: 8.0e-06\n",
      "Epoch 55/100 | Time: 4.34s | Loss: 0.0062 | Acc: 0.9990 | Val Loss: 0.7620 | Val Acc: 0.8335 | LR: 8.0e-06\n",
      "Epoch 56/100 | Time: 4.23s | Loss: 0.0050 | Acc: 0.9992 | Val Loss: 0.7545 | Val Acc: 0.8340 | LR: 8.0e-06\n",
      "Epoch 57/100 | Time: 4.29s | Loss: 0.0063 | Acc: 0.9985 | Val Loss: 0.7597 | Val Acc: 0.8345 | LR: 8.0e-06\n",
      "Epoch 58/100 | Time: 4.32s | Loss: 0.0049 | Acc: 0.9993 | Val Loss: 0.7584 | Val Acc: 0.8315 | LR: 8.0e-06\n",
      "Epoch 59/100 | Time: 4.33s | Loss: 0.0061 | Acc: 0.9987 | Val Loss: 0.7827 | Val Acc: 0.8325 | LR: 8.0e-06\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 60/100 | Time: 4.28s | Loss: 0.0050 | Acc: 0.9992 | Val Loss: 0.7719 | Val Acc: 0.8330 | LR: 1.6e-06\n",
      "Epoch 61/100 | Time: 4.29s | Loss: 0.0067 | Acc: 0.9985 | Val Loss: 0.7651 | Val Acc: 0.8325 | LR: 1.6e-06\n",
      "Epoch 62/100 | Time: 4.28s | Loss: 0.0046 | Acc: 0.9993 | Val Loss: 0.7615 | Val Acc: 0.8325 | LR: 1.6e-06\n",
      "Epoch 63/100 | Time: 4.29s | Loss: 0.0064 | Acc: 0.9987 | Val Loss: 0.7601 | Val Acc: 0.8320 | LR: 1.6e-06\n",
      "Epoch 64/100 | Time: 4.24s | Loss: 0.0041 | Acc: 1.0000 | Val Loss: 0.7591 | Val Acc: 0.8330 | LR: 1.6e-06\n",
      "Epoch 65/100 | Time: 4.29s | Loss: 0.0051 | Acc: 0.9993 | Val Loss: 0.7591 | Val Acc: 0.8320 | LR: 1.6e-06\n",
      "Epoch 66/100 | Time: 4.29s | Loss: 0.0055 | Acc: 0.9990 | Val Loss: 0.7624 | Val Acc: 0.8315 | LR: 1.6e-06\n",
      "Epoch 67/100 | Time: 4.30s | Loss: 0.0058 | Acc: 0.9987 | Val Loss: 0.7594 | Val Acc: 0.8340 | LR: 1.6e-06\n",
      "Epoch 68/100 | Time: 4.30s | Loss: 0.0063 | Acc: 0.9987 | Val Loss: 0.7626 | Val Acc: 0.8325 | LR: 1.6e-06\n",
      "Epoch 69/100 | Time: 4.27s | Loss: 0.0057 | Acc: 0.9993 | Val Loss: 0.7604 | Val Acc: 0.8330 | LR: 1.6e-06\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "Epoch 70/100 | Time: 4.29s | Loss: 0.0051 | Acc: 0.9990 | Val Loss: 0.7631 | Val Acc: 0.8315 | LR: 3.2e-07\n",
      "Epoch 71/100 | Time: 4.24s | Loss: 0.0054 | Acc: 0.9992 | Val Loss: 0.7625 | Val Acc: 0.8325 | LR: 3.2e-07\n",
      "Epoch 72/100 | Time: 4.29s | Loss: 0.0043 | Acc: 1.0000 | Val Loss: 0.7632 | Val Acc: 0.8305 | LR: 3.2e-07\n",
      "üèÅ Finished training. Best Validation Accuracy: 0.8365\n",
      "\n",
      "üéâ FINAL COMPARATIVE ANALYSIS COMPLETED üéâ\n",
      "\n",
      "Final Leaderboard (sorted by Best Validation Accuracy):\n",
      "| Model                 |   Test_Accuracy |   Best_Val_Accuracy |   Epochs_Run |\n",
      "|:----------------------|----------------:|--------------------:|-------------:|\n",
      "| UNet_Audio_Classifier |          0.835  |              0.8365 |           72 |\n",
      "| ResSE_AudioCNN        |          0.7895 |              0.7905 |           67 |\n",
      "| Efficient_VGG         |          0.7035 |              0.7385 |           67 |\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 3: FINAL, FOCUSED TRAINING FRAMEWORK\n",
    "# ===================================================================\n",
    "# This cell orchestrates the definitive training run for our three\n",
    "# curated candidate architectures. It uses the same robust data pipelines\n",
    "# and logger, but focuses only on the models relevant to our final narrative.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers, callbacks\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 0. DATA LOADING AND PREPARATION (Unchanged)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"Loading pre-processed data...\")\n",
    "try:\n",
    "    X_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_train.npy'))\n",
    "    y_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_train.npy'))\n",
    "    X_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_val.npy'))\n",
    "    y_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_val.npy'))\n",
    "    X_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_test.npy'))\n",
    "    y_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_test.npy'))\n",
    "    with open(os.path.join(PROCESSED_DATA_PATH, 'label_encoder.pkl'), 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "\n",
    "    y_train_cat = to_categorical(y_train)\n",
    "    y_val_cat = to_categorical(y_val)\n",
    "    y_test_cat = to_categorical(y_test)\n",
    "    \n",
    "    print(\"‚úÖ Data successfully loaded and prepared.\")\n",
    "except FileNotFoundError:\n",
    "    raise RuntimeError(\"ERROR: Data files not found. Please run the '00_Data_Preprocessing' notebook first.\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. DATA AUGMENTATION & CUSTOM CALLBACK (Unchanged)\n",
    "# -------------------------------------------------------------------\n",
    "@tf.function\n",
    "def spec_augment_tf(spectrogram, label):\n",
    "    \"\"\"Applies frequency and time masking to a spectrogram.\"\"\"\n",
    "    aug_spec = tf.identity(spectrogram)\n",
    "    # Frequency Masking\n",
    "    freq_bins = tf.shape(aug_spec)[0]\n",
    "    f_param = tf.cast(tf.cast(freq_bins, tf.float32) * 0.2, tf.int32)\n",
    "    if f_param > 1:\n",
    "        f = tf.random.uniform(shape=(), minval=1, maxval=f_param, dtype=tf.int32)\n",
    "        f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_bins - f, dtype=tf.int32)\n",
    "        mask_freq_values = tf.concat([tf.ones((f0,)), tf.zeros((f,)), tf.ones((freq_bins - f0 - f,))], axis=0)\n",
    "        freq_mask = tf.reshape(tf.cast(mask_freq_values, aug_spec.dtype), (freq_bins, 1, 1))\n",
    "        aug_spec *= freq_mask\n",
    "    # Time Masking\n",
    "    time_steps = tf.shape(aug_spec)[1]\n",
    "    t_param = tf.cast(tf.cast(time_steps, tf.float32) * 0.2, tf.int32)\n",
    "    if t_param > 1:\n",
    "        t = tf.random.uniform(shape=(), minval=1, maxval=t_param, dtype=tf.int32)\n",
    "        t0 = tf.random.uniform(shape=(), minval=0, maxval=time_steps - t, dtype=tf.int32)\n",
    "        mask_time_values = tf.concat([tf.ones((t0,)), tf.zeros((t,)), tf.ones((time_steps - t0 - t,))], axis=0)\n",
    "        time_mask = tf.reshape(tf.cast(mask_time_values, aug_spec.dtype), (1, time_steps, 1))\n",
    "        aug_spec *= time_mask\n",
    "    return aug_spec, label\n",
    "\n",
    "class RichLoggerCallback(callbacks.Callback):\n",
    "    \"\"\"A custom Keras callback for clean, informative, and professional logging.\"\"\"\n",
    "    def __init__(self, total_epochs):\n",
    "        super().__init__()\n",
    "        self.total_epochs = total_epochs\n",
    "        self.best_val_accuracy = 0\n",
    "        self.start_time = 0\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(f\"üöÄ Starting training for model: {self.model.name}...\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.start_time\n",
    "        lr = self.model.optimizer.learning_rate\n",
    "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            lr = lr(self.model.optimizer.iterations)\n",
    "        lr_value = lr.numpy() if hasattr(lr, 'numpy') else lr\n",
    "        is_best = \"\"\n",
    "        if logs['val_accuracy'] > self.best_val_accuracy:\n",
    "            self.best_val_accuracy = logs['val_accuracy']\n",
    "            is_best = \" ‚úÖ\"\n",
    "        log_str = (f\"Epoch {epoch + 1:02d}/{self.total_epochs} | \"\n",
    "                   f\"Time: {epoch_time:.2f}s | \"\n",
    "                   f\"Loss: {logs['loss']:.4f} | Acc: {logs['accuracy']:.4f} | \"\n",
    "                   f\"Val Loss: {logs['val_loss']:.4f} | Val Acc: {logs['val_accuracy']:.4f} | \"\n",
    "                   f\"LR: {lr_value:.1e}{is_best}\")\n",
    "        print(log_str)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(f\"üèÅ Finished training. Best Validation Accuracy: {self.best_val_accuracy:.4f}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. EXPERIMENT ORCHESTRATION CLASS (Unchanged)\n",
    "# -------------------------------------------------------------------\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Orchestrates the training and evaluation of multiple models.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "\n",
    "    def run_experiments(self, model_factories, train_data, val_data, test_data, epochs, patience):\n",
    "        for model_name, model_factory_fn in model_factories.items():\n",
    "            print(f\"\\n{'='*80}\\nTRAINING ARCHITECTURE: '{model_name}'\\n{'='*80}\")\n",
    "            try:\n",
    "                # Clear session to ensure a clean slate for each model\n",
    "                keras.backend.clear_session()\n",
    "                \n",
    "                model = model_factory_fn()\n",
    "                optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                \n",
    "                callbacks_list = [\n",
    "                    RichLoggerCallback(total_epochs=epochs),\n",
    "                    callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, restore_best_weights=True, verbose=0),\n",
    "                    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=patience//2, verbose=1),\n",
    "                    callbacks.ModelCheckpoint(os.path.join(MODELS_PATH, f\"{model_name}_best.keras\"), \n",
    "                                              monitor='val_accuracy', save_best_only=True, verbose=0)\n",
    "                ]\n",
    "                \n",
    "                history = model.fit(train_data, epochs=epochs, validation_data=val_data, callbacks=callbacks_list, verbose=0)\n",
    "                \n",
    "                test_loss, test_acc = model.evaluate(test_data, verbose=0)\n",
    "                self.results.append({\n",
    "                    'Model': model_name,\n",
    "                    'Test_Accuracy': test_acc,\n",
    "                    'Best_Val_Accuracy': max(history.history.get('val_accuracy', [0])),\n",
    "                    'Epochs_Run': len(history.history['val_accuracy']),\n",
    "                })\n",
    "            except Exception:\n",
    "                print(f\"‚ùå ERROR during training of [{model_name}]:\")\n",
    "                traceback.print_exc()\n",
    "        return pd.DataFrame(self.results)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. EXPERIMENT CONFIGURATION & EXECUTION (CORRECTED)\n",
    "# -------------------------------------------------------------------\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "PATIENCE = 20\n",
    "\n",
    "# Data Pipelines\n",
    "print(\"\\nConfiguring JIT data pipelines...\")\n",
    "train_pipeline = (tf.data.Dataset.from_tensor_slices((X_train, y_train_cat)).shuffle(len(X_train))\n",
    "                  .map(spec_augment_tf, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "val_pipeline = (tf.data.Dataset.from_tensor_slices((X_val, y_val_cat)).batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "test_pipeline = (tf.data.Dataset.from_tensor_slices((X_test, y_test_cat)).batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "\n",
    "# ===================================================================\n",
    "# *** FIX: Define the model factories correctly for the final run ***\n",
    "# ===================================================================\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = y_train_cat.shape[1]\n",
    "\n",
    "# 1. Get the dictionary of builder methods from our curated factory\n",
    "final_model_builders = ModelFactory.get_final_models()\n",
    "\n",
    "# 2. Create the final dictionary of callable functions for the evaluator.\n",
    "#    The lambda now correctly captures the builder 'b' for each item.\n",
    "model_factories_to_run = {\n",
    "    name: (lambda b=builder: b(input_shape, num_classes))\n",
    "    for name, builder in final_model_builders.items()\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Ready to run final tournament for the following models: {list(model_factories_to_run.keys())}\")\n",
    "\n",
    "# Execute the comparative analysis\n",
    "evaluator = ModelEvaluator()\n",
    "results_df = evaluator.run_experiments(\n",
    "    model_factories_to_run, train_pipeline, val_pipeline, test_pipeline, EPOCHS, PATIENCE\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. REPORTING (Unchanged)\n",
    "# -------------------------------------------------------------------\n",
    "if not results_df.empty:\n",
    "    # Save the definitive results\n",
    "    results_df.to_csv(os.path.join(REPORTS_PATH, 'training_summary_final.csv'), index=False)\n",
    "    \n",
    "    print(\"\\nüéâ FINAL COMPARATIVE ANALYSIS COMPLETED üéâ\")\n",
    "    print(\"\\nFinal Leaderboard (sorted by Best Validation Accuracy):\")\n",
    "    print(results_df.sort_values(by='Best_Val_Accuracy', ascending=False).to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
