{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d52819",
   "metadata": {},
   "source": [
    "# Tabla Taala — 01 Model Training\n",
    "\n",
    "Train a small AudioCNN on the Tabla Taala dataset using mel-spectrograms, SpecAugment, label smoothing, and class weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "41ae2629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUs visible or CPU forced; running on CPU.\n",
      "Config OK {'BATCH': 48, 'EPOCHS': 70, 'PATIENCE': 10, 'LR': 0.0005, 'SMOOTH': 0.02, 'SPEC_AUG': True, 'SPEC_MASKS': (8, 16, 1), 'INIT_FROM_GTZAN': True, 'FORCE_RETRAIN': False, 'RESUME': False, 'SKIP_IF_CKPT': False}\n"
     ]
    }
   ],
   "source": [
    "# 1) Imports & Config\n",
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "\n",
    "# Environment toggles (set before importing TensorFlow)\n",
    "os.environ.setdefault('KERAS_BACKEND', 'tensorflow')\n",
    "os.environ.setdefault('TF_DETERMINISTIC_OPS', '1')\n",
    "os.environ.setdefault('TF_CUDNN_DETERMINISTIC', '1')\n",
    "os.environ.setdefault('TRAIN_ON_GPU', '1')\n",
    "os.environ.setdefault('TAB_FORCE_CPU', '0')\n",
    "os.environ.setdefault('TAB_USE_MIXED_PRECISION', '1')\n",
    "os.environ.setdefault('TAB_ENABLE_TF32', '1')\n",
    "# Checkpoint/training flow toggles\n",
    "os.environ.setdefault('TAB_FORCE_RETRAIN', '0')\n",
    "os.environ.setdefault('TAB_RESUME_FROM_CKPT', '0')\n",
    "os.environ.setdefault('SKIP_TRAIN_IF_CKPT', '0')\n",
    "# Data/cache/aug toggles\n",
    "os.environ.setdefault('TAB_CACHE_TRAIN', '0')  # default off to keep per-epoch random crops\n",
    "os.environ.setdefault('TAB_SPEC_FREQ_MASK', '4')   # soften augmentation for Tabla\n",
    "os.environ.setdefault('TAB_SPEC_TIME_MASK', '8')\n",
    "os.environ.setdefault('TAB_SPEC_NUM_MASKS', '1')\n",
    "# Init from GTZAN checkpoint (transfer feature weights; final layer skipped)\n",
    "os.environ.setdefault('TAB_INIT_FROM_GTZAN', '1')\n",
    "\n",
    "if os.environ.get('TAB_FORCE_CPU','0') == '1' or os.environ.get('TRAIN_ON_GPU','0') != '1':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Seeds and reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "try:\n",
    "    tf.random.set_seed(RANDOM_STATE)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Optional: GPU memory growth and mixed precision\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU') if os.environ.get('TAB_FORCE_CPU','0') != '1' else []\n",
    "    for g in gpus:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    if gpus:\n",
    "        print(f'GPUs found: {len(gpus)} — enabled memory growth')\n",
    "        if os.environ.get('TAB_USE_MIXED_PRECISION','1') == '1':\n",
    "            try:\n",
    "                from keras import mixed_precision\n",
    "                mixed_precision.set_global_policy('mixed_float16')\n",
    "                print('Mixed precision policy: mixed_float16')\n",
    "            except Exception as e:\n",
    "                print('Mixed precision unavailable:', e)\n",
    "        if os.environ.get('TAB_ENABLE_TF32','1') == '1':\n",
    "            try:\n",
    "                tf.config.experimental.enable_tensor_float_32_execution(True)\n",
    "                print('TF32 enabled')\n",
    "            except Exception as e:\n",
    "                print('TF32 enable failed:', e)\n",
    "    else:\n",
    "        print('No GPUs visible or CPU forced; running on CPU.')\n",
    "except Exception as e:\n",
    "    print('GPU setup note:', e)\n",
    "\n",
    "# Audio & feature params\n",
    "SR = 22050\n",
    "DURATION = 3.0\n",
    "TARGET_SAMPLES = int(SR * DURATION)\n",
    "N_FFT = 1024\n",
    "HOP = 512\n",
    "N_MELS = 128\n",
    "\n",
    "# Training params (GTZAN-aligned defaults with Tabla tuning)\n",
    "BATCH_SIZE = int(os.environ.get('TAB_BATCH','48'))\n",
    "EPOCHS = int(os.environ.get('TAB_EPOCHS','70'))\n",
    "PATIENCE = int(os.environ.get('TAB_PATIENCE','10'))\n",
    "LR = float(os.environ.get('TAB_LR','5e-4'))\n",
    "LABEL_SMOOTHING = float(os.environ.get('TAB_LABEL_SMOOTHING','0.02'))\n",
    "SPEC_AUGMENT = os.environ.get('TAB_SPEC_AUGMENT','1') == '1'\n",
    "SPEC_FREQ_MASK = int(os.environ.get('TAB_SPEC_FREQ_MASK','4'))\n",
    "SPEC_TIME_MASK = int(os.environ.get('TAB_SPEC_TIME_MASK','8'))\n",
    "SPEC_NUM_MASKS = int(os.environ.get('TAB_SPEC_NUM_MASKS','1'))\n",
    "TAB_INIT_FROM_GTZAN = os.environ.get('TAB_INIT_FROM_GTZAN','1') == '1'\n",
    "TAB_FORCE_RETRAIN = os.environ.get('TAB_FORCE_RETRAIN','0') == '1'\n",
    "TAB_RESUME_FROM_CKPT = os.environ.get('TAB_RESUME_FROM_CKPT','0') == '1'\n",
    "SKIP_TRAIN_IF_CKPT = os.environ.get('SKIP_TRAIN_IF_CKPT','0') == '1'\n",
    "\n",
    "print('Config OK', {\n",
    "  'BATCH': BATCH_SIZE, 'EPOCHS': EPOCHS, 'PATIENCE': PATIENCE, 'LR': LR,\n",
    "  'SMOOTH': LABEL_SMOOTHING, 'SPEC_AUG': SPEC_AUGMENT,\n",
    "  'SPEC_MASKS': (SPEC_FREQ_MASK, SPEC_TIME_MASK, SPEC_NUM_MASKS),\n",
    "  'INIT_FROM_GTZAN': TAB_INIT_FROM_GTZAN,\n",
    "  'FORCE_RETRAIN': TAB_FORCE_RETRAIN, 'RESUME': TAB_RESUME_FROM_CKPT, 'SKIP_IF_CKPT': SKIP_TRAIN_IF_CKPT\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "498a970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Addhatrital', 'Bhajani', 'Dadra', 'Deepchandi', 'Ektal', 'Jhaptal', 'Rupak', 'Trital']\n",
      "Split sizes -> train: 448 val: 56 test: 57\n",
      "Labels missing in any split (ok if expected): []\n",
      "\n",
      "Class counts (train):\n",
      "label\n",
      "Trital         79\n",
      "Addhatrital    62\n",
      "Dadra          58\n",
      "Bhajani        57\n",
      "Deepchandi     48\n",
      "Ektal          48\n",
      "Jhaptal        48\n",
      "Rupak          48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class counts (val):\n",
      "label\n",
      "Trital         10\n",
      "Addhatrital     8\n",
      "Bhajani         7\n",
      "Dadra           7\n",
      "Jhaptal         6\n",
      "Rupak           6\n",
      "Deepchandi      6\n",
      "Ektal           6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class counts (test):\n",
      "label\n",
      "Trital         10\n",
      "Bhajani         8\n",
      "Addhatrital     8\n",
      "Dadra           7\n",
      "Rupak           6\n",
      "Deepchandi      6\n",
      "Jhaptal         6\n",
      "Ektal           6\n",
      "Name: count, dtype: int64\n",
      "Paths OK\n"
     ]
    }
   ],
   "source": [
    "# 2) Paths & Load CSV splits\n",
    "def find_project_root(start: Path, markers=('requirements.txt', 'README.md')) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for p in [cur] + list(cur.parents):\n",
    "        if all((p / m).exists() for m in markers):\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "PROJECT_ROOT = find_project_root(Path.cwd())\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "PROC_DIR = DATA_DIR / 'processed_tabla'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "REPORTS_DIR = PROJECT_ROOT / 'reports'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_csv = PROC_DIR / 'train_split.csv'\n",
    "val_csv   = PROC_DIR / 'val_split.csv'\n",
    "test_csv  = PROC_DIR / 'test_split.csv'\n",
    "le_json   = PROC_DIR / 'label_encoder.json'\n",
    "assert train_csv.exists() and val_csv.exists() and test_csv.exists(), 'Split CSVs not found in processed_tabla.'\n",
    "\n",
    "train_df = pd.read_csv(train_csv)\n",
    "val_df   = pd.read_csv(val_csv)\n",
    "test_df  = pd.read_csv(test_csv)\n",
    "with open(le_json) as f:\n",
    "    classes = json.load(f)['classes']\n",
    "num_classes = len(classes)\n",
    "label2idx = {c: i for i, c in enumerate(classes)}\n",
    "print('Classes:', classes)\n",
    "print('Split sizes -> train:', len(train_df), 'val:', len(val_df), 'test:', len(test_df))\n",
    "\n",
    "# Sanitize label strings: strip whitespace\n",
    "for df in (train_df, val_df, test_df):\n",
    "    df['label'] = df['label'].astype(str).str.strip()\n",
    "\n",
    "# Basic sanity\n",
    "assert 'audio_path' in train_df.columns and 'label' in train_df.columns, 'CSV missing required columns'\n",
    "\n",
    "# Validate: labels present in encoder\n",
    "enc_set = set(classes)\n",
    "train_set = set(train_df['label'].unique())\n",
    "val_set = set(val_df['label'].unique())\n",
    "test_set = set(test_df['label'].unique())\n",
    "missing_in_encoder = sorted((train_set | val_set | test_set) - enc_set)\n",
    "if missing_in_encoder:\n",
    "    print('Warning: labels in splits not present in encoder:', missing_in_encoder)\n",
    "missing_in_splits = sorted(enc_set - (train_set | val_set | test_set))\n",
    "print('Labels missing in any split (ok if expected):', missing_in_splits)\n",
    "\n",
    "# Class distribution diagnostics\n",
    "print('\\nClass counts (train):')\n",
    "print(train_df['label'].value_counts())\n",
    "print('\\nClass counts (val):')\n",
    "print(val_df['label'].value_counts())\n",
    "print('\\nClass counts (test):')\n",
    "print(test_df['label'].value_counts())\n",
    "\n",
    "# Validate audio paths exist\n",
    "for name, df in [('train', train_df), ('val', val_df), ('test', test_df)]:\n",
    "    missing_paths = (~df['audio_path'].astype(str).apply(lambda p: Path(p).exists())).sum()\n",
    "    if missing_paths:\n",
    "        print(f'Warning: {missing_paths} missing audio files in {name} split')\n",
    "\n",
    "print('Paths OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "10cb6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_augment_tf(S, freq_mask_param=SPEC_FREQ_MASK, time_mask_param=SPEC_TIME_MASK):\n",
    "    # S: (n_mels, time)\n",
    "    shape = tf.shape(S, out_type=tf.int32)\n",
    "    n_mels = tf.gather(shape, 0)\n",
    "    t = tf.gather(shape, 1)\n",
    "\n",
    "    def mask_axis(x, max_width, axis):\n",
    "        width = tf.random.uniform([], minval=0, maxval=max_width + 1, dtype=tf.int32, seed=RANDOM_STATE)\n",
    "        if axis == 0:\n",
    "            # Frequency masking\n",
    "            start_max = tf.maximum(n_mels - width, 1)\n",
    "            start = tf.random.uniform([], 0, start_max, dtype=tf.int32, seed=RANDOM_STATE)\n",
    "            after = tf.maximum(n_mels - start - width, 0)\n",
    "\n",
    "            mask = tf.concat([\n",
    "                tf.ones(tf.stack([start, t]), dtype=x.dtype),\n",
    "                tf.zeros(tf.stack([width, t]), dtype=x.dtype),\n",
    "                tf.ones(tf.stack([after, t]), dtype=x.dtype),\n",
    "            ], axis=0)\n",
    "        else:\n",
    "            # Time masking\n",
    "            start_max = tf.maximum(t - width, 1)\n",
    "            start = tf.random.uniform([], 0, start_max, dtype=tf.int32, seed=RANDOM_STATE)\n",
    "            after = tf.maximum(t - start - width, 0)\n",
    "\n",
    "            mask = tf.concat([\n",
    "                tf.ones(tf.stack([n_mels, start]), dtype=x.dtype),\n",
    "                tf.zeros(tf.stack([n_mels, width]), dtype=x.dtype),\n",
    "                tf.ones(tf.stack([n_mels, after]), dtype=x.dtype),\n",
    "            ], axis=1)\n",
    "\n",
    "        return x * mask\n",
    "\n",
    "    S = mask_axis(S, freq_mask_param, axis=0)\n",
    "    S = mask_axis(S, time_mask_param, axis=1)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66357dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded arrays: (448, 128, 130, 1) (56, 128, 130, 1) (57, 128, 130, 1)\n",
      "Input shape will be: (128, 130, 1)\n",
      "Datasets ready (array-based)\n"
     ]
    }
   ],
   "source": [
    "# 4) Load precomputed arrays (processed_tabla) and build fast tf.data pipelines\n",
    "from pathlib import Path\n",
    "import numpy as np, tensorflow as tf\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = (Path.cwd()).resolve().parents[1]\n",
    "PROCESSED_TABLA = PROJECT_ROOT / 'data' / 'processed_tabla'\n",
    "\n",
    "# Arrays (already scaled in 00_Setup notebook)\n",
    "X_train = np.load(PROCESSED_TABLA/'X_train.npy', mmap_mode='r')\n",
    "y_train = np.load(PROCESSED_TABLA/'y_train.npy', mmap_mode='r')\n",
    "X_val   = np.load(PROCESSED_TABLA/'X_val.npy',   mmap_mode='r')\n",
    "y_val   = np.load(PROCESSED_TABLA/'y_val.npy',   mmap_mode='r')\n",
    "X_test  = np.load(PROCESSED_TABLA/'X_test.npy',  mmap_mode='r')\n",
    "y_test  = np.load(PROCESSED_TABLA/'y_test.npy',  mmap_mode='r')\n",
    "\n",
    "# Ensure channel dim (N, M, T, 1)\n",
    "if X_train.ndim == 3: X_train = X_train[..., None]\n",
    "if X_val.ndim   == 3: X_val   = X_val[..., None]\n",
    "if X_test.ndim  == 3: X_test  = X_test[..., None]\n",
    "\n",
    "print('Loaded arrays:', X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# Vectorized SpecAugment (batch) like INDIAN\n",
    "\n",
    "def batch_spec_augment(mels, freq_mask_param=SPEC_FREQ_MASK, time_mask_param=SPEC_TIME_MASK, num_masks=SPEC_NUM_MASKS):\n",
    "    B = tf.shape(mels)[0]\n",
    "    M = tf.shape(mels)[1]\n",
    "    T = tf.shape(mels)[2]\n",
    "    x = mels\n",
    "    for _ in range(num_masks):\n",
    "        if freq_mask_param > 0:\n",
    "            f = tf.random.uniform([B, 1, 1, 1], 0, freq_mask_param + 1, dtype=tf.int32)\n",
    "            f = tf.minimum(f, M)\n",
    "            f0_max = tf.maximum(M - f, 1)\n",
    "            f0 = tf.cast(tf.floor(tf.random.uniform([B, 1, 1, 1]) * tf.cast(f0_max, tf.float32)), tf.int32)\n",
    "            freq_idx = tf.reshape(tf.range(M, dtype=tf.int32), [1, M, 1, 1])\n",
    "            freq_mask = (freq_idx >= f0) & (freq_idx < (f0 + f))\n",
    "            freq_mask = tf.broadcast_to(freq_mask, [B, M, T, 1])\n",
    "            x = tf.where(freq_mask, tf.zeros([], dtype=x.dtype), x)\n",
    "        if time_mask_param > 0:\n",
    "            t = tf.random.uniform([B, 1, 1, 1], 0, time_mask_param + 1, dtype=tf.int32)\n",
    "            t = tf.minimum(t, T)\n",
    "            t0_max = tf.maximum(T - t, 1)\n",
    "            t0 = tf.cast(tf.floor(tf.random.uniform([B, 1, 1, 1]) * tf.cast(t0_max, tf.float32)), tf.int32)\n",
    "            time_idx = tf.reshape(tf.range(T, dtype=tf.int32), [1, 1, T, 1])\n",
    "            time_mask = (time_idx >= t0) & (time_idx < (t0 + t))\n",
    "            time_mask = tf.broadcast_to(time_mask, [B, M, T, 1])\n",
    "            x = tf.where(time_mask, tf.zeros([], dtype=x.dtype), x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Build datasets from arrays (fast)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def ds_with_optional_aug(X, y_int, batch_size, training: bool):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y_int))\n",
    "    if training:\n",
    "        ds = ds.shuffle(min(10000, X.shape[0]), seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
    "    # Do not drop remainder for val/test; only drop on training for stable BN stats\n",
    "    ds = ds.batch(batch_size, drop_remainder=training)\n",
    "    # One-hot inside the pipeline to avoid expanding memory upfront\n",
    "    def _one_hot(mel, y):\n",
    "        return mel, tf.one_hot(tf.cast(y, tf.int32), depth=num_classes)\n",
    "    ds = ds.map(_one_hot, num_parallel_calls=AUTOTUNE)\n",
    "    if training and SPEC_AUGMENT:\n",
    "        def _aug(mel, y):\n",
    "            mel = batch_spec_augment(mel, SPEC_FREQ_MASK, SPEC_TIME_MASK, num_masks=SPEC_NUM_MASKS)\n",
    "            return mel, y\n",
    "        ds = ds.map(_aug, num_parallel_calls=AUTOTUNE, deterministic=False)\n",
    "    return ds.prefetch(AUTOTUNE)\n",
    "\n",
    "train_ds = ds_with_optional_aug(X_train, y_train, BATCH_SIZE, training=True)\n",
    "val_ds   = ds_with_optional_aug(X_val,   y_val,   BATCH_SIZE, training=False)\n",
    "test_ds  = ds_with_optional_aug(X_test,  y_test,  BATCH_SIZE, training=False)\n",
    "\n",
    "# Input shape inferred from arrays\n",
    "N_MELS_FIXED, T_FRAMES = int(X_train.shape[1]), int(X_train.shape[2])\n",
    "print('Input shape will be:', (N_MELS_FIXED, T_FRAMES, 1))\n",
    "print('Datasets ready (array-based)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7f537478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 29 compatible layer(s) from UNet_Audio_Classifier_best_WITH_AUG.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UNet_Audio_Classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"UNet_Audio_Classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_mel (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_prelu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_prelu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_prelu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_prelu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_prelu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_prelu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">294,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_prelu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_prelu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gap (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_mel (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_prelu1 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_prelu2 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_prelu1 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_prelu2 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_prelu1 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_prelu2 (\u001b[38;5;33mPReLU\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m294,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_prelu1 (\u001b[38;5;33mPReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m589,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bneck_prelu2 (\u001b[38;5;33mPReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gap (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ logits (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m2,056\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,177,576</span> (4.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,177,576\u001b[0m (4.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,175,656</span> (4.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,175,656\u001b[0m (4.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready (UNet_Audio_Classifier)\n"
     ]
    }
   ],
   "source": [
    "# 5) Define UNet model (same architecture as GTZAN/INDIAN)\n",
    "from keras import layers, models\n",
    "\n",
    "\n",
    "def _unet_encoder_block(input_tensor, filters, pool=True, name_prefix=\"\"):\n",
    "    x = layers.Conv2D(filters, 3, padding='same', use_bias=False, name=f'{name_prefix}_conv1')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=f'{name_prefix}_bn1')(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2], name=f'{name_prefix}_prelu1')(x)\n",
    "    x = layers.Conv2D(filters, 3, padding='same', use_bias=False, name=f'{name_prefix}_conv2')(x)\n",
    "    x = layers.BatchNormalization(name=f'{name_prefix}_bn2')(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2], name=f'{name_prefix}_prelu2')(x)\n",
    "    skip_connection = x\n",
    "    if pool:\n",
    "        pool_output = layers.MaxPooling2D(2, name=f'{name_prefix}_pool')(x)\n",
    "        return pool_output, skip_connection\n",
    "    else:\n",
    "        return x, skip_connection\n",
    "\n",
    "\n",
    "def build_unet_audio_classifier(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape, name='input_mel')\n",
    "    # Encoder path\n",
    "    p1, s1 = _unet_encoder_block(inputs, 32, name_prefix=\"enc1\")\n",
    "    p2, s2 = _unet_encoder_block(p1, 64, name_prefix=\"enc2\")\n",
    "    p3, s3 = _unet_encoder_block(p2, 128, name_prefix=\"enc3\")\n",
    "    # Bottleneck (pool=False)\n",
    "    bottleneck, _ = _unet_encoder_block(p3, 256, pool=False, name_prefix=\"bneck\")\n",
    "    # Classification head\n",
    "    x = layers.GlobalAveragePooling2D(name=\"gap\")(bottleneck)\n",
    "    x = layers.Dropout(0.5, name='dropout')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32', name='logits')(x)\n",
    "    return models.Model(inputs=inputs, outputs=outputs, name='UNet_Audio_Classifier')\n",
    "\n",
    "\n",
    "def try_load_backbone_from_gtzan(model, models_dir: Path, classes: int) -> None:\n",
    "    \"\"\"Optionally initialize encoder weights from a WITH_AUG GTZAN UNet checkpoint.\n",
    "\n",
    "    We only load layers that exist with matching shapes, skipping the final Dense layer.\n",
    "    \"\"\"\n",
    "    if not TAB_INIT_FROM_GTZAN:\n",
    "        return\n",
    "    candidates = [\n",
    "        'UNet_Audio_Classifier_best_WITH_AUG.keras',\n",
    "        'UNet_Audio_Classifier_best_NO_AUG.keras',\n",
    "    ]\n",
    "    for name in candidates:\n",
    "        ckpt = (models_dir / name)\n",
    "        if ckpt.exists():\n",
    "            try:\n",
    "                # Load full model to extract layer weights\n",
    "                src = keras.models.load_model(ckpt.as_posix(), compile=False)\n",
    "                loaded = 0\n",
    "                for layer in model.layers:\n",
    "                    if layer.name == 'logits':\n",
    "                        continue  # skip final classification head\n",
    "                    try:\n",
    "                        src_layer = src.get_layer(layer.name)\n",
    "                        if src_layer is not None and len(layer.get_weights()) == len(src_layer.get_weights()):\n",
    "                            # Ensure shapes match per weight tensor\n",
    "                            tgt_w = layer.get_weights()\n",
    "                            src_w = src_layer.get_weights()\n",
    "                            if all(ti.shape == si.shape for ti, si in zip(tgt_w, src_w)):\n",
    "                                layer.set_weights(src_w)\n",
    "                                loaded += 1\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                print(f'Loaded {loaded} compatible layer(s) from {ckpt.name}')\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print('Backbone init failed for', ckpt.name, '→', e)\n",
    "    print('No compatible GTZAN checkpoint found for backbone init.')\n",
    "\n",
    "# Use observed constants for input shape contract\n",
    "inp_shape = (N_MELS_FIXED, T_FRAMES, 1)\n",
    "model = build_unet_audio_classifier(inp_shape, num_classes)\n",
    "try_load_backbone_from_gtzan(model, MODELS_DIR, num_classes)\n",
    "model.summary()\n",
    "print('Model ready (UNet_Audio_Classifier)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a57fa220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.9032258064516129, 1: 0.9824561403508771, 2: 0.9655172413793104, 3: 1.1666666666666667, 4: 1.1666666666666667, 5: 1.1666666666666667, 6: 1.1666666666666667, 7: 0.7088607594936709}\n",
      "Compile & callbacks ready\n"
     ]
    }
   ],
   "source": [
    "# 6) Compile, class weights, and callbacks\n",
    "opt = keras.optimizers.Adam(learning_rate=LR)\n",
    "# Metrics: accuracy + top-3 like GTZAN\n",
    "top3 = keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')\n",
    "loss = keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy', top3])\n",
    "\n",
    "# Class weights\n",
    "train_labels = train_df['label'].astype(str).values\n",
    "cw = compute_class_weight(class_weight='balanced', classes=np.array(classes), y=train_labels)\n",
    "class_weight = {i: float(w) for i, w in enumerate(cw)}\n",
    "print('Class weights:', class_weight)\n",
    "\n",
    "best_model_path = MODELS_DIR / 'UNet_Audio_Classifier_best_TABLA.keras'\n",
    "csv_log_path = REPORTS_DIR / 'training_summary_TABLA.csv'\n",
    "cb = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=max(2, PATIENCE//2), min_lr=1e-6),\n",
    "    keras.callbacks.ModelCheckpoint(best_model_path.as_posix(), monitor='val_accuracy', save_best_only=True),\n",
    "]\n",
    "print('Compile & callbacks ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "22e5d7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint scenario → training from scratch\n",
      "Epoch 1/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.2269 - loss: 1.9857 - top3_acc: 0.5440 - val_accuracy: 0.1429 - val_loss: 2.6647 - val_top3_acc: 0.5000 - learning_rate: 5.0000e-04\n",
      "Epoch 2/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.5787 - loss: 1.3290 - top3_acc: 0.8819 - val_accuracy: 0.2500 - val_loss: 4.0171 - val_top3_acc: 0.4464 - learning_rate: 5.0000e-04\n",
      "Epoch 3/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.6875 - loss: 0.9807 - top3_acc: 0.9514 - val_accuracy: 0.2143 - val_loss: 6.0458 - val_top3_acc: 0.5179 - learning_rate: 5.0000e-04\n",
      "Epoch 4/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.8519 - loss: 0.6718 - top3_acc: 0.9907 - val_accuracy: 0.3214 - val_loss: 3.6425 - val_top3_acc: 0.5179 - learning_rate: 5.0000e-04\n",
      "Epoch 5/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9190 - loss: 0.4655 - top3_acc: 0.9977 - val_accuracy: 0.3571 - val_loss: 2.3888 - val_top3_acc: 0.6964 - learning_rate: 5.0000e-04\n",
      "Epoch 6/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9745 - loss: 0.3309 - top3_acc: 1.0000 - val_accuracy: 0.4286 - val_loss: 1.9646 - val_top3_acc: 0.7321 - learning_rate: 5.0000e-04\n",
      "Epoch 7/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9838 - loss: 0.2707 - top3_acc: 1.0000 - val_accuracy: 0.4821 - val_loss: 1.9998 - val_top3_acc: 0.7321 - learning_rate: 5.0000e-04\n",
      "Epoch 8/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9931 - loss: 0.2241 - top3_acc: 1.0000 - val_accuracy: 0.4821 - val_loss: 2.0843 - val_top3_acc: 0.7321 - learning_rate: 5.0000e-04\n",
      "Epoch 9/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9931 - loss: 0.2147 - top3_acc: 1.0000 - val_accuracy: 0.4464 - val_loss: 2.0154 - val_top3_acc: 0.6607 - learning_rate: 5.0000e-04\n",
      "Epoch 10/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.2004 - top3_acc: 1.0000 - val_accuracy: 0.5000 - val_loss: 1.6678 - val_top3_acc: 0.7143 - learning_rate: 5.0000e-04\n",
      "Epoch 11/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9977 - loss: 0.1821 - top3_acc: 1.0000 - val_accuracy: 0.5893 - val_loss: 1.1729 - val_top3_acc: 0.8393 - learning_rate: 5.0000e-04\n",
      "Epoch 12/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1779 - top3_acc: 1.0000 - val_accuracy: 0.6250 - val_loss: 0.9150 - val_top3_acc: 0.9286 - learning_rate: 5.0000e-04\n",
      "Epoch 13/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9977 - loss: 0.1688 - top3_acc: 1.0000 - val_accuracy: 0.6429 - val_loss: 0.9060 - val_top3_acc: 0.9286 - learning_rate: 5.0000e-04\n",
      "Epoch 14/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1701 - top3_acc: 1.0000 - val_accuracy: 0.6250 - val_loss: 0.9616 - val_top3_acc: 0.9643 - learning_rate: 5.0000e-04\n",
      "Epoch 15/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1610 - top3_acc: 1.0000 - val_accuracy: 0.7143 - val_loss: 0.7194 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 16/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1597 - top3_acc: 1.0000 - val_accuracy: 0.9286 - val_loss: 0.4538 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 17/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1581 - top3_acc: 1.0000 - val_accuracy: 0.9464 - val_loss: 0.3956 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 18/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1560 - top3_acc: 1.0000 - val_accuracy: 0.9464 - val_loss: 0.3439 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 19/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9977 - loss: 0.1568 - top3_acc: 1.0000 - val_accuracy: 0.9464 - val_loss: 0.3470 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 20/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1537 - top3_acc: 1.0000 - val_accuracy: 0.8571 - val_loss: 0.4582 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 21/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.1576 - top3_acc: 1.0000 - val_accuracy: 0.9464 - val_loss: 0.3364 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 22/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.1540 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1883 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 23/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1543 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1777 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 24/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.1539 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1692 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 25/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1527 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1954 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 26/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.1481 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1771 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 27/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9977 - loss: 0.1472 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1626 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 28/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9977 - loss: 0.1546 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1554 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 29/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1513 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1667 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 30/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.1489 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1639 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 31/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.1476 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1597 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 32/70\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1430 - top3_acc: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1664 - val_top3_acc: 1.0000 - learning_rate: 5.0000e-04\n",
      "Saved: /home/alepot55/Desktop/projects/naml_project/reports/training_summary_TABLA.csv\n"
     ]
    }
   ],
   "source": [
    "# 7) Train or skip/resume based on checkpoint toggles\n",
    "history = None\n",
    "if TAB_FORCE_RETRAIN:\n",
    "    print('FORCE_RETRAIN=1 → training from scratch, ignoring checkpoint')\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, class_weight=class_weight, verbose=1, callbacks=cb)\n",
    "elif TAB_RESUME_FROM_CKPT and best_model_path.exists():\n",
    "    print('RESUME_FROM_CKPT=1 → continuing training from checkpoint')\n",
    "    try:\n",
    "        model.load_weights(best_model_path.as_posix())\n",
    "    except Exception as e:\n",
    "        print('Failed to load checkpoint for resume:', e)\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, class_weight=class_weight, verbose=1, callbacks=cb)\n",
    "elif SKIP_TRAIN_IF_CKPT and best_model_path.exists():\n",
    "    print('Training skipped due to existing checkpoint.')\n",
    "else:\n",
    "    print('No checkpoint scenario → training from scratch')\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, class_weight=class_weight, verbose=1, callbacks=cb)\n",
    "\n",
    "# Persist compact training summary\n",
    "if history is not None:\n",
    "    import numpy as np\n",
    "    best_val = float(np.max(history.history.get('val_accuracy', [0])))\n",
    "    epochs_run = int(len(history.history.get('val_accuracy', [])))\n",
    "else:\n",
    "    best_val = None\n",
    "    epochs_run = 0\n",
    "\n",
    "pd.DataFrame([\n",
    "  {\n",
    "    'Model':'UNet_Audio_Classifier', 'Dataset':'TABLA',\n",
    "    'Best_Val_Accuracy': best_val,\n",
    "    'Test_Accuracy': None,  # filled after test eval\n",
    "    'Epochs_Run': epochs_run\n",
    "  }\n",
    "]).to_csv(csv_log_path, index=False)\n",
    "print('Saved:', csv_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a399d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 16:37:19.707206: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Addhatrital     1.0000    1.0000    1.0000         8\n",
      "     Bhajani     1.0000    1.0000    1.0000         7\n",
      "       Dadra     1.0000    1.0000    1.0000         7\n",
      "  Deepchandi     1.0000    1.0000    1.0000         6\n",
      "       Ektal     1.0000    1.0000    1.0000         6\n",
      "     Jhaptal     1.0000    1.0000    1.0000         6\n",
      "       Rupak     1.0000    1.0000    1.0000         6\n",
      "      Trital     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        56\n",
      "   macro avg     1.0000    1.0000    1.0000        56\n",
      "weighted avg     1.0000    1.0000    1.0000        56\n",
      "\n",
      "[TEST]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Addhatrital     1.0000    1.0000    1.0000         8\n",
      "     Bhajani     1.0000    1.0000    1.0000         8\n",
      "       Dadra     1.0000    1.0000    1.0000         7\n",
      "  Deepchandi     1.0000    0.8333    0.9091         6\n",
      "       Ektal     0.7500    1.0000    0.8571         6\n",
      "     Jhaptal     1.0000    0.8333    0.9091         6\n",
      "       Rupak     1.0000    1.0000    1.0000         6\n",
      "      Trital     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         0.9649        57\n",
      "   macro avg     0.9688    0.9583    0.9594        57\n",
      "weighted avg     0.9737    0.9649    0.9658        57\n",
      "\n",
      "Updated summary with Test_Accuracy: 0.9649122807017544\n",
      "Reports saved to /home/alepot55/Desktop/projects/naml_project/reports\n"
     ]
    }
   ],
   "source": [
    "# 8) Evaluate on val & test, save reports (and update summary)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ensure we evaluate best checkpoint\n",
    "if best_model_path.exists():\n",
    "    try:\n",
    "        model.load_weights(best_model_path.as_posix())\n",
    "    except Exception as e:\n",
    "        print('Warning: could not reload best checkpoint:', e)\n",
    "\n",
    "# VAL on full array to avoid dropping last batch\n",
    "val_probs = model.predict(X_val, batch_size=BATCH_SIZE, verbose=0)\n",
    "val_pred_idx = np.argmax(val_probs, axis=1)\n",
    "val_true_idx = np.asarray(y_val, dtype=int)\n",
    "val_report = classification_report(val_true_idx, val_pred_idx, target_names=classes, digits=4, zero_division=0)\n",
    "print('[VAL]')\n",
    "print(val_report)\n",
    "with open(REPORTS_DIR / 'classification_report_UNet_Audio_Classifier_TABLA_VAL.txt', 'w') as f:\n",
    "    f.write(val_report)\n",
    "cm_val = confusion_matrix(val_true_idx, val_pred_idx, labels=list(range(len(classes))))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix — VAL')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'confusion_matrix_UNet_Audio_Classifier_TABLA_VAL.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# TEST on full array\n",
    "y_pred_probs = model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "y_pred_idx = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_idx = np.asarray(y_test, dtype=int)\n",
    "\n",
    "# Save classification report (TEST)\n",
    "report = classification_report(y_true_idx, y_pred_idx, target_names=classes, digits=4, zero_division=0)\n",
    "with open(REPORTS_DIR / 'classification_report_UNet_Audio_Classifier_TABLA_TEST.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "print('[TEST]')\n",
    "print(report)\n",
    "\n",
    "# Save confusion matrix (TEST)\n",
    "cm = confusion_matrix(y_true_idx, y_pred_idx, labels=list(range(len(classes))))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix — TEST')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'confusion_matrix_UNet_Audio_Classifier_TABLA_TEST.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Update training summary with final test accuracy\n",
    "final_test_acc = accuracy_score(y_true_idx, y_pred_idx)\n",
    "try:\n",
    "    df = pd.read_csv(REPORTS_DIR/'training_summary_TABLA.csv')\n",
    "    df.loc[0, 'Test_Accuracy'] = float(final_test_acc)\n",
    "    df.to_csv(REPORTS_DIR/'training_summary_TABLA.csv', index=False)\n",
    "except Exception as e:\n",
    "    pd.DataFrame([{ 'Model':'UNet_Audio_Classifier', 'Dataset':'TABLA', 'Best_Val_Accuracy': None, 'Test_Accuracy': float(final_test_acc), 'Epochs_Run': 0 }]).to_csv(REPORTS_DIR/'training_summary_TABLA.csv', index=False)\n",
    "print('Updated summary with Test_Accuracy:', final_test_acc)\n",
    "print('Reports saved to', REPORTS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
