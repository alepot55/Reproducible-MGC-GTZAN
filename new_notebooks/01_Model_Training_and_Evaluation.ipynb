{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec7b1a4",
   "metadata": {},
   "source": [
    "# Notebook 01: Addestramento e Valutazione dei Modelli\n",
    "\n",
    "**Scopo:** Questo notebook carica i dati pre-processati dal Notebook 00, definisce le architetture delle reti neurali, orchestra un ciclo di esperimenti per addestrare e valutare diverse combinazioni di modelli e ottimizzatori, e salva gli artefatti migliori per l'analisi successiva.\n",
    "\n",
    "**Input:**\n",
    "- Dati pre-processati da `../data/processed/` (`X_train.npy`, `y_train.npy`, etc.)\n",
    "\n",
    "**Output (salvati in `../models/` e `../reports/`):**\n",
    "- I modelli migliori per ogni esperimento (es. `UNet_Lite_Adam.keras`).\n",
    "- Un file di riepilogo con le metriche di performance (es. `training_summary.csv`).\n",
    "- (Opzionale) Le storie di training salvate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe0892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 12:33:54.759810: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 12:33:54.770537: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753439634.783584  198303 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753439634.787262  198303 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753439634.797356  198303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753439634.797374  198303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753439634.797376  198303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753439634.797377  198303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 12:33:54.800946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU(s) Trovata/e: ['NVIDIA GeForce RTX 4070']\n",
      "âœ… Politica di Mixed Precision impostata su: mixed_float16\n",
      "\n",
      "ðŸ”„ Caricamento dei dati pre-processati...\n",
      "\n",
      "âœ… Dati caricati con successo.\n",
      "   - Shape X_train: (2995, 128, 256, 1) | Shape y_train_cat: (2995, 10)\n",
      "   - Numero di classi: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alepot55/Desktop/projects/naml_project/venv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.0 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 1: SETUP, IMPORTS E CARICAMENTO DATI\n",
    "# ===================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from keras import layers, models, optimizers, callbacks, regularizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# --- Configurazione Globale ---\n",
    "PROCESSED_DATA_PATH = '../data/processed/'\n",
    "MODELS_PATH = '../models/ale/'\n",
    "REPORTS_PATH = '../reports/'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(REPORTS_PATH, exist_ok=True)\n",
    "\n",
    "# 1. GPU e Mixed Precision\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ… GPU(s) Trovata/e: {[tf.config.experimental.get_device_details(g)['device_name'] for g in gpus]}\")\n",
    "        policy = keras.mixed_precision.Policy('mixed_float16')\n",
    "        keras.mixed_precision.set_global_policy(policy)\n",
    "        print(f\"âœ… Politica di Mixed Precision impostata su: {keras.mixed_precision.global_policy().name}\")\n",
    "    except RuntimeError as e: print(f\"âš ï¸ Errore durante l'inizializzazione della GPU: {e}\")\n",
    "else: print(\"âŒ NESSUNA GPU TROVATA. L'allenamento sarÃ  su CPU.\")\n",
    "\n",
    "# 2. Caricamento Dati Pre-processati\n",
    "print(\"\\nðŸ”„ Caricamento dei dati pre-processati...\")\n",
    "try:\n",
    "    X_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_train.npy'))\n",
    "    y_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_train.npy'))\n",
    "    X_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_val.npy'))\n",
    "    y_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_val.npy'))\n",
    "    X_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_test.npy'))\n",
    "    y_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_test.npy'))\n",
    "    \n",
    "    with open(os.path.join(PROCESSED_DATA_PATH, 'label_encoder.pkl'), 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "\n",
    "    # Conversione in formato categorico\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val_cat = to_categorical(y_val, num_classes=num_classes)\n",
    "    y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "    print(\"\\nâœ… Dati caricati con successo.\")\n",
    "    print(f\"   - Shape X_train: {X_train.shape} | Shape y_train_cat: {y_train_cat.shape}\")\n",
    "    print(f\"   - Numero di classi: {num_classes}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERRORE: File di dati non trovati. Eseguire prima il notebook '00_Setup_and_Data_Preparation.ipynb'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56958c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ModelFactory aggiornata. Nuovo candidato 'InceptionSE_CNN' pronto per il test.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 2: DEFINIZIONE DELLE ARCHITETTURE DEI MODELLI (con il nuovo Champion Model)\n",
    "# ===================================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, ReLU,\n",
    "    Concatenate, GlobalAveragePooling2D, Dense, Reshape, Multiply,\n",
    "    Activation, SeparableConv2D, add\n",
    ")\n",
    "\n",
    "class ModelFactory:\n",
    "    \"\"\"\n",
    "    Contiene le factory per tutte le architetture testate.\n",
    "    Il nostro nuovo candidato per superare il 73% Ã¨ 'build_inception_se_cnn'.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _inception_se_block(input_tensor, f1, f3_in, f3_out, f5_in, f5_out, f_pool, se_ratio=16):\n",
    "        \"\"\"Helper privato: Blocco Inception con Squeeze-and-Excitation.\"\"\"\n",
    "        # Percorso 1: Convoluzione 1x1\n",
    "        conv1 = Conv2D(filters=f1, kernel_size=(1, 1), padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "        # Percorso 2: Convoluzione 3x3 con bottleneck\n",
    "        conv3_bottleneck = Conv2D(filters=f3_in, kernel_size=(1, 1), padding='same', activation='relu')(input_tensor)\n",
    "        conv3 = Conv2D(filters=f3_out, kernel_size=(3, 3), padding='same', activation='relu')(conv3_bottleneck)\n",
    "\n",
    "        # Percorso 3: Convoluzione 5x5 con bottleneck\n",
    "        conv5_bottleneck = Conv2D(filters=f5_in, kernel_size=(1, 1), padding='same', activation='relu')(input_tensor)\n",
    "        conv5 = Conv2D(filters=f5_out, kernel_size=(5, 5), padding='same', activation='relu')(conv5_bottleneck)\n",
    "\n",
    "        # Percorso 4: Max-Pooling con bottleneck\n",
    "        pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_tensor)\n",
    "        pool_proj = Conv2D(filters=f_pool, kernel_size=(1, 1), padding='same', activation='relu')(pool)\n",
    "\n",
    "        # Concatenazione dei percorsi multi-scala\n",
    "        inception_out = Concatenate(axis=-1)([conv1, conv3, conv5, pool_proj])\n",
    "        \n",
    "        # Blocco Squeeze-and-Excitation (SE) per l'attenzione sui canali\n",
    "        channels = inception_out.shape[-1]\n",
    "        se = GlobalAveragePooling2D()(inception_out)\n",
    "        se = Reshape((1, 1, channels))(se)\n",
    "        se = Dense(channels // se_ratio, activation='relu', use_bias=False)(se)\n",
    "        se = Dense(channels, activation='sigmoid', use_bias=False)(se)\n",
    "        \n",
    "        return Multiply()([inception_out, se])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_inception_se_cnn(input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        NUOVO CHAMPION MODEL: Architettura Inception-style con blocchi SE.\n",
    "        Progettato per efficienza parametrica e cattura di feature multi-scala.\n",
    "        \"\"\"\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        # Blocco Iniziale (Stem)\n",
    "        x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "        # Blocco Inception-SE 1\n",
    "        x = ModelFactory._inception_se_block(x, f1=32, f3_in=48, f3_out=64, f5_in=8, f5_out=16, f_pool=16)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "\n",
    "        # Blocco Inception-SE 2\n",
    "        x = ModelFactory._inception_se_block(x, f1=64, f3_in=64, f3_out=128, f5_in=16, f5_out=32, f_pool=32)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "        # Testa di Classificazione\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "\n",
    "        model = Model(inputs, outputs, name='InceptionSE_CNN')\n",
    "        return model\n",
    "\n",
    "    # --- Manteniamo i modelli precedenti per riferimento ---\n",
    "    @staticmethod\n",
    "    def build_simple_cnn(input_shape, num_classes):\n",
    "        \"\"\"Un solido modello CNN baseline (VGG-style).\"\"\"\n",
    "        # ... (codice invariato)\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "        return Model(inputs=inputs, outputs=outputs, name='SimpleCNN')\n",
    "\n",
    "print(\"âœ… ModelFactory aggiornata. Nuovo candidato 'InceptionSE_CNN' pronto per il test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6c0fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753439636.303748  198303 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10162 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ARCHITETTURA IN TEST: 'InceptionSE_CNN'\n",
      "================================================================================\n",
      "\n",
      "--- ðŸš€ TRAINING: [InceptionSE_CNN] with [Adam] ---\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753439640.723895  199115 service.cc:152] XLA service 0x7c40bc00d160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753439640.723923  199115 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2025-07-25 12:34:00.816660: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1753439641.511187  199115 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1753439652.377420  199115 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-07-25 12:34:31.988426: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_385', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 36s - 776ms/step - accuracy: 0.3162 - loss: 2.0669 - val_accuracy: 0.1000 - val_loss: 2.3745 - learning_rate: 1.0000e-03\n",
      "Epoch 2/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.4311 - loss: 1.5994 - val_accuracy: 0.1520 - val_loss: 2.4946 - learning_rate: 1.0000e-03\n",
      "Epoch 3/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.5018 - loss: 1.4176 - val_accuracy: 0.1890 - val_loss: 2.5236 - learning_rate: 1.0000e-03\n",
      "Epoch 4/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.5309 - loss: 1.3042 - val_accuracy: 0.1540 - val_loss: 2.5494 - learning_rate: 1.0000e-03\n",
      "Epoch 5/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.5780 - loss: 1.1880 - val_accuracy: 0.2260 - val_loss: 2.2622 - learning_rate: 1.0000e-03\n",
      "Epoch 6/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.6140 - loss: 1.0938 - val_accuracy: 0.1570 - val_loss: 3.1061 - learning_rate: 1.0000e-03\n",
      "Epoch 7/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.6361 - loss: 1.0345 - val_accuracy: 0.2540 - val_loss: 2.1581 - learning_rate: 1.0000e-03\n",
      "Epoch 8/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.6581 - loss: 0.9905 - val_accuracy: 0.4290 - val_loss: 1.7462 - learning_rate: 1.0000e-03\n",
      "Epoch 9/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.6865 - loss: 0.9057 - val_accuracy: 0.4810 - val_loss: 1.7995 - learning_rate: 1.0000e-03\n",
      "Epoch 10/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7092 - loss: 0.8351 - val_accuracy: 0.4750 - val_loss: 1.5272 - learning_rate: 1.0000e-03\n",
      "Epoch 11/100\n",
      "47/47 - 1s - 32ms/step - accuracy: 0.7232 - loss: 0.8098 - val_accuracy: 0.5200 - val_loss: 1.5907 - learning_rate: 1.0000e-03\n",
      "Epoch 12/100\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.7162 - loss: 0.8193 - val_accuracy: 0.6180 - val_loss: 1.0756 - learning_rate: 1.0000e-03\n",
      "Epoch 13/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7255 - loss: 0.7662 - val_accuracy: 0.4560 - val_loss: 1.9265 - learning_rate: 1.0000e-03\n",
      "Epoch 14/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7426 - loss: 0.7311 - val_accuracy: 0.5570 - val_loss: 1.3375 - learning_rate: 1.0000e-03\n",
      "Epoch 15/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7616 - loss: 0.6881 - val_accuracy: 0.6020 - val_loss: 1.1639 - learning_rate: 1.0000e-03\n",
      "Epoch 16/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7750 - loss: 0.6593 - val_accuracy: 0.5990 - val_loss: 1.1524 - learning_rate: 1.0000e-03\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7659 - loss: 0.6457 - val_accuracy: 0.6110 - val_loss: 1.1294 - learning_rate: 1.0000e-03\n",
      "Epoch 18/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.8063 - loss: 0.5571 - val_accuracy: 0.6490 - val_loss: 1.0121 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.8277 - loss: 0.5084 - val_accuracy: 0.7260 - val_loss: 0.7860 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8270 - loss: 0.5018 - val_accuracy: 0.7110 - val_loss: 0.8319 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8441 - loss: 0.4761 - val_accuracy: 0.7080 - val_loss: 0.8321 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8240 - loss: 0.4801 - val_accuracy: 0.7080 - val_loss: 0.8522 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.8474 - loss: 0.4566 - val_accuracy: 0.7350 - val_loss: 0.7518 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.8464 - loss: 0.4569 - val_accuracy: 0.7290 - val_loss: 0.7692 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8447 - loss: 0.4503 - val_accuracy: 0.7200 - val_loss: 0.8546 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8447 - loss: 0.4404 - val_accuracy: 0.7330 - val_loss: 0.8092 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.8467 - loss: 0.4406 - val_accuracy: 0.7500 - val_loss: 0.7592 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8387 - loss: 0.4503 - val_accuracy: 0.7460 - val_loss: 0.7590 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.8705 - loss: 0.3882 - val_accuracy: 0.7620 - val_loss: 0.7325 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.8591 - loss: 0.4085 - val_accuracy: 0.7670 - val_loss: 0.7234 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.8651 - loss: 0.3919 - val_accuracy: 0.7550 - val_loss: 0.7479 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8644 - loss: 0.3916 - val_accuracy: 0.7380 - val_loss: 0.7606 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8638 - loss: 0.3825 - val_accuracy: 0.7510 - val_loss: 0.7385 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8761 - loss: 0.3739 - val_accuracy: 0.7320 - val_loss: 0.7695 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8705 - loss: 0.3853 - val_accuracy: 0.7400 - val_loss: 0.7917 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.8671 - loss: 0.3775 - val_accuracy: 0.7470 - val_loss: 0.7719 - learning_rate: 8.0000e-06\n",
      "Epoch 37/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8611 - loss: 0.3994 - val_accuracy: 0.7470 - val_loss: 0.7513 - learning_rate: 8.0000e-06\n",
      "Epoch 38/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.8678 - loss: 0.3854 - val_accuracy: 0.7520 - val_loss: 0.7486 - learning_rate: 8.0000e-06\n",
      "Epoch 39/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8678 - loss: 0.3817 - val_accuracy: 0.7550 - val_loss: 0.7337 - learning_rate: 8.0000e-06\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8748 - loss: 0.3631 - val_accuracy: 0.7540 - val_loss: 0.7353 - learning_rate: 8.0000e-06\n",
      "Epoch 41/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8715 - loss: 0.3642 - val_accuracy: 0.7530 - val_loss: 0.7324 - learning_rate: 1.6000e-06\n",
      "Epoch 42/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.8674 - loss: 0.3810 - val_accuracy: 0.7570 - val_loss: 0.7293 - learning_rate: 1.6000e-06\n",
      "Epoch 43/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.8735 - loss: 0.3774 - val_accuracy: 0.7560 - val_loss: 0.7308 - learning_rate: 1.6000e-06\n",
      "Epoch 44/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8698 - loss: 0.4013 - val_accuracy: 0.7570 - val_loss: 0.7317 - learning_rate: 1.6000e-06\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8731 - loss: 0.3652 - val_accuracy: 0.7580 - val_loss: 0.7310 - learning_rate: 1.6000e-06\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "--- ðŸš€ TRAINING: [InceptionSE_CNN] with [SGD_Momentum] ---\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 12:35:37.611333: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 388 bytes spill stores, 388 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:37.928980: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 416 bytes spill stores, 416 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:37.963038: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 400 bytes spill stores, 400 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:37.995794: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 680 bytes spill stores, 548 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:46.377119: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 452 bytes spill stores, 452 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:46.411517: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 456 bytes spill stores, 456 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:46.524787: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 516 bytes spill stores, 516 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:46.700441: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 416 bytes spill stores, 416 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:46.754100: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:46.819473: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 452 bytes spill stores, 452 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:46.856121: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-07-25 12:35:46.996162: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3095', 452 bytes spill stores, 452 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 23s - 480ms/step - accuracy: 0.2531 - loss: 2.2507 - val_accuracy: 0.1440 - val_loss: 2.2291 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.4050 - loss: 1.6236 - val_accuracy: 0.1640 - val_loss: 2.3140 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.4654 - loss: 1.4793 - val_accuracy: 0.1470 - val_loss: 2.3294 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.4898 - loss: 1.3745 - val_accuracy: 0.1360 - val_loss: 2.3437 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.5329 - loss: 1.2913 - val_accuracy: 0.1490 - val_loss: 2.5755 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.5359 - loss: 1.2690 - val_accuracy: 0.2150 - val_loss: 2.4088 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.5716 - loss: 1.1783 - val_accuracy: 0.2730 - val_loss: 2.2273 - learning_rate: 0.0020\n",
      "Epoch 8/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.6124 - loss: 1.0953 - val_accuracy: 0.3440 - val_loss: 2.0599 - learning_rate: 0.0020\n",
      "Epoch 9/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.6154 - loss: 1.0810 - val_accuracy: 0.3920 - val_loss: 1.8598 - learning_rate: 0.0020\n",
      "Epoch 10/100\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.6290 - loss: 1.0629 - val_accuracy: 0.4550 - val_loss: 1.6780 - learning_rate: 0.0020\n",
      "Epoch 11/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.6351 - loss: 1.0491 - val_accuracy: 0.5230 - val_loss: 1.4103 - learning_rate: 0.0020\n",
      "Epoch 12/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.6381 - loss: 1.0377 - val_accuracy: 0.5070 - val_loss: 1.5071 - learning_rate: 0.0020\n",
      "Epoch 13/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.6290 - loss: 1.0373 - val_accuracy: 0.5990 - val_loss: 1.1768 - learning_rate: 0.0020\n",
      "Epoch 14/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.6528 - loss: 1.0035 - val_accuracy: 0.5850 - val_loss: 1.2068 - learning_rate: 0.0020\n",
      "Epoch 15/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.6454 - loss: 1.0019 - val_accuracy: 0.5550 - val_loss: 1.3054 - learning_rate: 0.0020\n",
      "Epoch 16/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.6541 - loss: 0.9841 - val_accuracy: 0.6080 - val_loss: 1.1165 - learning_rate: 0.0020\n",
      "Epoch 17/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.6628 - loss: 0.9643 - val_accuracy: 0.5920 - val_loss: 1.1722 - learning_rate: 0.0020\n",
      "Epoch 18/100\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.6571 - loss: 0.9686 - val_accuracy: 0.6480 - val_loss: 1.0405 - learning_rate: 0.0020\n",
      "Epoch 19/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.6588 - loss: 0.9509 - val_accuracy: 0.5550 - val_loss: 1.2476 - learning_rate: 0.0020\n",
      "Epoch 20/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.6788 - loss: 0.9279 - val_accuracy: 0.6010 - val_loss: 1.1981 - learning_rate: 0.0020\n",
      "Epoch 21/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.6781 - loss: 0.9208 - val_accuracy: 0.6370 - val_loss: 1.0275 - learning_rate: 0.0020\n",
      "Epoch 22/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.6618 - loss: 0.9356 - val_accuracy: 0.6230 - val_loss: 1.0760 - learning_rate: 0.0020\n",
      "Epoch 23/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.6755 - loss: 0.9181 - val_accuracy: 0.6710 - val_loss: 0.9763 - learning_rate: 0.0020\n",
      "Epoch 24/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.6888 - loss: 0.8960 - val_accuracy: 0.6350 - val_loss: 1.1061 - learning_rate: 0.0020\n",
      "Epoch 25/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.6885 - loss: 0.8823 - val_accuracy: 0.6430 - val_loss: 1.0372 - learning_rate: 0.0020\n",
      "Epoch 26/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7005 - loss: 0.8875 - val_accuracy: 0.6400 - val_loss: 1.0616 - learning_rate: 0.0020\n",
      "Epoch 27/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.6942 - loss: 0.8556 - val_accuracy: 0.6870 - val_loss: 0.9333 - learning_rate: 0.0020\n",
      "Epoch 28/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.6942 - loss: 0.8716 - val_accuracy: 0.6530 - val_loss: 0.9945 - learning_rate: 0.0020\n",
      "Epoch 29/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7085 - loss: 0.8288 - val_accuracy: 0.6160 - val_loss: 1.1089 - learning_rate: 0.0020\n",
      "Epoch 30/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7032 - loss: 0.8439 - val_accuracy: 0.6700 - val_loss: 0.9255 - learning_rate: 0.0020\n",
      "Epoch 31/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7098 - loss: 0.8260 - val_accuracy: 0.6010 - val_loss: 1.2116 - learning_rate: 0.0020\n",
      "Epoch 32/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7155 - loss: 0.8201 - val_accuracy: 0.6610 - val_loss: 0.9709 - learning_rate: 0.0020\n",
      "Epoch 33/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7135 - loss: 0.8215 - val_accuracy: 0.5710 - val_loss: 1.3427 - learning_rate: 0.0020\n",
      "Epoch 34/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7048 - loss: 0.8336 - val_accuracy: 0.6640 - val_loss: 1.0067 - learning_rate: 0.0020\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7255 - loss: 0.7935 - val_accuracy: 0.6700 - val_loss: 0.9570 - learning_rate: 0.0020\n",
      "Epoch 36/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7232 - loss: 0.7667 - val_accuracy: 0.6810 - val_loss: 0.9394 - learning_rate: 4.0000e-04\n",
      "Epoch 37/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7456 - loss: 0.7475 - val_accuracy: 0.6570 - val_loss: 0.9684 - learning_rate: 4.0000e-04\n",
      "Epoch 38/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7359 - loss: 0.7584 - val_accuracy: 0.6790 - val_loss: 0.9517 - learning_rate: 4.0000e-04\n",
      "Epoch 39/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7366 - loss: 0.7603 - val_accuracy: 0.6670 - val_loss: 0.9613 - learning_rate: 4.0000e-04\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7316 - loss: 0.7661 - val_accuracy: 0.6630 - val_loss: 1.0127 - learning_rate: 4.0000e-04\n",
      "Epoch 41/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7409 - loss: 0.7454 - val_accuracy: 0.6830 - val_loss: 0.9322 - learning_rate: 8.0000e-05\n",
      "Epoch 42/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7312 - loss: 0.7639 - val_accuracy: 0.6810 - val_loss: 0.9296 - learning_rate: 8.0000e-05\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "--- ðŸš€ TRAINING: [InceptionSE_CNN] with [RMSprop] ---\n",
      "Epoch 1/100\n",
      "47/47 - 19s - 401ms/step - accuracy: 0.3275 - loss: 1.9827 - val_accuracy: 0.1620 - val_loss: 2.3505 - learning_rate: 1.0000e-03\n",
      "Epoch 2/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.4414 - loss: 1.5567 - val_accuracy: 0.1000 - val_loss: 2.5230 - learning_rate: 1.0000e-03\n",
      "Epoch 3/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.4948 - loss: 1.4098 - val_accuracy: 0.1620 - val_loss: 2.6240 - learning_rate: 1.0000e-03\n",
      "Epoch 4/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.5486 - loss: 1.2453 - val_accuracy: 0.1550 - val_loss: 2.7373 - learning_rate: 1.0000e-03\n",
      "Epoch 5/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.5863 - loss: 1.1652 - val_accuracy: 0.1590 - val_loss: 2.6919 - learning_rate: 1.0000e-03\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.6234 - loss: 1.0585 - val_accuracy: 0.2190 - val_loss: 2.4440 - learning_rate: 1.0000e-03\n",
      "Epoch 7/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.6641 - loss: 0.9675 - val_accuracy: 0.3150 - val_loss: 2.2694 - learning_rate: 2.0000e-04\n",
      "Epoch 8/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.6945 - loss: 0.8749 - val_accuracy: 0.3480 - val_loss: 2.0775 - learning_rate: 2.0000e-04\n",
      "Epoch 9/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7022 - loss: 0.8533 - val_accuracy: 0.3620 - val_loss: 1.9606 - learning_rate: 2.0000e-04\n",
      "Epoch 10/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7109 - loss: 0.8296 - val_accuracy: 0.4630 - val_loss: 1.5115 - learning_rate: 2.0000e-04\n",
      "Epoch 11/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.7225 - loss: 0.8142 - val_accuracy: 0.4870 - val_loss: 1.4481 - learning_rate: 2.0000e-04\n",
      "Epoch 12/100\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.7239 - loss: 0.7768 - val_accuracy: 0.6130 - val_loss: 1.0934 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7326 - loss: 0.7731 - val_accuracy: 0.5420 - val_loss: 1.3002 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7259 - loss: 0.7706 - val_accuracy: 0.6290 - val_loss: 1.0412 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7442 - loss: 0.7375 - val_accuracy: 0.6050 - val_loss: 1.1554 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.7479 - loss: 0.7278 - val_accuracy: 0.6830 - val_loss: 0.9674 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7442 - loss: 0.7061 - val_accuracy: 0.6510 - val_loss: 0.9958 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7673 - loss: 0.6858 - val_accuracy: 0.6480 - val_loss: 1.0649 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.7703 - loss: 0.6566 - val_accuracy: 0.7010 - val_loss: 0.9240 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7643 - loss: 0.6801 - val_accuracy: 0.6840 - val_loss: 0.9165 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.7793 - loss: 0.6561 - val_accuracy: 0.7110 - val_loss: 0.8549 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7713 - loss: 0.6532 - val_accuracy: 0.6720 - val_loss: 0.9531 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7763 - loss: 0.6348 - val_accuracy: 0.6980 - val_loss: 0.8758 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7866 - loss: 0.6332 - val_accuracy: 0.6680 - val_loss: 1.0147 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.7947 - loss: 0.6155 - val_accuracy: 0.7120 - val_loss: 0.8366 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.7997 - loss: 0.6003 - val_accuracy: 0.7070 - val_loss: 0.7909 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "47/47 - 1s - 31ms/step - accuracy: 0.7943 - loss: 0.5875 - val_accuracy: 0.7240 - val_loss: 0.8051 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7943 - loss: 0.5923 - val_accuracy: 0.6950 - val_loss: 0.9230 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7947 - loss: 0.5932 - val_accuracy: 0.5220 - val_loss: 1.8621 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.7983 - loss: 0.5772 - val_accuracy: 0.7190 - val_loss: 0.8616 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8050 - loss: 0.5624 - val_accuracy: 0.7070 - val_loss: 0.9249 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "47/47 - 2s - 32ms/step - accuracy: 0.8160 - loss: 0.5347 - val_accuracy: 0.7340 - val_loss: 0.8145 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8170 - loss: 0.5201 - val_accuracy: 0.7330 - val_loss: 0.8013 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.8294 - loss: 0.5043 - val_accuracy: 0.7430 - val_loss: 0.7806 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8234 - loss: 0.5300 - val_accuracy: 0.7140 - val_loss: 0.8024 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "47/47 - 1s - 29ms/step - accuracy: 0.8240 - loss: 0.5078 - val_accuracy: 0.7490 - val_loss: 0.7500 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8317 - loss: 0.5025 - val_accuracy: 0.7480 - val_loss: 0.7585 - learning_rate: 4.0000e-05\n",
      "Epoch 38/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8267 - loss: 0.5055 - val_accuracy: 0.7490 - val_loss: 0.7934 - learning_rate: 4.0000e-05\n",
      "Epoch 39/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8327 - loss: 0.4920 - val_accuracy: 0.7420 - val_loss: 0.7658 - learning_rate: 4.0000e-05\n",
      "Epoch 40/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.8280 - loss: 0.5062 - val_accuracy: 0.7410 - val_loss: 0.7511 - learning_rate: 4.0000e-05\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8277 - loss: 0.5149 - val_accuracy: 0.7460 - val_loss: 0.7538 - learning_rate: 4.0000e-05\n",
      "Epoch 42/100\n",
      "47/47 - 1s - 30ms/step - accuracy: 0.8347 - loss: 0.4806 - val_accuracy: 0.7560 - val_loss: 0.7425 - learning_rate: 8.0000e-06\n",
      "Epoch 43/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8344 - loss: 0.4809 - val_accuracy: 0.7530 - val_loss: 0.7460 - learning_rate: 8.0000e-06\n",
      "Epoch 44/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8361 - loss: 0.4927 - val_accuracy: 0.7480 - val_loss: 0.7523 - learning_rate: 8.0000e-06\n",
      "Epoch 45/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8341 - loss: 0.4848 - val_accuracy: 0.7500 - val_loss: 0.7532 - learning_rate: 8.0000e-06\n",
      "Epoch 46/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8414 - loss: 0.4716 - val_accuracy: 0.7490 - val_loss: 0.7523 - learning_rate: 8.0000e-06\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8347 - loss: 0.4811 - val_accuracy: 0.7510 - val_loss: 0.7511 - learning_rate: 8.0000e-06\n",
      "Epoch 48/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8304 - loss: 0.4942 - val_accuracy: 0.7490 - val_loss: 0.7501 - learning_rate: 1.6000e-06\n",
      "Epoch 49/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8381 - loss: 0.4814 - val_accuracy: 0.7490 - val_loss: 0.7483 - learning_rate: 1.6000e-06\n",
      "Epoch 50/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8361 - loss: 0.4963 - val_accuracy: 0.7510 - val_loss: 0.7499 - learning_rate: 1.6000e-06\n",
      "Epoch 51/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8407 - loss: 0.4937 - val_accuracy: 0.7520 - val_loss: 0.7511 - learning_rate: 1.6000e-06\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8304 - loss: 0.4867 - val_accuracy: 0.7510 - val_loss: 0.7503 - learning_rate: 1.6000e-06\n",
      "Epoch 53/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8301 - loss: 0.4886 - val_accuracy: 0.7530 - val_loss: 0.7504 - learning_rate: 3.2000e-07\n",
      "Epoch 54/100\n",
      "47/47 - 1s - 28ms/step - accuracy: 0.8441 - loss: 0.4719 - val_accuracy: 0.7530 - val_loss: 0.7504 - learning_rate: 3.2000e-07\n",
      "Epoch 55/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8344 - loss: 0.4794 - val_accuracy: 0.7500 - val_loss: 0.7504 - learning_rate: 3.2000e-07\n",
      "Epoch 56/100\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8347 - loss: 0.4925 - val_accuracy: 0.7500 - val_loss: 0.7503 - learning_rate: 3.2000e-07\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "47/47 - 1s - 27ms/step - accuracy: 0.8327 - loss: 0.4959 - val_accuracy: 0.7520 - val_loss: 0.7516 - learning_rate: 3.2000e-07\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "\n",
      "ðŸŽ‰ CICLO DI TRAINING SUL NUOVO MODELLO COMPLETATO ðŸŽ‰\n",
      "\n",
      "Risultati Finali:\n",
      "                     Experiment            Model     Optimizer  Test_Accuracy  \\\n",
      "0          InceptionSE_CNN_Adam  InceptionSE_CNN          Adam          0.760   \n",
      "2       InceptionSE_CNN_RMSprop  InceptionSE_CNN       RMSprop          0.736   \n",
      "1  InceptionSE_CNN_SGD_Momentum  InceptionSE_CNN  SGD_Momentum          0.631   \n",
      "\n",
      "   Test_Loss  Best_Val_Accuracy  Epochs  \n",
      "0   0.787394              0.767      45  \n",
      "2   0.857970              0.756      57  \n",
      "1   1.066718              0.687      42  \n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 3: FRAMEWORK DI TRAINING FINALE (Focalizzato sul nuovo modello)\n",
    "# ===================================================================\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import tensorflow as tf\n",
    "from keras import optimizers, callbacks\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. FUNZIONE DI DATA AUGMENTATION (Invariata)\n",
    "# -------------------------------------------------------------------\n",
    "@tf.function\n",
    "def spec_augment_tf(spectrogram, label):\n",
    "    \"\"\"Applica SpecAugment usando solo operazioni TensorFlow.\"\"\"\n",
    "    # ... (codice invariato)\n",
    "    aug_spec = tf.identity(spectrogram)\n",
    "    freq_bins = tf.shape(aug_spec)[0]\n",
    "    time_steps = tf.shape(aug_spec)[1]\n",
    "    \n",
    "    # Mascheramento in Frequenza\n",
    "    f_param = tf.cast(tf.cast(freq_bins, tf.float32) * 0.2, tf.int32)\n",
    "    if f_param > 1:\n",
    "        f = tf.random.uniform(shape=(), minval=1, maxval=f_param, dtype=tf.int32)\n",
    "        f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_bins - f, dtype=tf.int32)\n",
    "        mask_freq_values = tf.concat([tf.ones((f0,), dtype=aug_spec.dtype), tf.zeros((f,), dtype=aug_spec.dtype), tf.ones((freq_bins - f0 - f,), dtype=aug_spec.dtype)], axis=0)\n",
    "        mask_freq = tf.reshape(mask_freq_values, (freq_bins, 1, 1))\n",
    "        aug_spec = aug_spec * mask_freq\n",
    "\n",
    "    # Mascheramento nel Tempo\n",
    "    t_param = tf.cast(tf.cast(time_steps, tf.float32) * 0.2, tf.int32)\n",
    "    if t_param > 1:\n",
    "        t = tf.random.uniform(shape=(), minval=1, maxval=t_param, dtype=tf.int32)\n",
    "        t0 = tf.random.uniform(shape=(), minval=0, maxval=time_steps - t, dtype=tf.int32)\n",
    "        mask_time_values = tf.concat([tf.ones((t0,), dtype=aug_spec.dtype), tf.zeros((t,), dtype=aug_spec.dtype), tf.ones((time_steps - t0 - t,), dtype=aug_spec.dtype)], axis=0)\n",
    "        mask_time = tf.reshape(mask_time_values, (1, time_steps, 1))\n",
    "        aug_spec = aug_spec * mask_time\n",
    "        \n",
    "    return aug_spec, label\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. CLASSE EVALUATOR (Invariata)\n",
    "# -------------------------------------------------------------------\n",
    "class MusicGenreEvaluator:\n",
    "    \"\"\"Orchestra il training in modo stabile per tutte le architetture.\"\"\"\n",
    "    # ... (codice invariato)\n",
    "    def __init__(self, class_names):\n",
    "        self.class_names = class_names\n",
    "        self.results = []\n",
    "\n",
    "    def prepare_optimizers(self, lr=1e-3):\n",
    "        return {\n",
    "            'Adam': optimizers.Adam(learning_rate=lr),\n",
    "            'SGD_Momentum': optimizers.SGD(learning_rate=lr*10, momentum=0.9),\n",
    "            'RMSprop': optimizers.RMSprop(learning_rate=lr)\n",
    "        }\n",
    "\n",
    "    def run_experiments(self, model_factories, optimizers_config, train_data, val_data, test_data, epochs):\n",
    "        for model_name, model_factory in model_factories.items():\n",
    "            print(f\"\\n{'='*80}\\nARCHITETTURA IN TEST: '{model_name}'\\n{'='*80}\")\n",
    "            for optimizer_name, optimizer in optimizers_config.items():\n",
    "                print(f\"\\n--- ðŸš€ TRAINING: [{model_name}] with [{optimizer_name}] ---\")\n",
    "                try:\n",
    "                    model = model_factory()\n",
    "                    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    \n",
    "                    callbacks_list = [\n",
    "                        callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True, verbose=1),\n",
    "                        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1),\n",
    "                        callbacks.ModelCheckpoint(os.path.join(MODELS_PATH, f\"{model_name}_{optimizer_name}.keras\"),\n",
    "                                                  monitor='val_accuracy', save_best_only=True)\n",
    "                    ]\n",
    "                    \n",
    "                    history = model.fit(train_data, epochs=epochs, validation_data=val_data, callbacks=callbacks_list, verbose=2)\n",
    "                    \n",
    "                    test_loss, test_acc = model.evaluate(test_data, verbose=0)\n",
    "                    self.results.append({\n",
    "                        'Experiment': f\"{model_name}_{optimizer_name}\", 'Model': model_name, 'Optimizer': optimizer_name,\n",
    "                        'Test_Accuracy': test_acc, 'Test_Loss': test_loss,\n",
    "                        'Best_Val_Accuracy': max(history.history['val_accuracy']),\n",
    "                        'Epochs': len(history.history['val_accuracy']),\n",
    "                    })\n",
    "                except Exception:\n",
    "                    print(f\"âŒ ERRORE durante il training di [{model_name}] con [{optimizer_name}]:\")\n",
    "                    traceback.print_exc()\n",
    "        return pd.DataFrame(self.results)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. ESECUZIONE DEL CICLO DI TRAINING SUL NUOVO MODELLO\n",
    "# -------------------------------------------------------------------\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 64 # Manteniamo un batch size ragionevole per Inception\n",
    "EPOCHS = 100\n",
    "\n",
    "# Impostazioni globali (invariate)\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n",
    "\n",
    "# Pipeline di dati (invariata)\n",
    "train_pipeline = (tf.data.Dataset.from_tensor_slices((X_train, y_train_cat)).cache().shuffle(len(X_train))\n",
    "                  .map(spec_augment_tf, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "val_pipeline = (tf.data.Dataset.from_tensor_slices((X_val, y_val_cat)).cache().batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "test_pipeline = (tf.data.Dataset.from_tensor_slices((X_test, y_test_cat)).cache().batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "\n",
    "# *** MODIFICA CHIAVE ***\n",
    "# Factory dei modelli: puntiamo solo al nostro nuovo candidato.\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = y_train_cat.shape[1]\n",
    "model_factories = {\n",
    "    'InceptionSE_CNN': lambda: ModelFactory.build_inception_se_cnn(input_shape, num_classes),\n",
    "}\n",
    "\n",
    "# Esecuzione\n",
    "evaluator = MusicGenreEvaluator(class_names=label_encoder.classes_)\n",
    "optimizers_config = evaluator.prepare_optimizers(lr=1e-3) # Adam funziona bene con 1e-3\n",
    "results_df = evaluator.run_experiments(\n",
    "    model_factories, optimizers_config, train_pipeline, val_pipeline, test_pipeline, EPOCHS\n",
    ")\n",
    "\n",
    "# Salvataggio e visualizzazione (invariati)\n",
    "if not results_df.empty:\n",
    "    results_df.to_csv(os.path.join(REPORTS_PATH, 'training_summary_InceptionSE.csv'), index=False)\n",
    "    print(\"\\nðŸŽ‰ CICLO DI TRAINING SUL NUOVO MODELLO COMPLETATO ðŸŽ‰\")\n",
    "    print(\"\\nRisultati Finali:\")\n",
    "    print(results_df.sort_values(by='Best_Val_Accuracy', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
